{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Q-Learning ","metadata":{}},{"cell_type":"markdown","source":"Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down.","metadata":{}},{"cell_type":"code","source":"! git clone https://github.com/HariniAru/cs444.git","metadata":{"execution":{"iopub.status.busy":"2024-05-06T01:37:40.087150Z","iopub.execute_input":"2024-05-06T01:37:40.087447Z","iopub.status.idle":"2024-05-06T01:37:42.288250Z","shell.execute_reply.started":"2024-05-06T01:37:40.087421Z","shell.execute_reply":"2024-05-06T01:37:42.287058Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'cs444'...\nremote: Enumerating objects: 284, done.\u001b[K\nremote: Counting objects: 100% (115/115), done.\u001b[K\nremote: Compressing objects: 100% (104/104), done.\u001b[K\nremote: Total 284 (delta 49), reused 19 (delta 9), pack-reused 169\u001b[K\nReceiving objects: 100% (284/284), 8.47 MiB | 15.14 MiB/s, done.\nResolving deltas: 100% (124/124), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install gym pyvirtualdisplay\n!sudo apt-get install -y xvfb python-opengl ffmpeg","metadata":{"execution":{"iopub.status.busy":"2024-05-06T01:37:48.733424Z","iopub.execute_input":"2024-05-06T01:37:48.733783Z","iopub.status.idle":"2024-05-06T01:38:13.408533Z","shell.execute_reply.started":"2024-05-06T01:37:48.733751Z","shell.execute_reply":"2024-05-06T01:38:13.407609Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gym in /opt/conda/lib/python3.10/site-packages (0.26.2)\nCollecting pyvirtualdisplay\n  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym) (0.0.8)\nDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\nInstalling collected packages: pyvirtualdisplay\nSuccessfully installed pyvirtualdisplay-3.0\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\nxvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.17).\nThe following additional packages will be installed:\n  freeglut3 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n  libpython2.7-stdlib python2 python2-minimal python2.7 python2.7-minimal\nSuggested packages:\n  python-tk python-numpy libgle3 python2-doc python2.7-doc binfmt-support\nThe following NEW packages will be installed:\n  freeglut3 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n  libpython2.7-stdlib python-opengl python2 python2-minimal python2.7\n  python2.7-minimal\n0 upgraded, 10 newly installed, 0 to remove and 65 not upgraded.\nNeed to get 4540 kB of archives.\nAfter this operation, 22.7 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-minimal amd64 2.7.18-1~20.04.4 [335 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7-minimal amd64 2.7.18-1~20.04.4 [1280 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-stdlib amd64 2.7.18-1~20.04.4 [1887 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7 amd64 2.7.18-1~20.04.4 [248 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7072 B]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libglu1-mesa amd64 9.0.1-1build1 [168 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\nFetched 4540 kB in 0s (30.1 MB/s)      \nSelecting previously unselected package libpython2.7-minimal:amd64.\n(Reading database ... 113807 files and directories currently installed.)\nPreparing to unpack .../0-libpython2.7-minimal_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking libpython2.7-minimal:amd64 (2.7.18-1~20.04.4) ...\nSelecting previously unselected package python2.7-minimal.\nPreparing to unpack .../1-python2.7-minimal_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking python2.7-minimal (2.7.18-1~20.04.4) ...\nSelecting previously unselected package python2-minimal.\nPreparing to unpack .../2-python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\nUnpacking python2-minimal (2.7.17-2ubuntu4) ...\nSelecting previously unselected package libpython2.7-stdlib:amd64.\nPreparing to unpack .../3-libpython2.7-stdlib_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking libpython2.7-stdlib:amd64 (2.7.18-1~20.04.4) ...\nSelecting previously unselected package python2.7.\nPreparing to unpack .../4-python2.7_2.7.18-1~20.04.4_amd64.deb ...\nUnpacking python2.7 (2.7.18-1~20.04.4) ...\nSelecting previously unselected package libpython2-stdlib:amd64.\nPreparing to unpack .../5-libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\nUnpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\nSetting up libpython2.7-minimal:amd64 (2.7.18-1~20.04.4) ...\nSetting up python2.7-minimal (2.7.18-1~20.04.4) ...\nLinking and byte-compiling packages for runtime python2.7...\nSetting up python2-minimal (2.7.17-2ubuntu4) ...\nSelecting previously unselected package python2.\n(Reading database ... 114554 files and directories currently installed.)\nPreparing to unpack .../python2_2.7.17-2ubuntu4_amd64.deb ...\nUnpacking python2 (2.7.17-2ubuntu4) ...\nSelecting previously unselected package freeglut3:amd64.\nPreparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\nUnpacking freeglut3:amd64 (2.8.1-3) ...\nSelecting previously unselected package libglu1-mesa:amd64.\nPreparing to unpack .../libglu1-mesa_9.0.1-1build1_amd64.deb ...\nUnpacking libglu1-mesa:amd64 (9.0.1-1build1) ...\nSelecting previously unselected package python-opengl.\nPreparing to unpack .../python-opengl_3.1.0+dfsg-2build1_all.deb ...\nUnpacking python-opengl (3.1.0+dfsg-2build1) ...\nSetting up freeglut3:amd64 (2.8.1-3) ...\nSetting up libpython2.7-stdlib:amd64 (2.7.18-1~20.04.4) ...\nSetting up libglu1-mesa:amd64 (9.0.1-1build1) ...\nSetting up python2.7 (2.7.18-1~20.04.4) ...\nSetting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\nSetting up python2 (2.7.17-2ubuntu4) ...\nSetting up python-opengl (3.1.0+dfsg-2build1) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for mime-support (3.64ubuntu1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install --upgrade setuptools --user\n!pip3 install ez_setup \n!pip3 install gym[atari] \n!pip3 install gym[accept-rom-license] ","metadata":{"execution":{"iopub.status.busy":"2024-05-06T01:38:21.486091Z","iopub.execute_input":"2024-05-06T01:38:21.486519Z","iopub.status.idle":"2024-05-06T01:39:30.512307Z","shell.execute_reply.started":"2024-05-06T01:38:21.486484Z","shell.execute_reply":"2024-05-06T01:39:30.511195Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (69.0.3)\nCollecting setuptools\n  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\nDownloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: setuptools\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed setuptools-69.5.1\nCollecting ez_setup\n  Downloading ez_setup-0.9.tar.gz (6.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: ez_setup\n  Building wheel for ez_setup (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ez_setup: filename=ez_setup-0.9-py3-none-any.whl size=10995 sha256=6e6463963a83afd0899068b77ab3af7fa297f0206210efb0b20ede603fa581b3\n  Stored in directory: /root/.cache/pip/wheels/7a/d6/77/8f495e85fb7df23d41c328b9ea3cf0d9e83631b20bba479293\nSuccessfully built ez_setup\nInstalling collected packages: ez_setup\nSuccessfully installed ez_setup-0.9\nRequirement already satisfied: gym[atari] in /opt/conda/lib/python3.10/site-packages (0.26.2)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (0.0.8)\nCollecting ale-py~=0.8.0 (from gym[atari])\n  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.8.0->gym[atari]) (6.1.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.8.0->gym[atari]) (4.9.0)\nDownloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ale-py\nSuccessfully installed ale-py-0.8.1\nRequirement already satisfied: gym[accept-rom-license] in /opt/conda/lib/python3.10/site-packages (0.26.2)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (0.0.8)\nCollecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license])\n  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (8.1.7)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (4.66.1)\nCollecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license])\n  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license]) (2024.2.2)\nDownloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\nBuilding wheels for collected packages: AutoROM.accept-rom-license\n  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=bc02f2108c05a7f7b16b754c6895c796fd9bbb95e584bfecf413b26cafa774ee\n  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\nSuccessfully built AutoROM.accept-rom-license\nInstalling collected packages: AutoROM.accept-rom-license, autorom\nSuccessfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__.","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\nimport sys\n\n# Add the path to the directory containing the `gan` package to sys.path\nsys.path.append('/kaggle/working/cs444/assignment5_materials')\n\nimport gym\nimport torch\nimport pylab\nimport random\nimport numpy as np\nfrom collections import deque\nfrom datetime import datetime\nfrom copy import deepcopy\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom utils import find_max_lives, check_live, get_frame, get_init_state\nfrom model import DQN, DQN_LSTM\nfrom config import *\n\nimport matplotlib.pyplot as plt\n# %load_ext autoreload\n# %autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-05-06T01:39:35.063459Z","iopub.execute_input":"2024-05-06T01:39:35.063830Z","iopub.status.idle":"2024-05-06T01:39:39.034948Z","shell.execute_reply.started":"2024-05-06T01:39:35.063800Z","shell.execute_reply":"2024-05-06T01:39:39.034145Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Understanding the environment","metadata":{}},{"cell_type":"markdown","source":"In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. \n\nIn breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right.","metadata":{}},{"cell_type":"code","source":"env = gym.make('BreakoutDeterministic-v4')\nstate = env.reset()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T01:39:43.411935Z","iopub.execute_input":"2024-05-06T01:39:43.412689Z","iopub.status.idle":"2024-05-06T01:39:43.749922Z","shell.execute_reply.started":"2024-05-06T01:39:43.412656Z","shell.execute_reply":"2024-05-06T01:39:43.749201Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n[Powered by Stella]\n","output_type":"stream"}]},{"cell_type":"code","source":"number_lives = find_max_lives(env)\nstate_size = env.observation_space.shape\naction_size = 3 #fire, left, and right","metadata":{"execution":{"iopub.status.busy":"2024-05-06T01:39:45.778179Z","iopub.execute_input":"2024-05-06T01:39:45.778891Z","iopub.status.idle":"2024-05-06T01:39:45.800057Z","shell.execute_reply.started":"2024-05-06T01:39:45.778857Z","shell.execute_reply":"2024-05-06T01:39:45.799121Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n  if not isinstance(terminated, (bool, np.bool8)):\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Creating a DQN Agent","metadata":{}},{"cell_type":"markdown","source":"Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n\n__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n\n__Frame__ : Number of frames processed in total.\n\n__Memory Size__ : The current size of the replay memory.","metadata":{}},{"cell_type":"code","source":"double_dqn = True # set to True if using double DQN agent\n\nif double_dqn:\n    from agent_double import Agent\nelse:\n    from agent import Agent\n\nagent = Agent(action_size)\nevaluation_reward = deque(maxlen=evaluation_reward_length)\nframe = 0\nmemory_size = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-06T01:39:48.653294Z","iopub.execute_input":"2024-05-06T01:39:48.653911Z","iopub.status.idle":"2024-05-06T01:39:50.987169Z","shell.execute_reply.started":"2024-05-06T01:39:48.653881Z","shell.execute_reply":"2024-05-06T01:39:50.986262Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Main Training Loop","metadata":{}},{"cell_type":"markdown","source":"In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\"","metadata":{}},{"cell_type":"code","source":"import os\n\n# Create the directory for saving graphs if it does not exist\nif not os.path.exists(\"./save_graph\"):\n    os.makedirs(\"./save_graph\")\n    \nif not os.path.exists(\"./save_model\"):\n    os.makedirs(\"./save_model\")\n\nrewards, episodes = [], []\nbest_eval_reward = 0\nfor e in range(EPISODES):\n    done = False\n    score = 0\n\n    history = np.zeros([5, 84, 84], dtype=np.uint8)\n    step = 0\n    state, _ = env.reset()\n    next_state = state\n    life = number_lives\n\n    get_init_state(history, state, HISTORY_SIZE)\n\n    while not done:\n        step += 1\n        frame += 1\n\n        # Perform a fire action if ball is no longer on screen to continue onto next life\n        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n            action = torch.tensor([[0]]).cuda()\n        else:\n            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n        state = next_state\n        next_state, reward, done, _, info = env.step(action + 1)\n        \n        frame_next_state = get_frame(next_state)\n        history[4, :, :] = frame_next_state\n        terminal_state = check_live(life, info['lives'])\n\n        life = info['lives']\n        r = reward\n\n        # Store the transition in memory \n        agent.memory.push(deepcopy(frame_next_state), action.cpu(), r, terminal_state)\n        # Start training after random sample generation\n        if(frame >= train_frame): # You can set train_frame to a lower value while testing your starts training earlier\n            agent.train_policy_net(frame)\n            # Update the target network only for Double DQN only\n            if double_dqn and (frame % update_target_network_frequency)== 0:\n                agent.update_target_net()\n        score += reward\n        history[:4, :, :] = history[1:, :, :]\n            \n        if done:\n            evaluation_reward.append(score)\n            rewards.append(np.mean(evaluation_reward))\n            episodes.append(e)\n            pylab.plot(episodes, rewards, 'b')\n            pylab.xlabel('Episodes')\n            pylab.ylabel('Rewards') \n            pylab.title('Episodes vs Reward')\n            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n            \n            # every episode, plot the play time\n            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n\n            # if the mean of scores of last 100 episode is bigger than 5 save model\n            ### Change this save condition to whatever you prefer ###\n            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n                best_eval_reward = np.mean(evaluation_reward)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-06T01:39:53.762090Z","iopub.execute_input":"2024-05-06T01:39:53.763012Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"episode: 0   score: 2.0   memory length: 198   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 2.0\nepisode: 1   score: 3.0   memory length: 441   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 2.5\nepisode: 2   score: 1.0   memory length: 610   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 2.0\nepisode: 3   score: 0.0   memory length: 732   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\nepisode: 4   score: 2.0   memory length: 948   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.6\nepisode: 5   score: 0.0   memory length: 1071   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3333333333333333\nepisode: 6   score: 2.0   memory length: 1289   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4285714285714286\nepisode: 7   score: 7.0   memory length: 1690   epsilon: 1.0    steps: 401    lr: 0.0001     evaluation reward: 2.125\nepisode: 8   score: 0.0   memory length: 1813   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8888888888888888\nepisode: 9   score: 0.0   memory length: 1935   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7\nepisode: 10   score: 1.0   memory length: 2104   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6363636363636365\nepisode: 11   score: 3.0   memory length: 2370   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.75\nepisode: 12   score: 3.0   memory length: 2616   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.8461538461538463\nepisode: 13   score: 0.0   memory length: 2739   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7142857142857142\nepisode: 14   score: 2.0   memory length: 2962   epsilon: 1.0    steps: 223    lr: 0.0001     evaluation reward: 1.7333333333333334\nepisode: 15   score: 1.0   memory length: 3131   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6875\nepisode: 16   score: 0.0   memory length: 3253   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.588235294117647\nepisode: 17   score: 1.0   memory length: 3422   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5555555555555556\nepisode: 18   score: 1.0   memory length: 3590   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.5263157894736843\nepisode: 19   score: 3.0   memory length: 3837   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.6\nepisode: 20   score: 1.0   memory length: 4006   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5714285714285714\nepisode: 21   score: 1.0   memory length: 4157   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5454545454545454\nepisode: 22   score: 2.0   memory length: 4355   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.565217391304348\nepisode: 23   score: 2.0   memory length: 4553   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5833333333333333\nepisode: 24   score: 3.0   memory length: 4817   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.64\nepisode: 25   score: 1.0   memory length: 4987   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6153846153846154\nepisode: 26   score: 0.0   memory length: 5110   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5555555555555556\nepisode: 27   score: 0.0   memory length: 5233   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 28   score: 0.0   memory length: 5356   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4482758620689655\nepisode: 29   score: 4.0   memory length: 5634   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.5333333333333334\nepisode: 30   score: 1.0   memory length: 5805   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5161290322580645\nepisode: 31   score: 3.0   memory length: 6054   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.5625\nepisode: 32   score: 0.0   memory length: 6177   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5151515151515151\nepisode: 33   score: 2.0   memory length: 6375   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5294117647058822\nepisode: 34   score: 2.0   memory length: 6573   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.542857142857143\nepisode: 35   score: 0.0   memory length: 6696   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 36   score: 2.0   memory length: 6912   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.5135135135135136\nepisode: 37   score: 0.0   memory length: 7034   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4736842105263157\nepisode: 38   score: 2.0   memory length: 7253   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4871794871794872\nepisode: 39   score: 1.0   memory length: 7421   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.475\nepisode: 40   score: 0.0   memory length: 7544   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4390243902439024\nepisode: 41   score: 1.0   memory length: 7695   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4285714285714286\nepisode: 42   score: 0.0   memory length: 7818   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3953488372093024\nepisode: 43   score: 3.0   memory length: 8065   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.4318181818181819\nepisode: 44   score: 2.0   memory length: 8245   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.4444444444444444\nepisode: 45   score: 2.0   memory length: 8443   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4565217391304348\nepisode: 46   score: 0.0   memory length: 8566   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.425531914893617\nepisode: 47   score: 2.0   memory length: 8783   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.4375\nepisode: 48   score: 0.0   memory length: 8906   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4081632653061225\nepisode: 49   score: 0.0   memory length: 9029   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\nepisode: 50   score: 1.0   memory length: 9180   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.3725490196078431\nepisode: 51   score: 2.0   memory length: 9378   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.3846153846153846\nepisode: 52   score: 5.0   memory length: 9722   epsilon: 1.0    steps: 344    lr: 0.0001     evaluation reward: 1.4528301886792452\nepisode: 53   score: 5.0   memory length: 10046   epsilon: 1.0    steps: 324    lr: 0.0001     evaluation reward: 1.5185185185185186\nepisode: 54   score: 1.0   memory length: 10197   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.509090909090909\nepisode: 55   score: 2.0   memory length: 10415   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5178571428571428\nepisode: 56   score: 2.0   memory length: 10617   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.5263157894736843\nepisode: 57   score: 1.0   memory length: 10788   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5172413793103448\nepisode: 58   score: 4.0   memory length: 11085   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.5593220338983051\nepisode: 59   score: 3.0   memory length: 11333   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.5833333333333333\nepisode: 60   score: 2.0   memory length: 11531   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5901639344262295\nepisode: 61   score: 2.0   memory length: 11732   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.596774193548387\nepisode: 62   score: 2.0   memory length: 11934   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.6031746031746033\nepisode: 63   score: 1.0   memory length: 12085   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.59375\nepisode: 64   score: 3.0   memory length: 12332   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.6153846153846154\nepisode: 65   score: 4.0   memory length: 12650   epsilon: 1.0    steps: 318    lr: 0.0001     evaluation reward: 1.6515151515151516\nepisode: 66   score: 3.0   memory length: 12901   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.671641791044776\nepisode: 67   score: 1.0   memory length: 13053   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.661764705882353\nepisode: 68   score: 2.0   memory length: 13251   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6666666666666667\nepisode: 69   score: 0.0   memory length: 13373   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6428571428571428\nepisode: 70   score: 0.0   memory length: 13496   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.619718309859155\nepisode: 71   score: 1.0   memory length: 13664   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6111111111111112\nepisode: 72   score: 1.0   memory length: 13833   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6027397260273972\nepisode: 73   score: 0.0   memory length: 13955   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5810810810810811\nepisode: 74   score: 1.0   memory length: 14105   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.5733333333333333\nepisode: 75   score: 2.0   memory length: 14324   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.5789473684210527\nepisode: 76   score: 0.0   memory length: 14447   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5584415584415585\nepisode: 77   score: 2.0   memory length: 14644   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.564102564102564\nepisode: 78   score: 0.0   memory length: 14766   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5443037974683544\nepisode: 79   score: 3.0   memory length: 15012   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.5625\nepisode: 80   score: 1.0   memory length: 15184   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.5555555555555556\nepisode: 81   score: 0.0   memory length: 15307   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5365853658536586\nepisode: 82   score: 1.0   memory length: 15478   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5301204819277108\nepisode: 83   score: 0.0   memory length: 15601   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5119047619047619\nepisode: 84   score: 2.0   memory length: 15818   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.5176470588235293\nepisode: 85   score: 0.0   memory length: 15941   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 86   score: 0.0   memory length: 16063   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4827586206896552\nepisode: 87   score: 1.0   memory length: 16214   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4772727272727273\nepisode: 88   score: 2.0   memory length: 16412   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4831460674157304\nepisode: 89   score: 3.0   memory length: 16657   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.5\nepisode: 90   score: 0.0   memory length: 16779   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4835164835164836\nepisode: 91   score: 2.0   memory length: 16977   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4891304347826086\nepisode: 92   score: 2.0   memory length: 17175   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4946236559139785\nepisode: 93   score: 1.0   memory length: 17326   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4893617021276595\nepisode: 94   score: 1.0   memory length: 17479   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.4842105263157894\nepisode: 95   score: 1.0   memory length: 17631   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4791666666666667\nepisode: 96   score: 0.0   memory length: 17753   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4639175257731958\nepisode: 97   score: 0.0   memory length: 17876   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4489795918367347\nepisode: 98   score: 2.0   memory length: 18074   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4545454545454546\nepisode: 99   score: 2.0   memory length: 18273   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.46\nepisode: 100   score: 3.0   memory length: 18520   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.47\nepisode: 101   score: 1.0   memory length: 18689   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\nepisode: 102   score: 1.0   memory length: 18840   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.45\nepisode: 103   score: 5.0   memory length: 19185   epsilon: 1.0    steps: 345    lr: 0.0001     evaluation reward: 1.5\nepisode: 104   score: 1.0   memory length: 19335   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.49\nepisode: 105   score: 1.0   memory length: 19506   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5\nepisode: 106   score: 1.0   memory length: 19675   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 107   score: 0.0   memory length: 19798   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 108   score: 1.0   memory length: 19949   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.43\nepisode: 109   score: 0.0   memory length: 20072   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 110   score: 5.0   memory length: 20417   epsilon: 1.0    steps: 345    lr: 0.0001     evaluation reward: 1.47\nepisode: 111   score: 1.0   memory length: 20568   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.45\nepisode: 112   score: 5.0   memory length: 20874   epsilon: 1.0    steps: 306    lr: 0.0001     evaluation reward: 1.47\nepisode: 113   score: 3.0   memory length: 21100   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.5\nepisode: 114   score: 2.0   memory length: 21280   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.5\nepisode: 115   score: 0.0   memory length: 21402   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.49\nepisode: 116   score: 4.0   memory length: 21689   epsilon: 1.0    steps: 287    lr: 0.0001     evaluation reward: 1.53\nepisode: 117   score: 4.0   memory length: 21967   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.56\nepisode: 118   score: 7.0   memory length: 22385   epsilon: 1.0    steps: 418    lr: 0.0001     evaluation reward: 1.62\nepisode: 119   score: 2.0   memory length: 22605   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.61\nepisode: 120   score: 0.0   memory length: 22728   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 121   score: 0.0   memory length: 22851   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 122   score: 3.0   memory length: 23077   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.6\nepisode: 123   score: 2.0   memory length: 23277   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.6\nepisode: 124   score: 1.0   memory length: 23446   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.58\nepisode: 125   score: 1.0   memory length: 23616   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.58\nepisode: 126   score: 1.0   memory length: 23784   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.59\nepisode: 127   score: 2.0   memory length: 24002   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.61\nepisode: 128   score: 3.0   memory length: 24251   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.64\nepisode: 129   score: 0.0   memory length: 24373   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 130   score: 0.0   memory length: 24496   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 131   score: 1.0   memory length: 24665   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\nepisode: 132   score: 2.0   memory length: 24862   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.59\nepisode: 133   score: 2.0   memory length: 25047   epsilon: 1.0    steps: 185    lr: 0.0001     evaluation reward: 1.59\nepisode: 134   score: 2.0   memory length: 25248   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.59\nepisode: 135   score: 1.0   memory length: 25416   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6\nepisode: 136   score: 1.0   memory length: 25566   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.59\nepisode: 137   score: 2.0   memory length: 25764   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.61\nepisode: 138   score: 2.0   memory length: 25984   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.61\nepisode: 139   score: 1.0   memory length: 26155   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.61\nepisode: 140   score: 0.0   memory length: 26278   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 141   score: 1.0   memory length: 26449   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.61\nepisode: 142   score: 2.0   memory length: 26667   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.63\nepisode: 143   score: 1.0   memory length: 26818   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.61\nepisode: 144   score: 0.0   memory length: 26941   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 145   score: 0.0   memory length: 27064   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\nepisode: 146   score: 1.0   memory length: 27215   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 147   score: 0.0   memory length: 27338   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\nepisode: 148   score: 2.0   memory length: 27556   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.58\nepisode: 149   score: 1.0   memory length: 27724   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.59\nepisode: 150   score: 0.0   memory length: 27846   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 151   score: 1.0   memory length: 28015   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\nepisode: 152   score: 2.0   memory length: 28236   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.54\nepisode: 153   score: 0.0   memory length: 28358   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.49\nepisode: 154   score: 2.0   memory length: 28555   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5\nepisode: 155   score: 2.0   memory length: 28773   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5\nepisode: 156   score: 2.0   memory length: 28952   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.5\nepisode: 157   score: 2.0   memory length: 29170   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.51\nepisode: 158   score: 3.0   memory length: 29436   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.5\nepisode: 159   score: 2.0   memory length: 29633   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.49\nepisode: 160   score: 3.0   memory length: 29879   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.5\nepisode: 161   score: 0.0   memory length: 30001   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\nepisode: 162   score: 2.0   memory length: 30198   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.48\nepisode: 163   score: 0.0   memory length: 30321   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\nepisode: 164   score: 0.0   memory length: 30443   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\nepisode: 165   score: 2.0   memory length: 30644   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.42\nepisode: 166   score: 1.0   memory length: 30796   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\nepisode: 167   score: 2.0   memory length: 30994   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\nepisode: 168   score: 1.0   memory length: 31145   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\nepisode: 169   score: 1.0   memory length: 31314   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\nepisode: 170   score: 0.0   memory length: 31437   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 171   score: 1.0   memory length: 31589   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.41\nepisode: 172   score: 1.0   memory length: 31760   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.41\nepisode: 173   score: 0.0   memory length: 31883   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 174   score: 4.0   memory length: 32177   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.44\nepisode: 175   score: 1.0   memory length: 32327   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.43\nepisode: 176   score: 2.0   memory length: 32524   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.45\nepisode: 177   score: 0.0   memory length: 32647   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 178   score: 0.0   memory length: 32770   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 179   score: 3.0   memory length: 33034   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.43\nepisode: 180   score: 1.0   memory length: 33184   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.43\nepisode: 181   score: 1.0   memory length: 33353   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\nepisode: 182   score: 2.0   memory length: 33551   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.45\nepisode: 183   score: 1.0   memory length: 33720   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\nepisode: 184   score: 2.0   memory length: 33918   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.46\nepisode: 185   score: 0.0   memory length: 34040   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.46\nepisode: 186   score: 0.0   memory length: 34163   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 187   score: 1.0   memory length: 34332   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\nepisode: 188   score: 2.0   memory length: 34529   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.46\nepisode: 189   score: 4.0   memory length: 34846   epsilon: 1.0    steps: 317    lr: 0.0001     evaluation reward: 1.47\nepisode: 190   score: 2.0   memory length: 35044   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\nepisode: 191   score: 0.0   memory length: 35167   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\nepisode: 192   score: 1.0   memory length: 35336   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.46\nepisode: 193   score: 1.0   memory length: 35506   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.46\nepisode: 194   score: 2.0   memory length: 35703   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.47\nepisode: 195   score: 0.0   memory length: 35826   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 196   score: 2.0   memory length: 36024   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.48\nepisode: 197   score: 3.0   memory length: 36288   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.51\nepisode: 198   score: 0.0   memory length: 36411   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 199   score: 2.0   memory length: 36629   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.49\nepisode: 200   score: 2.0   memory length: 36848   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.48\nepisode: 201   score: 2.0   memory length: 37065   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.49\nepisode: 202   score: 1.0   memory length: 37235   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.49\nepisode: 203   score: 3.0   memory length: 37460   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.47\nepisode: 204   score: 2.0   memory length: 37681   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.48\nepisode: 205   score: 3.0   memory length: 37909   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.5\nepisode: 206   score: 1.0   memory length: 38080   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5\nepisode: 207   score: 1.0   memory length: 38249   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.51\nepisode: 208   score: 0.0   memory length: 38372   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 209   score: 3.0   memory length: 38620   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.53\nepisode: 210   score: 0.0   memory length: 38743   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 211   score: 1.0   memory length: 38893   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.48\nepisode: 212   score: 0.0   memory length: 39015   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\nepisode: 213   score: 1.0   memory length: 39186   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.41\nepisode: 214   score: 5.0   memory length: 39474   epsilon: 1.0    steps: 288    lr: 0.0001     evaluation reward: 1.44\nepisode: 215   score: 0.0   memory length: 39597   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 216   score: 2.0   memory length: 39795   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.42\nepisode: 217   score: 0.0   memory length: 39918   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\nepisode: 218   score: 0.0   memory length: 40041   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\nepisode: 219   score: 0.0   memory length: 40163   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.29\nepisode: 220   score: 2.0   memory length: 40362   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.31\nepisode: 221   score: 0.0   memory length: 40485   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\nepisode: 222   score: 2.0   memory length: 40683   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.3\nepisode: 223   score: 1.0   memory length: 40851   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.29\nepisode: 224   score: 2.0   memory length: 41067   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.3\nepisode: 225   score: 2.0   memory length: 41265   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.31\nepisode: 226   score: 3.0   memory length: 41491   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.33\nepisode: 227   score: 0.0   memory length: 41613   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.31\nepisode: 228   score: 3.0   memory length: 41859   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.31\nepisode: 229   score: 5.0   memory length: 42211   epsilon: 1.0    steps: 352    lr: 0.0001     evaluation reward: 1.36\nepisode: 230   score: 3.0   memory length: 42458   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.39\nepisode: 231   score: 2.0   memory length: 42655   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.4\nepisode: 232   score: 1.0   memory length: 42806   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.39\nepisode: 233   score: 1.0   memory length: 42975   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.38\nepisode: 234   score: 2.0   memory length: 43173   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\nepisode: 235   score: 0.0   memory length: 43295   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.37\nepisode: 236   score: 2.0   memory length: 43493   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\nepisode: 237   score: 5.0   memory length: 43811   epsilon: 1.0    steps: 318    lr: 0.0001     evaluation reward: 1.41\nepisode: 238   score: 3.0   memory length: 44060   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.42\nepisode: 239   score: 2.0   memory length: 44278   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.43\nepisode: 240   score: 4.0   memory length: 44538   epsilon: 1.0    steps: 260    lr: 0.0001     evaluation reward: 1.47\nepisode: 241   score: 4.0   memory length: 44797   epsilon: 1.0    steps: 259    lr: 0.0001     evaluation reward: 1.5\nepisode: 242   score: 1.0   memory length: 44948   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 243   score: 0.0   memory length: 45071   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 244   score: 0.0   memory length: 45194   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 245   score: 0.0   memory length: 45317   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 246   score: 1.0   memory length: 45468   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.48\nepisode: 247   score: 3.0   memory length: 45713   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.51\nepisode: 248   score: 2.0   memory length: 45931   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.51\nepisode: 249   score: 1.0   memory length: 46103   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.51\nepisode: 250   score: 0.0   memory length: 46226   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 251   score: 0.0   memory length: 46348   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\nepisode: 252   score: 0.0   memory length: 46471   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 253   score: 1.0   memory length: 46640   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 254   score: 3.0   memory length: 46911   epsilon: 1.0    steps: 271    lr: 0.0001     evaluation reward: 1.5\nepisode: 255   score: 0.0   memory length: 47033   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\nepisode: 256   score: 1.0   memory length: 47184   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.47\nepisode: 257   score: 1.0   memory length: 47354   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.46\nepisode: 258   score: 0.0   memory length: 47477   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 259   score: 1.0   memory length: 47627   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.42\nepisode: 260   score: 2.0   memory length: 47845   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.41\nepisode: 261   score: 3.0   memory length: 48108   epsilon: 1.0    steps: 263    lr: 0.0001     evaluation reward: 1.44\nepisode: 262   score: 0.0   memory length: 48231   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 263   score: 2.0   memory length: 48429   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\nepisode: 264   score: 1.0   memory length: 48597   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.45\nepisode: 265   score: 2.0   memory length: 48781   epsilon: 1.0    steps: 184    lr: 0.0001     evaluation reward: 1.45\nepisode: 266   score: 0.0   memory length: 48903   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\nepisode: 267   score: 3.0   memory length: 49155   epsilon: 1.0    steps: 252    lr: 0.0001     evaluation reward: 1.45\nepisode: 268   score: 1.0   memory length: 49306   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.45\nepisode: 269   score: 0.0   memory length: 49428   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\nepisode: 270   score: 1.0   memory length: 49596   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.45\nepisode: 271   score: 0.0   memory length: 49718   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\nepisode: 272   score: 0.0   memory length: 49841   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 273   score: 3.0   memory length: 50072   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.46\nepisode: 274   score: 2.0   memory length: 50291   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.44\nepisode: 275   score: 2.0   memory length: 50509   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.45\nepisode: 276   score: 0.0   memory length: 50632   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 277   score: 2.0   memory length: 50832   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.45\nepisode: 278   score: 0.0   memory length: 50955   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 279   score: 0.0   memory length: 51078   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 280   score: 2.0   memory length: 51294   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.43\nepisode: 281   score: 7.0   memory length: 51578   epsilon: 1.0    steps: 284    lr: 0.0001     evaluation reward: 1.49\nepisode: 282   score: 2.0   memory length: 51797   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.49\nepisode: 283   score: 0.0   memory length: 51920   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 284   score: 2.0   memory length: 52118   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.48\nepisode: 285   score: 2.0   memory length: 52336   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5\nepisode: 286   score: 0.0   memory length: 52459   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 287   score: 5.0   memory length: 52781   epsilon: 1.0    steps: 322    lr: 0.0001     evaluation reward: 1.54\nepisode: 288   score: 0.0   memory length: 52903   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\nepisode: 289   score: 2.0   memory length: 53101   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\nepisode: 290   score: 0.0   memory length: 53223   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\nepisode: 291   score: 2.0   memory length: 53423   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.5\nepisode: 292   score: 2.0   memory length: 53623   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.51\nepisode: 293   score: 3.0   memory length: 53848   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.53\nepisode: 294   score: 3.0   memory length: 54092   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.54\nepisode: 295   score: 1.0   memory length: 54243   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.55\nepisode: 296   score: 0.0   memory length: 54365   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\nepisode: 297   score: 6.0   memory length: 54723   epsilon: 1.0    steps: 358    lr: 0.0001     evaluation reward: 1.56\nepisode: 298   score: 0.0   memory length: 54846   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\nepisode: 299   score: 3.0   memory length: 55071   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.57\nepisode: 300   score: 4.0   memory length: 55345   epsilon: 1.0    steps: 274    lr: 0.0001     evaluation reward: 1.59\nepisode: 301   score: 1.0   memory length: 55514   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.58\nepisode: 302   score: 4.0   memory length: 55812   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.61\nepisode: 303   score: 1.0   memory length: 55981   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59\nepisode: 304   score: 1.0   memory length: 56150   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.58\nepisode: 305   score: 0.0   memory length: 56273   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\nepisode: 306   score: 2.0   memory length: 56470   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.56\nepisode: 307   score: 3.0   memory length: 56696   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.58\nepisode: 308   score: 0.0   memory length: 56818   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 309   score: 1.0   memory length: 56971   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.56\nepisode: 310   score: 0.0   memory length: 57093   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.56\nepisode: 311   score: 3.0   memory length: 57359   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.58\nepisode: 312   score: 0.0   memory length: 57482   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\nepisode: 313   score: 1.0   memory length: 57633   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 314   score: 0.0   memory length: 57756   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 315   score: 0.0   memory length: 57878   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\nepisode: 316   score: 2.0   memory length: 58077   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.53\nepisode: 317   score: 2.0   memory length: 58275   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.55\nepisode: 318   score: 3.0   memory length: 58521   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.58\nepisode: 319   score: 2.0   memory length: 58703   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.6\nepisode: 320   score: 3.0   memory length: 58930   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.61\nepisode: 321   score: 4.0   memory length: 59216   epsilon: 1.0    steps: 286    lr: 0.0001     evaluation reward: 1.65\nepisode: 322   score: 2.0   memory length: 59414   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.65\nepisode: 323   score: 3.0   memory length: 59639   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.67\nepisode: 324   score: 1.0   memory length: 59790   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.66\nepisode: 325   score: 0.0   memory length: 59912   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.64\nepisode: 326   score: 2.0   memory length: 60110   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.63\nepisode: 327   score: 3.0   memory length: 60357   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.66\nepisode: 328   score: 2.0   memory length: 60555   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.65\nepisode: 329   score: 3.0   memory length: 60822   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.63\nepisode: 330   score: 0.0   memory length: 60945   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 331   score: 1.0   memory length: 61113   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.59\nepisode: 332   score: 3.0   memory length: 61359   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.61\nepisode: 333   score: 0.0   memory length: 61482   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 334   score: 1.0   memory length: 61651   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59\nepisode: 335   score: 3.0   memory length: 61918   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.62\nepisode: 336   score: 1.0   memory length: 62069   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.61\nepisode: 337   score: 0.0   memory length: 62192   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\nepisode: 338   score: 0.0   memory length: 62315   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 339   score: 2.0   memory length: 62533   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.53\nepisode: 340   score: 2.0   memory length: 62730   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.51\nepisode: 341   score: 1.0   memory length: 62899   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\nepisode: 342   score: 1.0   memory length: 63068   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\nepisode: 343   score: 2.0   memory length: 63266   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\nepisode: 344   score: 3.0   memory length: 63516   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.53\nepisode: 345   score: 3.0   memory length: 63764   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.56\nepisode: 346   score: 1.0   memory length: 63933   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.56\nepisode: 347   score: 2.0   memory length: 64154   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.55\nepisode: 348   score: 0.0   memory length: 64277   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 349   score: 2.0   memory length: 64474   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.54\nepisode: 350   score: 2.0   memory length: 64692   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.56\nepisode: 351   score: 3.0   memory length: 64937   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.59\nepisode: 352   score: 1.0   memory length: 65088   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6\nepisode: 353   score: 2.0   memory length: 65306   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.61\nepisode: 354   score: 2.0   memory length: 65523   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.6\nepisode: 355   score: 1.0   memory length: 65691   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.61\nepisode: 356   score: 3.0   memory length: 65939   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.63\nepisode: 357   score: 3.0   memory length: 66167   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.65\nepisode: 358   score: 0.0   memory length: 66290   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\nepisode: 359   score: 2.0   memory length: 66506   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.66\nepisode: 360   score: 1.0   memory length: 66674   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.65\nepisode: 361   score: 2.0   memory length: 66892   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.64\nepisode: 362   score: 0.0   memory length: 67014   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.64\nepisode: 363   score: 0.0   memory length: 67136   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.62\nepisode: 364   score: 1.0   memory length: 67307   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.62\nepisode: 365   score: 1.0   memory length: 67457   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.61\nepisode: 366   score: 1.0   memory length: 67626   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.62\nepisode: 367   score: 0.0   memory length: 67749   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 368   score: 2.0   memory length: 67966   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.6\nepisode: 369   score: 1.0   memory length: 68135   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.61\nepisode: 370   score: 1.0   memory length: 68304   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.61\nepisode: 371   score: 0.0   memory length: 68426   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.61\nepisode: 372   score: 2.0   memory length: 68626   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.63\nepisode: 373   score: 1.0   memory length: 68797   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.61\nepisode: 374   score: 3.0   memory length: 69043   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.62\nepisode: 375   score: 0.0   memory length: 69166   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\nepisode: 376   score: 3.0   memory length: 69394   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.63\nepisode: 377   score: 0.0   memory length: 69517   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 378   score: 1.0   memory length: 69685   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.62\nepisode: 379   score: 1.0   memory length: 69836   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.63\nepisode: 380   score: 2.0   memory length: 70033   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.63\nepisode: 381   score: 1.0   memory length: 70186   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.57\nepisode: 382   score: 2.0   memory length: 70406   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.57\nepisode: 383   score: 0.0   memory length: 70529   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\nepisode: 384   score: 1.0   memory length: 70680   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.56\nepisode: 385   score: 2.0   memory length: 70898   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.56\nepisode: 386   score: 3.0   memory length: 71145   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.59\nepisode: 387   score: 0.0   memory length: 71268   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\nepisode: 388   score: 1.0   memory length: 71438   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.55\nepisode: 389   score: 3.0   memory length: 71683   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.56\nepisode: 390   score: 1.0   memory length: 71834   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.57\nepisode: 391   score: 2.0   memory length: 72032   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.57\nepisode: 392   score: 1.0   memory length: 72201   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.56\nepisode: 393   score: 0.0   memory length: 72323   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.53\nepisode: 394   score: 0.0   memory length: 72446   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 395   score: 3.0   memory length: 72716   epsilon: 1.0    steps: 270    lr: 0.0001     evaluation reward: 1.52\nepisode: 396   score: 1.0   memory length: 72887   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.53\nepisode: 397   score: 1.0   memory length: 73056   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\nepisode: 398   score: 2.0   memory length: 73253   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5\nepisode: 399   score: 1.0   memory length: 73421   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.48\nepisode: 400   score: 0.0   memory length: 73544   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 401   score: 2.0   memory length: 73723   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.45\nepisode: 402   score: 4.0   memory length: 74041   epsilon: 1.0    steps: 318    lr: 0.0001     evaluation reward: 1.45\nepisode: 403   score: 0.0   memory length: 74164   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 404   score: 0.0   memory length: 74286   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\nepisode: 405   score: 0.0   memory length: 74409   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\nepisode: 406   score: 0.0   memory length: 74532   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 407   score: 2.0   memory length: 74750   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4\nepisode: 408   score: 0.0   memory length: 74872   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\nepisode: 409   score: 1.0   memory length: 75022   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.4\nepisode: 410   score: 1.0   memory length: 75191   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\nepisode: 411   score: 1.0   memory length: 75342   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.39\nepisode: 412   score: 0.0   memory length: 75465   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 413   score: 3.0   memory length: 75714   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.41\nepisode: 414   score: 0.0   memory length: 75837   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 415   score: 1.0   memory length: 76006   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\nepisode: 416   score: 4.0   memory length: 76281   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.44\nepisode: 417   score: 0.0   memory length: 76403   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 418   score: 1.0   memory length: 76572   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4\nepisode: 419   score: 2.0   memory length: 76791   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4\nepisode: 420   score: 2.0   memory length: 77008   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.39\nepisode: 421   score: 1.0   memory length: 77180   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.36\nepisode: 422   score: 1.0   memory length: 77351   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.35\nepisode: 423   score: 0.0   memory length: 77474   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\nepisode: 424   score: 2.0   memory length: 77694   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.33\nepisode: 425   score: 3.0   memory length: 77940   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.36\nepisode: 426   score: 0.0   memory length: 78063   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\nepisode: 427   score: 0.0   memory length: 78185   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.31\nepisode: 428   score: 0.0   memory length: 78308   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.29\nepisode: 429   score: 1.0   memory length: 78476   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.27\nepisode: 430   score: 1.0   memory length: 78644   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.28\nepisode: 431   score: 1.0   memory length: 78813   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.28\nepisode: 432   score: 2.0   memory length: 79014   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.27\nepisode: 433   score: 2.0   memory length: 79212   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.29\nepisode: 434   score: 0.0   memory length: 79335   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.28\nepisode: 435   score: 2.0   memory length: 79538   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.27\nepisode: 436   score: 2.0   memory length: 79756   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.28\nepisode: 437   score: 0.0   memory length: 79878   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.28\nepisode: 438   score: 2.0   memory length: 80076   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.3\nepisode: 439   score: 0.0   memory length: 80199   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.28\nepisode: 440   score: 0.0   memory length: 80322   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.26\nepisode: 441   score: 1.0   memory length: 80490   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.26\nepisode: 442   score: 0.0   memory length: 80612   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.25\nepisode: 443   score: 1.0   memory length: 80763   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.24\nepisode: 444   score: 0.0   memory length: 80886   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.21\nepisode: 445   score: 0.0   memory length: 81009   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.18\nepisode: 446   score: 2.0   memory length: 81206   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.19\nepisode: 447   score: 2.0   memory length: 81404   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.19\nepisode: 448   score: 1.0   memory length: 81555   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.2\nepisode: 449   score: 0.0   memory length: 81677   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.18\nepisode: 450   score: 4.0   memory length: 81955   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.2\nepisode: 451   score: 3.0   memory length: 82221   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.2\nepisode: 452   score: 2.0   memory length: 82418   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.21\nepisode: 453   score: 0.0   memory length: 82540   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.19\nepisode: 454   score: 4.0   memory length: 82856   epsilon: 1.0    steps: 316    lr: 0.0001     evaluation reward: 1.21\nepisode: 455   score: 3.0   memory length: 83103   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.23\nepisode: 456   score: 3.0   memory length: 83371   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.23\nepisode: 457   score: 1.0   memory length: 83523   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.21\nepisode: 458   score: 4.0   memory length: 83820   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.25\nepisode: 459   score: 0.0   memory length: 83942   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.23\nepisode: 460   score: 3.0   memory length: 84169   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.25\nepisode: 461   score: 2.0   memory length: 84386   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.25\nepisode: 462   score: 2.0   memory length: 84603   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.27\nepisode: 463   score: 1.0   memory length: 84772   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.28\nepisode: 464   score: 2.0   memory length: 84970   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.29\nepisode: 465   score: 0.0   memory length: 85092   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.28\nepisode: 466   score: 2.0   memory length: 85289   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.29\nepisode: 467   score: 2.0   memory length: 85472   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.31\nepisode: 468   score: 2.0   memory length: 85669   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.31\nepisode: 469   score: 4.0   memory length: 85961   epsilon: 1.0    steps: 292    lr: 0.0001     evaluation reward: 1.34\nepisode: 470   score: 0.0   memory length: 86083   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.33\nepisode: 471   score: 0.0   memory length: 86206   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\nepisode: 472   score: 1.0   memory length: 86356   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.32\nepisode: 473   score: 1.0   memory length: 86506   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.32\nepisode: 474   score: 1.0   memory length: 86675   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.3\nepisode: 475   score: 2.0   memory length: 86893   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.32\nepisode: 476   score: 3.0   memory length: 87139   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.32\nepisode: 477   score: 2.0   memory length: 87336   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.34\nepisode: 478   score: 1.0   memory length: 87487   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.34\nepisode: 479   score: 2.0   memory length: 87685   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.35\nepisode: 480   score: 2.0   memory length: 87883   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.35\nepisode: 481   score: 4.0   memory length: 88160   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.38\nepisode: 482   score: 2.0   memory length: 88377   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.38\nepisode: 483   score: 0.0   memory length: 88500   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\nepisode: 484   score: 3.0   memory length: 88728   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.4\nepisode: 485   score: 1.0   memory length: 88878   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.39\nepisode: 486   score: 4.0   memory length: 89197   epsilon: 1.0    steps: 319    lr: 0.0001     evaluation reward: 1.4\nepisode: 487   score: 3.0   memory length: 89462   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.43\nepisode: 488   score: 1.0   memory length: 89633   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.43\nepisode: 489   score: 1.0   memory length: 89802   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\nepisode: 490   score: 0.0   memory length: 89925   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 491   score: 2.0   memory length: 90142   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.4\nepisode: 492   score: 3.0   memory length: 90389   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.42\nepisode: 493   score: 0.0   memory length: 90511   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 494   score: 1.0   memory length: 90661   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.43\nepisode: 495   score: 2.0   memory length: 90879   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.42\nepisode: 496   score: 1.0   memory length: 91047   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.42\nepisode: 497   score: 2.0   memory length: 91267   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.43\nepisode: 498   score: 1.0   memory length: 91435   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.42\nepisode: 499   score: 1.0   memory length: 91604   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\nepisode: 500   score: 1.0   memory length: 91775   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.43\nepisode: 501   score: 1.0   memory length: 91926   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\nepisode: 502   score: 0.0   memory length: 92049   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\nepisode: 503   score: 2.0   memory length: 92268   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4\nepisode: 504   score: 1.0   memory length: 92438   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.41\nepisode: 505   score: 6.0   memory length: 92821   epsilon: 1.0    steps: 383    lr: 0.0001     evaluation reward: 1.47\nepisode: 506   score: 2.0   memory length: 93005   epsilon: 1.0    steps: 184    lr: 0.0001     evaluation reward: 1.49\nepisode: 507   score: 0.0   memory length: 93128   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\nepisode: 508   score: 1.0   memory length: 93297   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\nepisode: 509   score: 1.0   memory length: 93469   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.48\nepisode: 510   score: 1.0   memory length: 93621   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.48\nepisode: 511   score: 2.0   memory length: 93819   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\nepisode: 512   score: 1.0   memory length: 93988   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\nepisode: 513   score: 0.0   memory length: 94111   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\nepisode: 514   score: 0.0   memory length: 94233   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\nepisode: 515   score: 2.0   memory length: 94431   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.48\nepisode: 516   score: 0.0   memory length: 94554   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 517   score: 3.0   memory length: 94780   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.47\nepisode: 518   score: 0.0   memory length: 94902   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.46\nepisode: 519   score: 2.0   memory length: 95120   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.46\nepisode: 520   score: 0.0   memory length: 95243   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 521   score: 2.0   memory length: 95440   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.45\nepisode: 522   score: 1.0   memory length: 95608   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.45\nepisode: 523   score: 3.0   memory length: 95852   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.48\nepisode: 524   score: 0.0   memory length: 95975   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 525   score: 1.0   memory length: 96144   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\nepisode: 526   score: 0.0   memory length: 96266   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\nepisode: 527   score: 0.0   memory length: 96389   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 528   score: 2.0   memory length: 96589   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.46\nepisode: 529   score: 0.0   memory length: 96712   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 530   score: 2.0   memory length: 96931   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.46\nepisode: 531   score: 0.0   memory length: 97054   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 532   score: 1.0   memory length: 97224   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.44\nepisode: 533   score: 0.0   memory length: 97347   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 534   score: 1.0   memory length: 97515   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.43\nepisode: 535   score: 2.0   memory length: 97712   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.43\nepisode: 536   score: 2.0   memory length: 97928   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.43\nepisode: 537   score: 0.0   memory length: 98050   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\nepisode: 538   score: 1.0   memory length: 98219   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\nepisode: 539   score: 1.0   memory length: 98369   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.43\nepisode: 540   score: 3.0   memory length: 98618   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.46\nepisode: 541   score: 3.0   memory length: 98866   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.48\nepisode: 542   score: 2.0   memory length: 99084   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5\nepisode: 543   score: 1.0   memory length: 99252   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.5\nepisode: 544   score: 2.0   memory length: 99450   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\nepisode: 545   score: 1.0   memory length: 99603   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.53\nepisode: 546   score: 0.0   memory length: 99726   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 547   score: 1.0   memory length: 99877   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5\nepisode: 548   score: 3.0   memory length: 100148   epsilon: 0.9997049800000064    steps: 271    lr: 0.0001     evaluation reward: 1.52\nepisode: 549   score: 2.0   memory length: 100345   epsilon: 0.9993149200000149    steps: 197    lr: 0.0001     evaluation reward: 1.54\nepisode: 550   score: 2.0   memory length: 100545   epsilon: 0.9989189200000235    steps: 200    lr: 0.0001     evaluation reward: 1.52\nepisode: 551   score: 0.0   memory length: 100668   epsilon: 0.9986753800000288    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 552   score: 2.0   memory length: 100865   epsilon: 0.9982853200000372    steps: 197    lr: 0.0001     evaluation reward: 1.49\nepisode: 553   score: 0.0   memory length: 100988   epsilon: 0.9980417800000425    steps: 123    lr: 0.0001     evaluation reward: 1.49\nepisode: 554   score: 2.0   memory length: 101186   epsilon: 0.997649740000051    steps: 198    lr: 0.0001     evaluation reward: 1.47\nepisode: 555   score: 5.0   memory length: 101474   epsilon: 0.9970795000000634    steps: 288    lr: 0.0001     evaluation reward: 1.49\nepisode: 556   score: 0.0   memory length: 101597   epsilon: 0.9968359600000687    steps: 123    lr: 0.0001     evaluation reward: 1.46\nepisode: 557   score: 1.0   memory length: 101748   epsilon: 0.9965369800000752    steps: 151    lr: 0.0001     evaluation reward: 1.46\nepisode: 558   score: 0.0   memory length: 101871   epsilon: 0.9962934400000805    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 559   score: 2.0   memory length: 102093   epsilon: 0.99585388000009    steps: 222    lr: 0.0001     evaluation reward: 1.44\nepisode: 560   score: 3.0   memory length: 102321   epsilon: 0.9954024400000998    steps: 228    lr: 0.0001     evaluation reward: 1.44\nepisode: 561   score: 3.0   memory length: 102546   epsilon: 0.9949569400001095    steps: 225    lr: 0.0001     evaluation reward: 1.45\nepisode: 562   score: 1.0   memory length: 102697   epsilon: 0.994657960000116    steps: 151    lr: 0.0001     evaluation reward: 1.44\nepisode: 563   score: 0.0   memory length: 102819   epsilon: 0.9944164000001212    steps: 122    lr: 0.0001     evaluation reward: 1.43\nepisode: 564   score: 0.0   memory length: 102942   epsilon: 0.9941728600001265    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 565   score: 0.0   memory length: 103064   epsilon: 0.9939313000001317    steps: 122    lr: 0.0001     evaluation reward: 1.41\nepisode: 566   score: 2.0   memory length: 103279   epsilon: 0.993505600000141    steps: 215    lr: 0.0001     evaluation reward: 1.41\nepisode: 567   score: 3.0   memory length: 103526   epsilon: 0.9930165400001516    steps: 247    lr: 0.0001     evaluation reward: 1.42\nepisode: 568   score: 2.0   memory length: 103724   epsilon: 0.9926245000001601    steps: 198    lr: 0.0001     evaluation reward: 1.42\nepisode: 569   score: 1.0   memory length: 103895   epsilon: 0.9922859200001675    steps: 171    lr: 0.0001     evaluation reward: 1.39\nepisode: 570   score: 0.0   memory length: 104018   epsilon: 0.9920423800001728    steps: 123    lr: 0.0001     evaluation reward: 1.39\nepisode: 571   score: 1.0   memory length: 104187   epsilon: 0.99170776000018    steps: 169    lr: 0.0001     evaluation reward: 1.4\nepisode: 572   score: 4.0   memory length: 104444   epsilon: 0.9911989000001911    steps: 257    lr: 0.0001     evaluation reward: 1.43\nepisode: 573   score: 1.0   memory length: 104595   epsilon: 0.9908999200001976    steps: 151    lr: 0.0001     evaluation reward: 1.43\nepisode: 574   score: 0.0   memory length: 104718   epsilon: 0.9906563800002028    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 575   score: 4.0   memory length: 105015   epsilon: 0.9900683200002156    steps: 297    lr: 0.0001     evaluation reward: 1.44\nepisode: 576   score: 2.0   memory length: 105215   epsilon: 0.9896723200002242    steps: 200    lr: 0.0001     evaluation reward: 1.43\nepisode: 577   score: 2.0   memory length: 105412   epsilon: 0.9892822600002327    steps: 197    lr: 0.0001     evaluation reward: 1.43\nepisode: 578   score: 4.0   memory length: 105729   epsilon: 0.9886546000002463    steps: 317    lr: 0.0001     evaluation reward: 1.46\nepisode: 579   score: 4.0   memory length: 105994   epsilon: 0.9881299000002577    steps: 265    lr: 0.0001     evaluation reward: 1.48\nepisode: 580   score: 0.0   memory length: 106116   epsilon: 0.9878883400002629    steps: 122    lr: 0.0001     evaluation reward: 1.46\nepisode: 581   score: 1.0   memory length: 106267   epsilon: 0.9875893600002694    steps: 151    lr: 0.0001     evaluation reward: 1.43\nepisode: 582   score: 1.0   memory length: 106435   epsilon: 0.9872567200002766    steps: 168    lr: 0.0001     evaluation reward: 1.42\nepisode: 583   score: 0.0   memory length: 106558   epsilon: 0.9870131800002819    steps: 123    lr: 0.0001     evaluation reward: 1.42\nepisode: 584   score: 2.0   memory length: 106755   epsilon: 0.9866231200002904    steps: 197    lr: 0.0001     evaluation reward: 1.41\nepisode: 585   score: 3.0   memory length: 106981   epsilon: 0.9861756400003001    steps: 226    lr: 0.0001     evaluation reward: 1.43\nepisode: 586   score: 1.0   memory length: 107150   epsilon: 0.9858410200003074    steps: 169    lr: 0.0001     evaluation reward: 1.4\nepisode: 587   score: 2.0   memory length: 107368   epsilon: 0.9854093800003167    steps: 218    lr: 0.0001     evaluation reward: 1.39\nepisode: 588   score: 2.0   memory length: 107566   epsilon: 0.9850173400003253    steps: 198    lr: 0.0001     evaluation reward: 1.4\nepisode: 589   score: 0.0   memory length: 107688   epsilon: 0.9847757800003305    steps: 122    lr: 0.0001     evaluation reward: 1.39\nepisode: 590   score: 5.0   memory length: 108036   epsilon: 0.9840867400003455    steps: 348    lr: 0.0001     evaluation reward: 1.44\nepisode: 591   score: 3.0   memory length: 108264   epsilon: 0.9836353000003553    steps: 228    lr: 0.0001     evaluation reward: 1.45\nepisode: 592   score: 2.0   memory length: 108482   epsilon: 0.9832036600003646    steps: 218    lr: 0.0001     evaluation reward: 1.44\nepisode: 593   score: 1.0   memory length: 108633   epsilon: 0.9829046800003711    steps: 151    lr: 0.0001     evaluation reward: 1.45\nepisode: 594   score: 2.0   memory length: 108834   epsilon: 0.9825067000003798    steps: 201    lr: 0.0001     evaluation reward: 1.46\nepisode: 595   score: 2.0   memory length: 109032   epsilon: 0.9821146600003883    steps: 198    lr: 0.0001     evaluation reward: 1.46\nepisode: 596   score: 0.0   memory length: 109154   epsilon: 0.9818731000003935    steps: 122    lr: 0.0001     evaluation reward: 1.45\nepisode: 597   score: 1.0   memory length: 109305   epsilon: 0.9815741200004    steps: 151    lr: 0.0001     evaluation reward: 1.44\nepisode: 598   score: 2.0   memory length: 109502   epsilon: 0.9811840600004085    steps: 197    lr: 0.0001     evaluation reward: 1.45\nepisode: 599   score: 0.0   memory length: 109625   epsilon: 0.9809405200004138    steps: 123    lr: 0.0001     evaluation reward: 1.44\nepisode: 600   score: 0.0   memory length: 109747   epsilon: 0.980698960000419    steps: 122    lr: 0.0001     evaluation reward: 1.43\nepisode: 601   score: 3.0   memory length: 109993   epsilon: 0.9802118800004296    steps: 246    lr: 0.0001     evaluation reward: 1.45\nepisode: 602   score: 0.0   memory length: 110116   epsilon: 0.9799683400004349    steps: 123    lr: 0.0001     evaluation reward: 1.45\nepisode: 603   score: 2.0   memory length: 110297   epsilon: 0.9796099600004426    steps: 181    lr: 0.0001     evaluation reward: 1.45\nepisode: 604   score: 2.0   memory length: 110495   epsilon: 0.9792179200004512    steps: 198    lr: 0.0001     evaluation reward: 1.46\nepisode: 605   score: 2.0   memory length: 110716   epsilon: 0.9787803400004607    steps: 221    lr: 0.0001     evaluation reward: 1.42\nepisode: 606   score: 0.0   memory length: 110839   epsilon: 0.978536800000466    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 607   score: 0.0   memory length: 110962   epsilon: 0.9782932600004712    steps: 123    lr: 0.0001     evaluation reward: 1.4\nepisode: 608   score: 1.0   memory length: 111113   epsilon: 0.9779942800004777    steps: 151    lr: 0.0001     evaluation reward: 1.4\nepisode: 609   score: 1.0   memory length: 111281   epsilon: 0.9776616400004849    steps: 168    lr: 0.0001     evaluation reward: 1.4\nepisode: 610   score: 2.0   memory length: 111502   epsilon: 0.9772240600004944    steps: 221    lr: 0.0001     evaluation reward: 1.41\nepisode: 611   score: 2.0   memory length: 111682   epsilon: 0.9768676600005022    steps: 180    lr: 0.0001     evaluation reward: 1.41\nepisode: 612   score: 1.0   memory length: 111851   epsilon: 0.9765330400005094    steps: 169    lr: 0.0001     evaluation reward: 1.41\nepisode: 613   score: 1.0   memory length: 112020   epsilon: 0.9761984200005167    steps: 169    lr: 0.0001     evaluation reward: 1.42\nepisode: 614   score: 1.0   memory length: 112189   epsilon: 0.975863800000524    steps: 169    lr: 0.0001     evaluation reward: 1.43\nepisode: 615   score: 5.0   memory length: 112533   epsilon: 0.9751826800005388    steps: 344    lr: 0.0001     evaluation reward: 1.46\nepisode: 616   score: 1.0   memory length: 112684   epsilon: 0.9748837000005453    steps: 151    lr: 0.0001     evaluation reward: 1.47\nepisode: 617   score: 4.0   memory length: 112959   epsilon: 0.9743392000005571    steps: 275    lr: 0.0001     evaluation reward: 1.48\nepisode: 618   score: 4.0   memory length: 113219   epsilon: 0.9738244000005682    steps: 260    lr: 0.0001     evaluation reward: 1.52\nepisode: 619   score: 2.0   memory length: 113435   epsilon: 0.9733967200005775    steps: 216    lr: 0.0001     evaluation reward: 1.52\nepisode: 620   score: 0.0   memory length: 113558   epsilon: 0.9731531800005828    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 621   score: 2.0   memory length: 113755   epsilon: 0.9727631200005913    steps: 197    lr: 0.0001     evaluation reward: 1.52\nepisode: 622   score: 1.0   memory length: 113907   epsilon: 0.9724621600005978    steps: 152    lr: 0.0001     evaluation reward: 1.52\nepisode: 623   score: 2.0   memory length: 114126   epsilon: 0.9720285400006072    steps: 219    lr: 0.0001     evaluation reward: 1.51\nepisode: 624   score: 4.0   memory length: 114443   epsilon: 0.9714008800006209    steps: 317    lr: 0.0001     evaluation reward: 1.55\nepisode: 625   score: 6.0   memory length: 114796   epsilon: 0.970701940000636    steps: 353    lr: 0.0001     evaluation reward: 1.6\nepisode: 626   score: 2.0   memory length: 114993   epsilon: 0.9703118800006445    steps: 197    lr: 0.0001     evaluation reward: 1.62\nepisode: 627   score: 1.0   memory length: 115161   epsilon: 0.9699792400006517    steps: 168    lr: 0.0001     evaluation reward: 1.63\nepisode: 628   score: 3.0   memory length: 115408   epsilon: 0.9694901800006623    steps: 247    lr: 0.0001     evaluation reward: 1.64\nepisode: 629   score: 0.0   memory length: 115531   epsilon: 0.9692466400006676    steps: 123    lr: 0.0001     evaluation reward: 1.64\nepisode: 630   score: 2.0   memory length: 115750   epsilon: 0.968813020000677    steps: 219    lr: 0.0001     evaluation reward: 1.64\nepisode: 631   score: 1.0   memory length: 115921   epsilon: 0.9684744400006844    steps: 171    lr: 0.0001     evaluation reward: 1.65\nepisode: 632   score: 3.0   memory length: 116169   epsilon: 0.967983400000695    steps: 248    lr: 0.0001     evaluation reward: 1.67\nepisode: 633   score: 0.0   memory length: 116292   epsilon: 0.9677398600007003    steps: 123    lr: 0.0001     evaluation reward: 1.67\nepisode: 634   score: 0.0   memory length: 116415   epsilon: 0.9674963200007056    steps: 123    lr: 0.0001     evaluation reward: 1.66\nepisode: 635   score: 0.0   memory length: 116537   epsilon: 0.9672547600007109    steps: 122    lr: 0.0001     evaluation reward: 1.64\nepisode: 636   score: 2.0   memory length: 116735   epsilon: 0.9668627200007194    steps: 198    lr: 0.0001     evaluation reward: 1.64\nepisode: 637   score: 0.0   memory length: 116858   epsilon: 0.9666191800007247    steps: 123    lr: 0.0001     evaluation reward: 1.64\nepisode: 638   score: 1.0   memory length: 117026   epsilon: 0.9662865400007319    steps: 168    lr: 0.0001     evaluation reward: 1.64\nepisode: 639   score: 0.0   memory length: 117148   epsilon: 0.9660449800007371    steps: 122    lr: 0.0001     evaluation reward: 1.63\nepisode: 640   score: 0.0   memory length: 117270   epsilon: 0.9658034200007424    steps: 122    lr: 0.0001     evaluation reward: 1.6\nepisode: 641   score: 3.0   memory length: 117496   epsilon: 0.9653559400007521    steps: 226    lr: 0.0001     evaluation reward: 1.6\nepisode: 642   score: 2.0   memory length: 117676   epsilon: 0.9649995400007598    steps: 180    lr: 0.0001     evaluation reward: 1.6\nepisode: 643   score: 3.0   memory length: 117903   epsilon: 0.9645500800007696    steps: 227    lr: 0.0001     evaluation reward: 1.62\nepisode: 644   score: 3.0   memory length: 118149   epsilon: 0.9640630000007802    steps: 246    lr: 0.0001     evaluation reward: 1.63\nepisode: 645   score: 0.0   memory length: 118272   epsilon: 0.9638194600007854    steps: 123    lr: 0.0001     evaluation reward: 1.62\nepisode: 646   score: 1.0   memory length: 118440   epsilon: 0.9634868200007927    steps: 168    lr: 0.0001     evaluation reward: 1.63\nepisode: 647   score: 2.0   memory length: 118637   epsilon: 0.9630967600008011    steps: 197    lr: 0.0001     evaluation reward: 1.64\nepisode: 648   score: 0.0   memory length: 118759   epsilon: 0.9628552000008064    steps: 122    lr: 0.0001     evaluation reward: 1.61\nepisode: 649   score: 0.0   memory length: 118881   epsilon: 0.9626136400008116    steps: 122    lr: 0.0001     evaluation reward: 1.59\nepisode: 650   score: 2.0   memory length: 119079   epsilon: 0.9622216000008201    steps: 198    lr: 0.0001     evaluation reward: 1.59\nepisode: 651   score: 2.0   memory length: 119277   epsilon: 0.9618295600008286    steps: 198    lr: 0.0001     evaluation reward: 1.61\nepisode: 652   score: 0.0   memory length: 119400   epsilon: 0.9615860200008339    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 653   score: 1.0   memory length: 119551   epsilon: 0.9612870400008404    steps: 151    lr: 0.0001     evaluation reward: 1.6\nepisode: 654   score: 1.0   memory length: 119702   epsilon: 0.9609880600008469    steps: 151    lr: 0.0001     evaluation reward: 1.59\nepisode: 655   score: 0.0   memory length: 119824   epsilon: 0.9607465000008522    steps: 122    lr: 0.0001     evaluation reward: 1.54\nepisode: 656   score: 2.0   memory length: 120006   epsilon: 0.96038614000086    steps: 182    lr: 0.0001     evaluation reward: 1.56\nepisode: 657   score: 3.0   memory length: 120252   epsilon: 0.9598990600008706    steps: 246    lr: 0.0001     evaluation reward: 1.58\nepisode: 658   score: 3.0   memory length: 120496   epsilon: 0.959415940000881    steps: 244    lr: 0.0001     evaluation reward: 1.61\nepisode: 659   score: 2.0   memory length: 120695   epsilon: 0.9590219200008896    steps: 199    lr: 0.0001     evaluation reward: 1.61\nepisode: 660   score: 2.0   memory length: 120916   epsilon: 0.9585843400008991    steps: 221    lr: 0.0001     evaluation reward: 1.6\nepisode: 661   score: 1.0   memory length: 121087   epsilon: 0.9582457600009064    steps: 171    lr: 0.0001     evaluation reward: 1.58\nepisode: 662   score: 2.0   memory length: 121284   epsilon: 0.9578557000009149    steps: 197    lr: 0.0001     evaluation reward: 1.59\nepisode: 663   score: 1.0   memory length: 121453   epsilon: 0.9575210800009222    steps: 169    lr: 0.0001     evaluation reward: 1.6\nepisode: 664   score: 2.0   memory length: 121651   epsilon: 0.9571290400009307    steps: 198    lr: 0.0001     evaluation reward: 1.62\nepisode: 665   score: 3.0   memory length: 121879   epsilon: 0.9566776000009405    steps: 228    lr: 0.0001     evaluation reward: 1.65\nepisode: 666   score: 1.0   memory length: 122051   epsilon: 0.9563370400009479    steps: 172    lr: 0.0001     evaluation reward: 1.64\nepisode: 667   score: 2.0   memory length: 122249   epsilon: 0.9559450000009564    steps: 198    lr: 0.0001     evaluation reward: 1.63\nepisode: 668   score: 0.0   memory length: 122372   epsilon: 0.9557014600009617    steps: 123    lr: 0.0001     evaluation reward: 1.61\nepisode: 669   score: 1.0   memory length: 122541   epsilon: 0.9553668400009689    steps: 169    lr: 0.0001     evaluation reward: 1.61\nepisode: 670   score: 0.0   memory length: 122663   epsilon: 0.9551252800009742    steps: 122    lr: 0.0001     evaluation reward: 1.61\nepisode: 671   score: 1.0   memory length: 122814   epsilon: 0.9548263000009807    steps: 151    lr: 0.0001     evaluation reward: 1.61\nepisode: 672   score: 1.0   memory length: 122965   epsilon: 0.9545273200009872    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 673   score: 3.0   memory length: 123214   epsilon: 0.9540343000009979    steps: 249    lr: 0.0001     evaluation reward: 1.6\nepisode: 674   score: 2.0   memory length: 123412   epsilon: 0.9536422600010064    steps: 198    lr: 0.0001     evaluation reward: 1.62\nepisode: 675   score: 4.0   memory length: 123706   epsilon: 0.953060140001019    steps: 294    lr: 0.0001     evaluation reward: 1.62\nepisode: 676   score: 1.0   memory length: 123875   epsilon: 0.9527255200010263    steps: 169    lr: 0.0001     evaluation reward: 1.61\nepisode: 677   score: 3.0   memory length: 124121   epsilon: 0.9522384400010369    steps: 246    lr: 0.0001     evaluation reward: 1.62\nepisode: 678   score: 2.0   memory length: 124341   epsilon: 0.9518028400010463    steps: 220    lr: 0.0001     evaluation reward: 1.6\nepisode: 679   score: 1.0   memory length: 124510   epsilon: 0.9514682200010536    steps: 169    lr: 0.0001     evaluation reward: 1.57\nepisode: 680   score: 2.0   memory length: 124731   epsilon: 0.9510306400010631    steps: 221    lr: 0.0001     evaluation reward: 1.59\nepisode: 681   score: 2.0   memory length: 124948   epsilon: 0.9506009800010724    steps: 217    lr: 0.0001     evaluation reward: 1.6\nepisode: 682   score: 1.0   memory length: 125099   epsilon: 0.9503020000010789    steps: 151    lr: 0.0001     evaluation reward: 1.6\nepisode: 683   score: 1.0   memory length: 125268   epsilon: 0.9499673800010862    steps: 169    lr: 0.0001     evaluation reward: 1.61\nepisode: 684   score: 0.0   memory length: 125391   epsilon: 0.9497238400010914    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 685   score: 2.0   memory length: 125572   epsilon: 0.9493654600010992    steps: 181    lr: 0.0001     evaluation reward: 1.58\nepisode: 686   score: 1.0   memory length: 125742   epsilon: 0.9490288600011065    steps: 170    lr: 0.0001     evaluation reward: 1.58\nepisode: 687   score: 0.0   memory length: 125864   epsilon: 0.9487873000011118    steps: 122    lr: 0.0001     evaluation reward: 1.56\nepisode: 688   score: 0.0   memory length: 125987   epsilon: 0.9485437600011171    steps: 123    lr: 0.0001     evaluation reward: 1.54\nepisode: 689   score: 1.0   memory length: 126156   epsilon: 0.9482091400011243    steps: 169    lr: 0.0001     evaluation reward: 1.55\nepisode: 690   score: 1.0   memory length: 126324   epsilon: 0.9478765000011316    steps: 168    lr: 0.0001     evaluation reward: 1.51\nepisode: 691   score: 1.0   memory length: 126475   epsilon: 0.947577520001138    steps: 151    lr: 0.0001     evaluation reward: 1.49\nepisode: 692   score: 3.0   memory length: 126703   epsilon: 0.9471260800011478    steps: 228    lr: 0.0001     evaluation reward: 1.5\nepisode: 693   score: 1.0   memory length: 126872   epsilon: 0.9467914600011551    steps: 169    lr: 0.0001     evaluation reward: 1.5\nepisode: 694   score: 0.0   memory length: 126995   epsilon: 0.9465479200011604    steps: 123    lr: 0.0001     evaluation reward: 1.48\nepisode: 695   score: 1.0   memory length: 127146   epsilon: 0.9462489400011669    steps: 151    lr: 0.0001     evaluation reward: 1.47\nepisode: 696   score: 2.0   memory length: 127365   epsilon: 0.9458153200011763    steps: 219    lr: 0.0001     evaluation reward: 1.49\nepisode: 697   score: 2.0   memory length: 127583   epsilon: 0.9453836800011857    steps: 218    lr: 0.0001     evaluation reward: 1.5\nepisode: 698   score: 1.0   memory length: 127753   epsilon: 0.945047080001193    steps: 170    lr: 0.0001     evaluation reward: 1.49\nepisode: 699   score: 1.0   memory length: 127922   epsilon: 0.9447124600012002    steps: 169    lr: 0.0001     evaluation reward: 1.5\nepisode: 700   score: 0.0   memory length: 128045   epsilon: 0.9444689200012055    steps: 123    lr: 0.0001     evaluation reward: 1.5\nepisode: 701   score: 1.0   memory length: 128196   epsilon: 0.944169940001212    steps: 151    lr: 0.0001     evaluation reward: 1.48\nepisode: 702   score: 3.0   memory length: 128440   epsilon: 0.9436868200012225    steps: 244    lr: 0.0001     evaluation reward: 1.51\nepisode: 703   score: 2.0   memory length: 128657   epsilon: 0.9432571600012318    steps: 217    lr: 0.0001     evaluation reward: 1.51\nepisode: 704   score: 1.0   memory length: 128827   epsilon: 0.9429205600012391    steps: 170    lr: 0.0001     evaluation reward: 1.5\nepisode: 705   score: 2.0   memory length: 129026   epsilon: 0.9425265400012477    steps: 199    lr: 0.0001     evaluation reward: 1.5\nepisode: 706   score: 2.0   memory length: 129244   epsilon: 0.9420949000012571    steps: 218    lr: 0.0001     evaluation reward: 1.52\nepisode: 707   score: 0.0   memory length: 129367   epsilon: 0.9418513600012623    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 708   score: 0.0   memory length: 129490   epsilon: 0.9416078200012676    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 709   score: 3.0   memory length: 129738   epsilon: 0.9411167800012783    steps: 248    lr: 0.0001     evaluation reward: 1.53\nepisode: 710   score: 0.0   memory length: 129861   epsilon: 0.9408732400012836    steps: 123    lr: 0.0001     evaluation reward: 1.51\nepisode: 711   score: 3.0   memory length: 130129   epsilon: 0.9403426000012951    steps: 268    lr: 0.0001     evaluation reward: 1.52\nepisode: 712   score: 0.0   memory length: 130251   epsilon: 0.9401010400013003    steps: 122    lr: 0.0001     evaluation reward: 1.51\nepisode: 713   score: 1.0   memory length: 130420   epsilon: 0.9397664200013076    steps: 169    lr: 0.0001     evaluation reward: 1.51\nepisode: 714   score: 1.0   memory length: 130588   epsilon: 0.9394337800013148    steps: 168    lr: 0.0001     evaluation reward: 1.51\nepisode: 715   score: 3.0   memory length: 130814   epsilon: 0.9389863000013245    steps: 226    lr: 0.0001     evaluation reward: 1.49\nepisode: 716   score: 6.0   memory length: 131167   epsilon: 0.9382873600013397    steps: 353    lr: 0.0001     evaluation reward: 1.54\nepisode: 717   score: 1.0   memory length: 131337   epsilon: 0.937950760001347    steps: 170    lr: 0.0001     evaluation reward: 1.51\nepisode: 718   score: 2.0   memory length: 131552   epsilon: 0.9375250600013563    steps: 215    lr: 0.0001     evaluation reward: 1.49\nepisode: 719   score: 3.0   memory length: 131798   epsilon: 0.9370379800013668    steps: 246    lr: 0.0001     evaluation reward: 1.5\nepisode: 720   score: 4.0   memory length: 132093   epsilon: 0.9364538800013795    steps: 295    lr: 0.0001     evaluation reward: 1.54\nepisode: 721   score: 3.0   memory length: 132361   epsilon: 0.935923240001391    steps: 268    lr: 0.0001     evaluation reward: 1.55\nepisode: 722   score: 0.0   memory length: 132484   epsilon: 0.9356797000013963    steps: 123    lr: 0.0001     evaluation reward: 1.54\nepisode: 723   score: 0.0   memory length: 132607   epsilon: 0.9354361600014016    steps: 123    lr: 0.0001     evaluation reward: 1.52\nepisode: 724   score: 1.0   memory length: 132776   epsilon: 0.9351015400014089    steps: 169    lr: 0.0001     evaluation reward: 1.49\nepisode: 725   score: 1.0   memory length: 132945   epsilon: 0.9347669200014161    steps: 169    lr: 0.0001     evaluation reward: 1.44\nepisode: 726   score: 0.0   memory length: 133067   epsilon: 0.9345253600014214    steps: 122    lr: 0.0001     evaluation reward: 1.42\nepisode: 727   score: 5.0   memory length: 133411   epsilon: 0.9338442400014362    steps: 344    lr: 0.0001     evaluation reward: 1.46\nepisode: 728   score: 1.0   memory length: 133583   epsilon: 0.9335036800014436    steps: 172    lr: 0.0001     evaluation reward: 1.44\nepisode: 729   score: 1.0   memory length: 133752   epsilon: 0.9331690600014508    steps: 169    lr: 0.0001     evaluation reward: 1.45\nepisode: 730   score: 2.0   memory length: 133970   epsilon: 0.9327374200014602    steps: 218    lr: 0.0001     evaluation reward: 1.45\nepisode: 731   score: 0.0   memory length: 134092   epsilon: 0.9324958600014654    steps: 122    lr: 0.0001     evaluation reward: 1.44\nepisode: 732   score: 0.0   memory length: 134215   epsilon: 0.9322523200014707    steps: 123    lr: 0.0001     evaluation reward: 1.41\nepisode: 733   score: 4.0   memory length: 134502   epsilon: 0.9316840600014831    steps: 287    lr: 0.0001     evaluation reward: 1.45\nepisode: 734   score: 2.0   memory length: 134700   epsilon: 0.9312920200014916    steps: 198    lr: 0.0001     evaluation reward: 1.47\nepisode: 735   score: 2.0   memory length: 134898   epsilon: 0.9308999800015001    steps: 198    lr: 0.0001     evaluation reward: 1.49\nepisode: 736   score: 2.0   memory length: 135095   epsilon: 0.9305099200015086    steps: 197    lr: 0.0001     evaluation reward: 1.49\nepisode: 737   score: 3.0   memory length: 135322   epsilon: 0.9300604600015183    steps: 227    lr: 0.0001     evaluation reward: 1.52\nepisode: 738   score: 2.0   memory length: 135520   epsilon: 0.9296684200015268    steps: 198    lr: 0.0001     evaluation reward: 1.53\nepisode: 739   score: 0.0   memory length: 135643   epsilon: 0.9294248800015321    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 740   score: 1.0   memory length: 135794   epsilon: 0.9291259000015386    steps: 151    lr: 0.0001     evaluation reward: 1.54\nepisode: 741   score: 1.0   memory length: 135964   epsilon: 0.9287893000015459    steps: 170    lr: 0.0001     evaluation reward: 1.52\nepisode: 742   score: 2.0   memory length: 136161   epsilon: 0.9283992400015544    steps: 197    lr: 0.0001     evaluation reward: 1.52\nepisode: 743   score: 3.0   memory length: 136427   epsilon: 0.9278725600015658    steps: 266    lr: 0.0001     evaluation reward: 1.52\nepisode: 744   score: 5.0   memory length: 136772   epsilon: 0.9271894600015806    steps: 345    lr: 0.0001     evaluation reward: 1.54\nepisode: 745   score: 2.0   memory length: 136990   epsilon: 0.92675782000159    steps: 218    lr: 0.0001     evaluation reward: 1.56\nepisode: 746   score: 2.0   memory length: 137188   epsilon: 0.9263657800015985    steps: 198    lr: 0.0001     evaluation reward: 1.57\nepisode: 747   score: 2.0   memory length: 137388   epsilon: 0.9259697800016071    steps: 200    lr: 0.0001     evaluation reward: 1.57\nepisode: 748   score: 2.0   memory length: 137588   epsilon: 0.9255737800016157    steps: 200    lr: 0.0001     evaluation reward: 1.59\nepisode: 749   score: 0.0   memory length: 137711   epsilon: 0.925330240001621    steps: 123    lr: 0.0001     evaluation reward: 1.59\nepisode: 750   score: 0.0   memory length: 137834   epsilon: 0.9250867000016263    steps: 123    lr: 0.0001     evaluation reward: 1.57\nepisode: 751   score: 1.0   memory length: 138003   epsilon: 0.9247520800016336    steps: 169    lr: 0.0001     evaluation reward: 1.56\nepisode: 752   score: 2.0   memory length: 138221   epsilon: 0.9243204400016429    steps: 218    lr: 0.0001     evaluation reward: 1.58\nepisode: 753   score: 1.0   memory length: 138392   epsilon: 0.9239818600016503    steps: 171    lr: 0.0001     evaluation reward: 1.58\nepisode: 754   score: 1.0   memory length: 138543   epsilon: 0.9236828800016568    steps: 151    lr: 0.0001     evaluation reward: 1.58\nepisode: 755   score: 1.0   memory length: 138712   epsilon: 0.923348260001664    steps: 169    lr: 0.0001     evaluation reward: 1.59\nepisode: 756   score: 1.0   memory length: 138880   epsilon: 0.9230156200016713    steps: 168    lr: 0.0001     evaluation reward: 1.58\nepisode: 757   score: 1.0   memory length: 139051   epsilon: 0.9226770400016786    steps: 171    lr: 0.0001     evaluation reward: 1.56\nepisode: 758   score: 4.0   memory length: 139326   epsilon: 0.9221325400016904    steps: 275    lr: 0.0001     evaluation reward: 1.57\nepisode: 759   score: 2.0   memory length: 139544   epsilon: 0.9217009000016998    steps: 218    lr: 0.0001     evaluation reward: 1.57\nepisode: 760   score: 3.0   memory length: 139814   epsilon: 0.9211663000017114    steps: 270    lr: 0.0001     evaluation reward: 1.58\nepisode: 761   score: 0.0   memory length: 139937   epsilon: 0.9209227600017167    steps: 123    lr: 0.0001     evaluation reward: 1.57\nepisode: 762   score: 2.0   memory length: 140137   epsilon: 0.9205267600017253    steps: 200    lr: 0.0001     evaluation reward: 1.57\nepisode: 763   score: 0.0   memory length: 140259   epsilon: 0.9202852000017305    steps: 122    lr: 0.0001     evaluation reward: 1.56\nepisode: 764   score: 3.0   memory length: 140505   epsilon: 0.9197981200017411    steps: 246    lr: 0.0001     evaluation reward: 1.57\nepisode: 765   score: 1.0   memory length: 140657   epsilon: 0.9194971600017476    steps: 152    lr: 0.0001     evaluation reward: 1.55\nepisode: 766   score: 2.0   memory length: 140855   epsilon: 0.9191051200017561    steps: 198    lr: 0.0001     evaluation reward: 1.56\nepisode: 767   score: 2.0   memory length: 141055   epsilon: 0.9187091200017647    steps: 200    lr: 0.0001     evaluation reward: 1.56\nepisode: 768   score: 3.0   memory length: 141308   epsilon: 0.9182081800017756    steps: 253    lr: 0.0001     evaluation reward: 1.59\nepisode: 769   score: 0.0   memory length: 141430   epsilon: 0.9179666200017809    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 770   score: 1.0   memory length: 141581   epsilon: 0.9176676400017874    steps: 151    lr: 0.0001     evaluation reward: 1.59\nepisode: 771   score: 1.0   memory length: 141731   epsilon: 0.9173706400017938    steps: 150    lr: 0.0001     evaluation reward: 1.59\nepisode: 772   score: 2.0   memory length: 141929   epsilon: 0.9169786000018023    steps: 198    lr: 0.0001     evaluation reward: 1.6\nepisode: 773   score: 2.0   memory length: 142126   epsilon: 0.9165885400018108    steps: 197    lr: 0.0001     evaluation reward: 1.59\nepisode: 774   score: 0.0   memory length: 142249   epsilon: 0.9163450000018161    steps: 123    lr: 0.0001     evaluation reward: 1.57\nepisode: 775   score: 2.0   memory length: 142468   epsilon: 0.9159113800018255    steps: 219    lr: 0.0001     evaluation reward: 1.55\nepisode: 776   score: 3.0   memory length: 142697   epsilon: 0.9154579600018353    steps: 229    lr: 0.0001     evaluation reward: 1.57\nepisode: 777   score: 2.0   memory length: 142915   epsilon: 0.9150263200018447    steps: 218    lr: 0.0001     evaluation reward: 1.56\nepisode: 778   score: 1.0   memory length: 143083   epsilon: 0.9146936800018519    steps: 168    lr: 0.0001     evaluation reward: 1.55\nepisode: 779   score: 3.0   memory length: 143329   epsilon: 0.9142066000018625    steps: 246    lr: 0.0001     evaluation reward: 1.57\nepisode: 780   score: 0.0   memory length: 143452   epsilon: 0.9139630600018678    steps: 123    lr: 0.0001     evaluation reward: 1.55\nepisode: 781   score: 0.0   memory length: 143575   epsilon: 0.9137195200018731    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 782   score: 1.0   memory length: 143744   epsilon: 0.9133849000018803    steps: 169    lr: 0.0001     evaluation reward: 1.53\nepisode: 783   score: 1.0   memory length: 143913   epsilon: 0.9130502800018876    steps: 169    lr: 0.0001     evaluation reward: 1.53\nepisode: 784   score: 0.0   memory length: 144036   epsilon: 0.9128067400018929    steps: 123    lr: 0.0001     evaluation reward: 1.53\nepisode: 785   score: 3.0   memory length: 144261   epsilon: 0.9123612400019026    steps: 225    lr: 0.0001     evaluation reward: 1.54\nepisode: 786   score: 1.0   memory length: 144432   epsilon: 0.9120226600019099    steps: 171    lr: 0.0001     evaluation reward: 1.54\nepisode: 787   score: 4.0   memory length: 144749   epsilon: 0.9113950000019235    steps: 317    lr: 0.0001     evaluation reward: 1.58\nepisode: 788   score: 0.0   memory length: 144871   epsilon: 0.9111534400019288    steps: 122    lr: 0.0001     evaluation reward: 1.58\nepisode: 789   score: 1.0   memory length: 145040   epsilon: 0.910818820001936    steps: 169    lr: 0.0001     evaluation reward: 1.58\nepisode: 790   score: 5.0   memory length: 145364   epsilon: 0.91017730000195    steps: 324    lr: 0.0001     evaluation reward: 1.62\nepisode: 791   score: 4.0   memory length: 145657   epsilon: 0.9095971600019626    steps: 293    lr: 0.0001     evaluation reward: 1.65\nepisode: 792   score: 1.0   memory length: 145808   epsilon: 0.909298180001969    steps: 151    lr: 0.0001     evaluation reward: 1.63\nepisode: 793   score: 1.0   memory length: 145959   epsilon: 0.9089992000019755    steps: 151    lr: 0.0001     evaluation reward: 1.63\nepisode: 794   score: 2.0   memory length: 146176   epsilon: 0.9085695400019849    steps: 217    lr: 0.0001     evaluation reward: 1.65\nepisode: 795   score: 1.0   memory length: 146327   epsilon: 0.9082705600019914    steps: 151    lr: 0.0001     evaluation reward: 1.65\nepisode: 796   score: 6.0   memory length: 146657   epsilon: 0.9076171600020055    steps: 330    lr: 0.0001     evaluation reward: 1.69\nepisode: 797   score: 1.0   memory length: 146826   epsilon: 0.9072825400020128    steps: 169    lr: 0.0001     evaluation reward: 1.68\nepisode: 798   score: 2.0   memory length: 147024   epsilon: 0.9068905000020213    steps: 198    lr: 0.0001     evaluation reward: 1.69\nepisode: 799   score: 3.0   memory length: 147249   epsilon: 0.906445000002031    steps: 225    lr: 0.0001     evaluation reward: 1.71\nepisode: 800   score: 2.0   memory length: 147446   epsilon: 0.9060549400020395    steps: 197    lr: 0.0001     evaluation reward: 1.73\nepisode: 801   score: 1.0   memory length: 147597   epsilon: 0.905755960002046    steps: 151    lr: 0.0001     evaluation reward: 1.73\nepisode: 802   score: 3.0   memory length: 147822   epsilon: 0.9053104600020556    steps: 225    lr: 0.0001     evaluation reward: 1.73\nepisode: 803   score: 2.0   memory length: 148002   epsilon: 0.9049540600020634    steps: 180    lr: 0.0001     evaluation reward: 1.73\nepisode: 804   score: 3.0   memory length: 148228   epsilon: 0.9045065800020731    steps: 226    lr: 0.0001     evaluation reward: 1.75\nepisode: 805   score: 0.0   memory length: 148351   epsilon: 0.9042630400020784    steps: 123    lr: 0.0001     evaluation reward: 1.73\nepisode: 806   score: 3.0   memory length: 148597   epsilon: 0.9037759600020889    steps: 246    lr: 0.0001     evaluation reward: 1.74\nepisode: 807   score: 2.0   memory length: 148795   epsilon: 0.9033839200020974    steps: 198    lr: 0.0001     evaluation reward: 1.76\nepisode: 808   score: 3.0   memory length: 149042   epsilon: 0.9028948600021081    steps: 247    lr: 0.0001     evaluation reward: 1.79\nepisode: 809   score: 0.0   memory length: 149165   epsilon: 0.9026513200021133    steps: 123    lr: 0.0001     evaluation reward: 1.76\nepisode: 810   score: 2.0   memory length: 149362   epsilon: 0.9022612600021218    steps: 197    lr: 0.0001     evaluation reward: 1.78\nepisode: 811   score: 2.0   memory length: 149578   epsilon: 0.9018335800021311    steps: 216    lr: 0.0001     evaluation reward: 1.77\nepisode: 812   score: 1.0   memory length: 149747   epsilon: 0.9014989600021384    steps: 169    lr: 0.0001     evaluation reward: 1.78\nepisode: 813   score: 2.0   memory length: 149964   epsilon: 0.9010693000021477    steps: 217    lr: 0.0001     evaluation reward: 1.79\nepisode: 814   score: 5.0   memory length: 150310   epsilon: 0.9003842200021626    steps: 346    lr: 0.0001     evaluation reward: 1.83\nepisode: 815   score: 0.0   memory length: 150433   epsilon: 0.9001406800021678    steps: 123    lr: 0.0001     evaluation reward: 1.8\nepisode: 816   score: 2.0   memory length: 150630   epsilon: 0.8997506200021763    steps: 197    lr: 0.0001     evaluation reward: 1.76\nepisode: 817   score: 2.0   memory length: 150848   epsilon: 0.8993189800021857    steps: 218    lr: 0.0001     evaluation reward: 1.77\nepisode: 818   score: 2.0   memory length: 151064   epsilon: 0.898891300002195    steps: 216    lr: 0.0001     evaluation reward: 1.77\nepisode: 819   score: 2.0   memory length: 151245   epsilon: 0.8985329200022028    steps: 181    lr: 0.0001     evaluation reward: 1.76\nepisode: 820   score: 3.0   memory length: 151472   epsilon: 0.8980834600022125    steps: 227    lr: 0.0001     evaluation reward: 1.75\nepisode: 821   score: 3.0   memory length: 151697   epsilon: 0.8976379600022222    steps: 225    lr: 0.0001     evaluation reward: 1.75\nepisode: 822   score: 1.0   memory length: 151848   epsilon: 0.8973389800022287    steps: 151    lr: 0.0001     evaluation reward: 1.76\nepisode: 823   score: 3.0   memory length: 152113   epsilon: 0.8968142800022401    steps: 265    lr: 0.0001     evaluation reward: 1.79\nepisode: 824   score: 0.0   memory length: 152236   epsilon: 0.8965707400022453    steps: 123    lr: 0.0001     evaluation reward: 1.78\nepisode: 825   score: 2.0   memory length: 152433   epsilon: 0.8961806800022538    steps: 197    lr: 0.0001     evaluation reward: 1.79\nepisode: 826   score: 2.0   memory length: 152648   epsilon: 0.8957549800022631    steps: 215    lr: 0.0001     evaluation reward: 1.81\nepisode: 827   score: 1.0   memory length: 152818   epsilon: 0.8954183800022704    steps: 170    lr: 0.0001     evaluation reward: 1.77\nepisode: 828   score: 3.0   memory length: 153082   epsilon: 0.8948956600022817    steps: 264    lr: 0.0001     evaluation reward: 1.79\nepisode: 829   score: 1.0   memory length: 153251   epsilon: 0.894561040002289    steps: 169    lr: 0.0001     evaluation reward: 1.79\nepisode: 830   score: 3.0   memory length: 153496   epsilon: 0.8940759400022995    steps: 245    lr: 0.0001     evaluation reward: 1.8\nepisode: 831   score: 3.0   memory length: 153722   epsilon: 0.8936284600023092    steps: 226    lr: 0.0001     evaluation reward: 1.83\nepisode: 832   score: 3.0   memory length: 153986   epsilon: 0.8931057400023206    steps: 264    lr: 0.0001     evaluation reward: 1.86\nepisode: 833   score: 2.0   memory length: 154184   epsilon: 0.8927137000023291    steps: 198    lr: 0.0001     evaluation reward: 1.84\nepisode: 834   score: 2.0   memory length: 154384   epsilon: 0.8923177000023377    steps: 200    lr: 0.0001     evaluation reward: 1.84\nepisode: 835   score: 2.0   memory length: 154582   epsilon: 0.8919256600023462    steps: 198    lr: 0.0001     evaluation reward: 1.84\nepisode: 836   score: 4.0   memory length: 154838   epsilon: 0.8914187800023572    steps: 256    lr: 0.0001     evaluation reward: 1.86\nepisode: 837   score: 1.0   memory length: 154990   epsilon: 0.8911178200023637    steps: 152    lr: 0.0001     evaluation reward: 1.84\nepisode: 838   score: 1.0   memory length: 155161   epsilon: 0.8907792400023711    steps: 171    lr: 0.0001     evaluation reward: 1.83\nepisode: 839   score: 1.0   memory length: 155330   epsilon: 0.8904446200023783    steps: 169    lr: 0.0001     evaluation reward: 1.84\nepisode: 840   score: 1.0   memory length: 155499   epsilon: 0.8901100000023856    steps: 169    lr: 0.0001     evaluation reward: 1.84\nepisode: 841   score: 1.0   memory length: 155668   epsilon: 0.8897753800023929    steps: 169    lr: 0.0001     evaluation reward: 1.84\nepisode: 842   score: 1.0   memory length: 155839   epsilon: 0.8894368000024002    steps: 171    lr: 0.0001     evaluation reward: 1.83\nepisode: 843   score: 1.0   memory length: 155989   epsilon: 0.8891398000024067    steps: 150    lr: 0.0001     evaluation reward: 1.81\nepisode: 844   score: 2.0   memory length: 156171   epsilon: 0.8887794400024145    steps: 182    lr: 0.0001     evaluation reward: 1.78\nepisode: 845   score: 2.0   memory length: 156369   epsilon: 0.888387400002423    steps: 198    lr: 0.0001     evaluation reward: 1.78\nepisode: 846   score: 3.0   memory length: 156617   epsilon: 0.8878963600024337    steps: 248    lr: 0.0001     evaluation reward: 1.79\nepisode: 847   score: 3.0   memory length: 156842   epsilon: 0.8874508600024433    steps: 225    lr: 0.0001     evaluation reward: 1.8\nepisode: 848   score: 3.0   memory length: 157074   epsilon: 0.8869915000024533    steps: 232    lr: 0.0001     evaluation reward: 1.81\nepisode: 849   score: 1.0   memory length: 157245   epsilon: 0.8866529200024607    steps: 171    lr: 0.0001     evaluation reward: 1.82\nepisode: 850   score: 1.0   memory length: 157417   epsilon: 0.886312360002468    steps: 172    lr: 0.0001     evaluation reward: 1.83\nepisode: 851   score: 2.0   memory length: 157617   epsilon: 0.8859163600024766    steps: 200    lr: 0.0001     evaluation reward: 1.84\nepisode: 852   score: 0.0   memory length: 157739   epsilon: 0.8856748000024819    steps: 122    lr: 0.0001     evaluation reward: 1.82\nepisode: 853   score: 2.0   memory length: 157954   epsilon: 0.8852491000024911    steps: 215    lr: 0.0001     evaluation reward: 1.83\nepisode: 854   score: 0.0   memory length: 158077   epsilon: 0.8850055600024964    steps: 123    lr: 0.0001     evaluation reward: 1.82\nepisode: 855   score: 1.0   memory length: 158228   epsilon: 0.8847065800025029    steps: 151    lr: 0.0001     evaluation reward: 1.82\nepisode: 856   score: 3.0   memory length: 158456   epsilon: 0.8842551400025127    steps: 228    lr: 0.0001     evaluation reward: 1.84\nepisode: 857   score: 2.0   memory length: 158678   epsilon: 0.8838155800025222    steps: 222    lr: 0.0001     evaluation reward: 1.85\nepisode: 858   score: 6.0   memory length: 159019   epsilon: 0.8831404000025369    steps: 341    lr: 0.0001     evaluation reward: 1.87\nepisode: 859   score: 2.0   memory length: 159219   epsilon: 0.8827444000025455    steps: 200    lr: 0.0001     evaluation reward: 1.87\nepisode: 860   score: 0.0   memory length: 159342   epsilon: 0.8825008600025508    steps: 123    lr: 0.0001     evaluation reward: 1.84\nepisode: 861   score: 2.0   memory length: 159540   epsilon: 0.8821088200025593    steps: 198    lr: 0.0001     evaluation reward: 1.86\nepisode: 862   score: 0.0   memory length: 159662   epsilon: 0.8818672600025645    steps: 122    lr: 0.0001     evaluation reward: 1.84\nepisode: 863   score: 0.0   memory length: 159784   epsilon: 0.8816257000025698    steps: 122    lr: 0.0001     evaluation reward: 1.84\nepisode: 864   score: 0.0   memory length: 159907   epsilon: 0.8813821600025751    steps: 123    lr: 0.0001     evaluation reward: 1.81\nepisode: 865   score: 3.0   memory length: 160154   epsilon: 0.8808931000025857    steps: 247    lr: 0.0001     evaluation reward: 1.83\nepisode: 866   score: 5.0   memory length: 160477   epsilon: 0.8802535600025996    steps: 323    lr: 0.0001     evaluation reward: 1.86\nepisode: 867   score: 2.0   memory length: 160695   epsilon: 0.879821920002609    steps: 218    lr: 0.0001     evaluation reward: 1.86\nepisode: 868   score: 2.0   memory length: 160875   epsilon: 0.8794655200026167    steps: 180    lr: 0.0001     evaluation reward: 1.85\nepisode: 869   score: 0.0   memory length: 160998   epsilon: 0.879221980002622    steps: 123    lr: 0.0001     evaluation reward: 1.85\nepisode: 870   score: 4.0   memory length: 161253   epsilon: 0.8787170800026329    steps: 255    lr: 0.0001     evaluation reward: 1.88\nepisode: 871   score: 3.0   memory length: 161519   epsilon: 0.8781904000026444    steps: 266    lr: 0.0001     evaluation reward: 1.9\nepisode: 872   score: 5.0   memory length: 161846   epsilon: 0.8775429400026584    steps: 327    lr: 0.0001     evaluation reward: 1.93\nepisode: 873   score: 1.0   memory length: 161997   epsilon: 0.8772439600026649    steps: 151    lr: 0.0001     evaluation reward: 1.92\nepisode: 874   score: 2.0   memory length: 162212   epsilon: 0.8768182600026742    steps: 215    lr: 0.0001     evaluation reward: 1.94\nepisode: 875   score: 1.0   memory length: 162381   epsilon: 0.8764836400026814    steps: 169    lr: 0.0001     evaluation reward: 1.93\nepisode: 876   score: 2.0   memory length: 162601   epsilon: 0.8760480400026909    steps: 220    lr: 0.0001     evaluation reward: 1.92\nepisode: 877   score: 4.0   memory length: 162876   epsilon: 0.8755035400027027    steps: 275    lr: 0.0001     evaluation reward: 1.94\nepisode: 878   score: 3.0   memory length: 163124   epsilon: 0.8750125000027134    steps: 248    lr: 0.0001     evaluation reward: 1.96\nepisode: 879   score: 2.0   memory length: 163322   epsilon: 0.8746204600027219    steps: 198    lr: 0.0001     evaluation reward: 1.95\nepisode: 880   score: 1.0   memory length: 163493   epsilon: 0.8742818800027292    steps: 171    lr: 0.0001     evaluation reward: 1.96\nepisode: 881   score: 1.0   memory length: 163664   epsilon: 0.8739433000027366    steps: 171    lr: 0.0001     evaluation reward: 1.97\nepisode: 882   score: 3.0   memory length: 163878   epsilon: 0.8735195800027458    steps: 214    lr: 0.0001     evaluation reward: 1.99\nepisode: 883   score: 3.0   memory length: 164124   epsilon: 0.8730325000027563    steps: 246    lr: 0.0001     evaluation reward: 2.01\nepisode: 884   score: 3.0   memory length: 164367   epsilon: 0.8725513600027668    steps: 243    lr: 0.0001     evaluation reward: 2.04\nepisode: 885   score: 4.0   memory length: 164686   epsilon: 0.8719197400027805    steps: 319    lr: 0.0001     evaluation reward: 2.05\nepisode: 886   score: 0.0   memory length: 164809   epsilon: 0.8716762000027858    steps: 123    lr: 0.0001     evaluation reward: 2.04\nepisode: 887   score: 3.0   memory length: 165076   epsilon: 0.8711475400027973    steps: 267    lr: 0.0001     evaluation reward: 2.03\nepisode: 888   score: 2.0   memory length: 165274   epsilon: 0.8707555000028058    steps: 198    lr: 0.0001     evaluation reward: 2.05\nepisode: 889   score: 0.0   memory length: 165396   epsilon: 0.870513940002811    steps: 122    lr: 0.0001     evaluation reward: 2.04\nepisode: 890   score: 6.0   memory length: 165747   epsilon: 0.8698189600028261    steps: 351    lr: 0.0001     evaluation reward: 2.05\nepisode: 891   score: 2.0   memory length: 165963   epsilon: 0.8693912800028354    steps: 216    lr: 0.0001     evaluation reward: 2.03\nepisode: 892   score: 1.0   memory length: 166114   epsilon: 0.8690923000028419    steps: 151    lr: 0.0001     evaluation reward: 2.03\nepisode: 893   score: 2.0   memory length: 166312   epsilon: 0.8687002600028504    steps: 198    lr: 0.0001     evaluation reward: 2.04\nepisode: 894   score: 2.0   memory length: 166512   epsilon: 0.868304260002859    steps: 200    lr: 0.0001     evaluation reward: 2.04\nepisode: 895   score: 5.0   memory length: 166839   epsilon: 0.867656800002873    steps: 327    lr: 0.0001     evaluation reward: 2.08\nepisode: 896   score: 0.0   memory length: 166962   epsilon: 0.8674132600028783    steps: 123    lr: 0.0001     evaluation reward: 2.02\nepisode: 897   score: 3.0   memory length: 167205   epsilon: 0.8669321200028888    steps: 243    lr: 0.0001     evaluation reward: 2.04\nepisode: 898   score: 3.0   memory length: 167457   epsilon: 0.8664331600028996    steps: 252    lr: 0.0001     evaluation reward: 2.05\nepisode: 899   score: 3.0   memory length: 167703   epsilon: 0.8659460800029102    steps: 246    lr: 0.0001     evaluation reward: 2.05\nepisode: 900   score: 0.0   memory length: 167825   epsilon: 0.8657045200029154    steps: 122    lr: 0.0001     evaluation reward: 2.03\nepisode: 901   score: 3.0   memory length: 168092   epsilon: 0.8651758600029269    steps: 267    lr: 0.0001     evaluation reward: 2.05\nepisode: 902   score: 7.0   memory length: 168527   epsilon: 0.8643145600029456    steps: 435    lr: 0.0001     evaluation reward: 2.09\nepisode: 903   score: 4.0   memory length: 168826   epsilon: 0.8637225400029584    steps: 299    lr: 0.0001     evaluation reward: 2.11\nepisode: 904   score: 5.0   memory length: 169165   epsilon: 0.863051320002973    steps: 339    lr: 0.0001     evaluation reward: 2.13\nepisode: 905   score: 1.0   memory length: 169335   epsilon: 0.8627147200029803    steps: 170    lr: 0.0001     evaluation reward: 2.14\nepisode: 906   score: 2.0   memory length: 169514   epsilon: 0.862360300002988    steps: 179    lr: 0.0001     evaluation reward: 2.13\nepisode: 907   score: 2.0   memory length: 169714   epsilon: 0.8619643000029966    steps: 200    lr: 0.0001     evaluation reward: 2.13\nepisode: 908   score: 1.0   memory length: 169865   epsilon: 0.8616653200030031    steps: 151    lr: 0.0001     evaluation reward: 2.11\nepisode: 909   score: 1.0   memory length: 170035   epsilon: 0.8613287200030104    steps: 170    lr: 0.0001     evaluation reward: 2.12\nepisode: 910   score: 5.0   memory length: 170319   epsilon: 0.8607664000030226    steps: 284    lr: 0.0001     evaluation reward: 2.15\nepisode: 911   score: 2.0   memory length: 170499   epsilon: 0.8604100000030304    steps: 180    lr: 0.0001     evaluation reward: 2.15\nepisode: 912   score: 3.0   memory length: 170729   epsilon: 0.8599546000030402    steps: 230    lr: 0.0001     evaluation reward: 2.17\nepisode: 913   score: 0.0   memory length: 170852   epsilon: 0.8597110600030455    steps: 123    lr: 0.0001     evaluation reward: 2.15\nepisode: 914   score: 0.0   memory length: 170974   epsilon: 0.8594695000030508    steps: 122    lr: 0.0001     evaluation reward: 2.1\nepisode: 915   score: 0.0   memory length: 171097   epsilon: 0.8592259600030561    steps: 123    lr: 0.0001     evaluation reward: 2.1\nepisode: 916   score: 0.0   memory length: 171220   epsilon: 0.8589824200030614    steps: 123    lr: 0.0001     evaluation reward: 2.08\nepisode: 917   score: 0.0   memory length: 171343   epsilon: 0.8587388800030666    steps: 123    lr: 0.0001     evaluation reward: 2.06\nepisode: 918   score: 3.0   memory length: 171592   epsilon: 0.8582458600030773    steps: 249    lr: 0.0001     evaluation reward: 2.07\nepisode: 919   score: 1.0   memory length: 171763   epsilon: 0.8579072800030847    steps: 171    lr: 0.0001     evaluation reward: 2.06\nepisode: 920   score: 3.0   memory length: 172032   epsilon: 0.8573746600030963    steps: 269    lr: 0.0001     evaluation reward: 2.06\nepisode: 921   score: 3.0   memory length: 172277   epsilon: 0.8568895600031068    steps: 245    lr: 0.0001     evaluation reward: 2.06\nepisode: 922   score: 4.0   memory length: 172594   epsilon: 0.8562619000031204    steps: 317    lr: 0.0001     evaluation reward: 2.09\nepisode: 923   score: 2.0   memory length: 172794   epsilon: 0.855865900003129    steps: 200    lr: 0.0001     evaluation reward: 2.08\nepisode: 924   score: 3.0   memory length: 173020   epsilon: 0.8554184200031387    steps: 226    lr: 0.0001     evaluation reward: 2.11\nepisode: 925   score: 8.0   memory length: 173425   epsilon: 0.8546165200031561    steps: 405    lr: 0.0001     evaluation reward: 2.17\nepisode: 926   score: 2.0   memory length: 173640   epsilon: 0.8541908200031654    steps: 215    lr: 0.0001     evaluation reward: 2.17\nepisode: 927   score: 4.0   memory length: 173933   epsilon: 0.853610680003178    steps: 293    lr: 0.0001     evaluation reward: 2.2\nepisode: 928   score: 3.0   memory length: 174178   epsilon: 0.8531255800031885    steps: 245    lr: 0.0001     evaluation reward: 2.2\nepisode: 929   score: 2.0   memory length: 174357   epsilon: 0.8527711600031962    steps: 179    lr: 0.0001     evaluation reward: 2.21\nepisode: 930   score: 0.0   memory length: 174480   epsilon: 0.8525276200032015    steps: 123    lr: 0.0001     evaluation reward: 2.18\nepisode: 931   score: 3.0   memory length: 174726   epsilon: 0.852040540003212    steps: 246    lr: 0.0001     evaluation reward: 2.18\nepisode: 932   score: 3.0   memory length: 174974   epsilon: 0.8515495000032227    steps: 248    lr: 0.0001     evaluation reward: 2.18\nepisode: 933   score: 3.0   memory length: 175220   epsilon: 0.8510624200032333    steps: 246    lr: 0.0001     evaluation reward: 2.19\nepisode: 934   score: 3.0   memory length: 175487   epsilon: 0.8505337600032448    steps: 267    lr: 0.0001     evaluation reward: 2.2\nepisode: 935   score: 3.0   memory length: 175719   epsilon: 0.8500744000032547    steps: 232    lr: 0.0001     evaluation reward: 2.21\nepisode: 936   score: 3.0   memory length: 175969   epsilon: 0.8495794000032655    steps: 250    lr: 0.0001     evaluation reward: 2.2\nepisode: 937   score: 0.0   memory length: 176092   epsilon: 0.8493358600032708    steps: 123    lr: 0.0001     evaluation reward: 2.19\nepisode: 938   score: 4.0   memory length: 176384   epsilon: 0.8487577000032833    steps: 292    lr: 0.0001     evaluation reward: 2.22\nepisode: 939   score: 5.0   memory length: 176711   epsilon: 0.8481102400032974    steps: 327    lr: 0.0001     evaluation reward: 2.26\nepisode: 940   score: 3.0   memory length: 176937   epsilon: 0.8476627600033071    steps: 226    lr: 0.0001     evaluation reward: 2.28\nepisode: 941   score: 0.0   memory length: 177060   epsilon: 0.8474192200033124    steps: 123    lr: 0.0001     evaluation reward: 2.27\nepisode: 942   score: 3.0   memory length: 177286   epsilon: 0.8469717400033221    steps: 226    lr: 0.0001     evaluation reward: 2.29\nepisode: 943   score: 1.0   memory length: 177456   epsilon: 0.8466351400033294    steps: 170    lr: 0.0001     evaluation reward: 2.29\nepisode: 944   score: 2.0   memory length: 177654   epsilon: 0.8462431000033379    steps: 198    lr: 0.0001     evaluation reward: 2.29\nepisode: 945   score: 3.0   memory length: 177881   epsilon: 0.8457936400033477    steps: 227    lr: 0.0001     evaluation reward: 2.3\nepisode: 946   score: 5.0   memory length: 178155   epsilon: 0.8452511200033594    steps: 274    lr: 0.0001     evaluation reward: 2.32\nepisode: 947   score: 2.0   memory length: 178355   epsilon: 0.844855120003368    steps: 200    lr: 0.0001     evaluation reward: 2.31\nepisode: 948   score: 2.0   memory length: 178538   epsilon: 0.8444927800033759    steps: 183    lr: 0.0001     evaluation reward: 2.3\nepisode: 949   score: 1.0   memory length: 178689   epsilon: 0.8441938000033824    steps: 151    lr: 0.0001     evaluation reward: 2.3\nepisode: 950   score: 5.0   memory length: 179004   epsilon: 0.8435701000033959    steps: 315    lr: 0.0001     evaluation reward: 2.34\nepisode: 951   score: 3.0   memory length: 179229   epsilon: 0.8431246000034056    steps: 225    lr: 0.0001     evaluation reward: 2.35\nepisode: 952   score: 1.0   memory length: 179380   epsilon: 0.8428256200034121    steps: 151    lr: 0.0001     evaluation reward: 2.36\nepisode: 953   score: 2.0   memory length: 179578   epsilon: 0.8424335800034206    steps: 198    lr: 0.0001     evaluation reward: 2.36\nepisode: 954   score: 2.0   memory length: 179775   epsilon: 0.8420435200034291    steps: 197    lr: 0.0001     evaluation reward: 2.38\nepisode: 955   score: 0.0   memory length: 179897   epsilon: 0.8418019600034343    steps: 122    lr: 0.0001     evaluation reward: 2.37\nepisode: 956   score: 3.0   memory length: 180123   epsilon: 0.841354480003444    steps: 226    lr: 0.0001     evaluation reward: 2.37\nepisode: 957   score: 1.0   memory length: 180292   epsilon: 0.8410198600034513    steps: 169    lr: 0.0001     evaluation reward: 2.36\nepisode: 958   score: 3.0   memory length: 180560   epsilon: 0.8404892200034628    steps: 268    lr: 0.0001     evaluation reward: 2.33\nepisode: 959   score: 7.0   memory length: 180945   epsilon: 0.8397269200034794    steps: 385    lr: 0.0001     evaluation reward: 2.38\nepisode: 960   score: 3.0   memory length: 181175   epsilon: 0.8392715200034893    steps: 230    lr: 0.0001     evaluation reward: 2.41\nepisode: 961   score: 1.0   memory length: 181344   epsilon: 0.8389369000034965    steps: 169    lr: 0.0001     evaluation reward: 2.4\nepisode: 962   score: 3.0   memory length: 181590   epsilon: 0.8384498200035071    steps: 246    lr: 0.0001     evaluation reward: 2.43\nepisode: 963   score: 3.0   memory length: 181819   epsilon: 0.8379964000035169    steps: 229    lr: 0.0001     evaluation reward: 2.46\nepisode: 964   score: 3.0   memory length: 182063   epsilon: 0.8375132800035274    steps: 244    lr: 0.0001     evaluation reward: 2.49\nepisode: 965   score: 2.0   memory length: 182260   epsilon: 0.8371232200035359    steps: 197    lr: 0.0001     evaluation reward: 2.48\nepisode: 966   score: 3.0   memory length: 182487   epsilon: 0.8366737600035457    steps: 227    lr: 0.0001     evaluation reward: 2.46\nepisode: 967   score: 2.0   memory length: 182684   epsilon: 0.8362837000035541    steps: 197    lr: 0.0001     evaluation reward: 2.46\nepisode: 968   score: 2.0   memory length: 182882   epsilon: 0.8358916600035626    steps: 198    lr: 0.0001     evaluation reward: 2.46\nepisode: 969   score: 7.0   memory length: 183299   epsilon: 0.8350660000035806    steps: 417    lr: 0.0001     evaluation reward: 2.53\nepisode: 970   score: 1.0   memory length: 183449   epsilon: 0.834769000003587    steps: 150    lr: 0.0001     evaluation reward: 2.5\nepisode: 971   score: 3.0   memory length: 183677   epsilon: 0.8343175600035968    steps: 228    lr: 0.0001     evaluation reward: 2.5\nepisode: 972   score: 2.0   memory length: 183874   epsilon: 0.8339275000036053    steps: 197    lr: 0.0001     evaluation reward: 2.47\nepisode: 973   score: 1.0   memory length: 184025   epsilon: 0.8336285200036118    steps: 151    lr: 0.0001     evaluation reward: 2.47\nepisode: 974   score: 3.0   memory length: 184272   epsilon: 0.8331394600036224    steps: 247    lr: 0.0001     evaluation reward: 2.48\nepisode: 975   score: 5.0   memory length: 184597   epsilon: 0.8324959600036363    steps: 325    lr: 0.0001     evaluation reward: 2.52\nepisode: 976   score: 7.0   memory length: 185022   epsilon: 0.8316544600036546    steps: 425    lr: 0.0001     evaluation reward: 2.57\nepisode: 977   score: 4.0   memory length: 185320   epsilon: 0.8310644200036674    steps: 298    lr: 0.0001     evaluation reward: 2.57\nepisode: 978   score: 2.0   memory length: 185518   epsilon: 0.8306723800036759    steps: 198    lr: 0.0001     evaluation reward: 2.56\nepisode: 979   score: 2.0   memory length: 185698   epsilon: 0.8303159800036837    steps: 180    lr: 0.0001     evaluation reward: 2.56\nepisode: 980   score: 15.0   memory length: 186162   epsilon: 0.8293972600037036    steps: 464    lr: 0.0001     evaluation reward: 2.7\nepisode: 981   score: 4.0   memory length: 186458   epsilon: 0.8288111800037163    steps: 296    lr: 0.0001     evaluation reward: 2.73\nepisode: 982   score: 3.0   memory length: 186706   epsilon: 0.828320140003727    steps: 248    lr: 0.0001     evaluation reward: 2.73\nepisode: 983   score: 4.0   memory length: 186979   epsilon: 0.8277796000037387    steps: 273    lr: 0.0001     evaluation reward: 2.74\nepisode: 984   score: 1.0   memory length: 187148   epsilon: 0.827444980003746    steps: 169    lr: 0.0001     evaluation reward: 2.72\nepisode: 985   score: 2.0   memory length: 187345   epsilon: 0.8270549200037545    steps: 197    lr: 0.0001     evaluation reward: 2.7\nepisode: 986   score: 2.0   memory length: 187524   epsilon: 0.8267005000037622    steps: 179    lr: 0.0001     evaluation reward: 2.72\nepisode: 987   score: 1.0   memory length: 187693   epsilon: 0.8263658800037694    steps: 169    lr: 0.0001     evaluation reward: 2.7\nepisode: 988   score: 3.0   memory length: 187919   epsilon: 0.8259184000037791    steps: 226    lr: 0.0001     evaluation reward: 2.71\nepisode: 989   score: 2.0   memory length: 188117   epsilon: 0.8255263600037877    steps: 198    lr: 0.0001     evaluation reward: 2.73\nepisode: 990   score: 2.0   memory length: 188335   epsilon: 0.825094720003797    steps: 218    lr: 0.0001     evaluation reward: 2.69\nepisode: 991   score: 2.0   memory length: 188517   epsilon: 0.8247343600038048    steps: 182    lr: 0.0001     evaluation reward: 2.69\nepisode: 992   score: 1.0   memory length: 188687   epsilon: 0.8243977600038122    steps: 170    lr: 0.0001     evaluation reward: 2.69\nepisode: 993   score: 4.0   memory length: 188983   epsilon: 0.8238116800038249    steps: 296    lr: 0.0001     evaluation reward: 2.71\nepisode: 994   score: 3.0   memory length: 189250   epsilon: 0.8232830200038364    steps: 267    lr: 0.0001     evaluation reward: 2.72\nepisode: 995   score: 4.0   memory length: 189509   epsilon: 0.8227702000038475    steps: 259    lr: 0.0001     evaluation reward: 2.71\nepisode: 996   score: 2.0   memory length: 189728   epsilon: 0.8223365800038569    steps: 219    lr: 0.0001     evaluation reward: 2.73\nepisode: 997   score: 4.0   memory length: 190003   epsilon: 0.8217920800038687    steps: 275    lr: 0.0001     evaluation reward: 2.74\nepisode: 998   score: 7.0   memory length: 190404   epsilon: 0.820998100003886    steps: 401    lr: 0.0001     evaluation reward: 2.78\nepisode: 999   score: 4.0   memory length: 190677   epsilon: 0.8204575600038977    steps: 273    lr: 0.0001     evaluation reward: 2.79\nepisode: 1000   score: 3.0   memory length: 190925   epsilon: 0.8199665200039084    steps: 248    lr: 0.0001     evaluation reward: 2.82\nepisode: 1001   score: 3.0   memory length: 191173   epsilon: 0.819475480003919    steps: 248    lr: 0.0001     evaluation reward: 2.82\nepisode: 1002   score: 1.0   memory length: 191324   epsilon: 0.8191765000039255    steps: 151    lr: 0.0001     evaluation reward: 2.76\nepisode: 1003   score: 5.0   memory length: 191686   epsilon: 0.8184597400039411    steps: 362    lr: 0.0001     evaluation reward: 2.77\nepisode: 1004   score: 3.0   memory length: 191931   epsilon: 0.8179746400039516    steps: 245    lr: 0.0001     evaluation reward: 2.75\nepisode: 1005   score: 10.0   memory length: 192454   epsilon: 0.8169391000039741    steps: 523    lr: 0.0001     evaluation reward: 2.84\nepisode: 1006   score: 0.0   memory length: 192577   epsilon: 0.8166955600039794    steps: 123    lr: 0.0001     evaluation reward: 2.82\nepisode: 1007   score: 2.0   memory length: 192800   epsilon: 0.816254020003989    steps: 223    lr: 0.0001     evaluation reward: 2.82\nepisode: 1008   score: 3.0   memory length: 193046   epsilon: 0.8157669400039995    steps: 246    lr: 0.0001     evaluation reward: 2.84\nepisode: 1009   score: 4.0   memory length: 193322   epsilon: 0.8152204600040114    steps: 276    lr: 0.0001     evaluation reward: 2.87\nepisode: 1010   score: 2.0   memory length: 193520   epsilon: 0.8148284200040199    steps: 198    lr: 0.0001     evaluation reward: 2.84\nepisode: 1011   score: 1.0   memory length: 193671   epsilon: 0.8145294400040264    steps: 151    lr: 0.0001     evaluation reward: 2.83\nepisode: 1012   score: 1.0   memory length: 193840   epsilon: 0.8141948200040336    steps: 169    lr: 0.0001     evaluation reward: 2.81\nepisode: 1013   score: 4.0   memory length: 194099   epsilon: 0.8136820000040448    steps: 259    lr: 0.0001     evaluation reward: 2.85\nepisode: 1014   score: 1.0   memory length: 194269   epsilon: 0.8133454000040521    steps: 170    lr: 0.0001     evaluation reward: 2.86\nepisode: 1015   score: 4.0   memory length: 194545   epsilon: 0.812798920004064    steps: 276    lr: 0.0001     evaluation reward: 2.9\nepisode: 1016   score: 2.0   memory length: 194742   epsilon: 0.8124088600040724    steps: 197    lr: 0.0001     evaluation reward: 2.92\nepisode: 1017   score: 4.0   memory length: 195000   epsilon: 0.8118980200040835    steps: 258    lr: 0.0001     evaluation reward: 2.96\nepisode: 1018   score: 3.0   memory length: 195211   epsilon: 0.8114802400040926    steps: 211    lr: 0.0001     evaluation reward: 2.96\nepisode: 1019   score: 4.0   memory length: 195485   epsilon: 0.8109377200041044    steps: 274    lr: 0.0001     evaluation reward: 2.99\nepisode: 1020   score: 5.0   memory length: 195790   epsilon: 0.8103338200041175    steps: 305    lr: 0.0001     evaluation reward: 3.01\nepisode: 1021   score: 0.0   memory length: 195912   epsilon: 0.8100922600041227    steps: 122    lr: 0.0001     evaluation reward: 2.98\nepisode: 1022   score: 2.0   memory length: 196093   epsilon: 0.8097338800041305    steps: 181    lr: 0.0001     evaluation reward: 2.96\nepisode: 1023   score: 0.0   memory length: 196215   epsilon: 0.8094923200041357    steps: 122    lr: 0.0001     evaluation reward: 2.94\nepisode: 1024   score: 1.0   memory length: 196387   epsilon: 0.8091517600041431    steps: 172    lr: 0.0001     evaluation reward: 2.92\nepisode: 1025   score: 3.0   memory length: 196613   epsilon: 0.8087042800041528    steps: 226    lr: 0.0001     evaluation reward: 2.87\nepisode: 1026   score: 0.0   memory length: 196736   epsilon: 0.8084607400041581    steps: 123    lr: 0.0001     evaluation reward: 2.85\nepisode: 1027   score: 2.0   memory length: 196936   epsilon: 0.8080647400041667    steps: 200    lr: 0.0001     evaluation reward: 2.83\nepisode: 1028   score: 2.0   memory length: 197154   epsilon: 0.8076331000041761    steps: 218    lr: 0.0001     evaluation reward: 2.82\nepisode: 1029   score: 2.0   memory length: 197372   epsilon: 0.8072014600041855    steps: 218    lr: 0.0001     evaluation reward: 2.82\nepisode: 1030   score: 5.0   memory length: 197717   epsilon: 0.8065183600042003    steps: 345    lr: 0.0001     evaluation reward: 2.87\nepisode: 1031   score: 1.0   memory length: 197888   epsilon: 0.8061797800042076    steps: 171    lr: 0.0001     evaluation reward: 2.85\nepisode: 1032   score: 2.0   memory length: 198089   epsilon: 0.8057818000042163    steps: 201    lr: 0.0001     evaluation reward: 2.84\nepisode: 1033   score: 3.0   memory length: 198315   epsilon: 0.805334320004226    steps: 226    lr: 0.0001     evaluation reward: 2.84\nepisode: 1034   score: 0.0   memory length: 198438   epsilon: 0.8050907800042313    steps: 123    lr: 0.0001     evaluation reward: 2.81\nepisode: 1035   score: 6.0   memory length: 198834   epsilon: 0.8043067000042483    steps: 396    lr: 0.0001     evaluation reward: 2.84\nepisode: 1036   score: 3.0   memory length: 199079   epsilon: 0.8038216000042588    steps: 245    lr: 0.0001     evaluation reward: 2.84\nepisode: 1037   score: 2.0   memory length: 199277   epsilon: 0.8034295600042674    steps: 198    lr: 0.0001     evaluation reward: 2.86\nepisode: 1038   score: 3.0   memory length: 199526   epsilon: 0.802936540004278    steps: 249    lr: 0.0001     evaluation reward: 2.85\nepisode: 1039   score: 2.0   memory length: 199725   epsilon: 0.8025425200042866    steps: 199    lr: 0.0001     evaluation reward: 2.82\nepisode: 1040   score: 3.0   memory length: 199951   epsilon: 0.8020950400042963    steps: 226    lr: 0.0001     evaluation reward: 2.82\nepisode: 1041   score: 3.0   memory length: 200198   epsilon: 0.8016059800043069    steps: 247    lr: 4e-05     evaluation reward: 2.85\nepisode: 1042   score: 3.0   memory length: 200425   epsilon: 0.8011565200043167    steps: 227    lr: 4e-05     evaluation reward: 2.85\nepisode: 1043   score: 4.0   memory length: 200685   epsilon: 0.8006417200043279    steps: 260    lr: 4e-05     evaluation reward: 2.88\nepisode: 1044   score: 1.0   memory length: 200855   epsilon: 0.8003051200043352    steps: 170    lr: 4e-05     evaluation reward: 2.87\nepisode: 1045   score: 3.0   memory length: 201084   epsilon: 0.799851700004345    steps: 229    lr: 4e-05     evaluation reward: 2.87\nepisode: 1046   score: 3.0   memory length: 201353   epsilon: 0.7993190800043566    steps: 269    lr: 4e-05     evaluation reward: 2.85\nepisode: 1047   score: 3.0   memory length: 201566   epsilon: 0.7988973400043657    steps: 213    lr: 4e-05     evaluation reward: 2.86\nepisode: 1048   score: 2.0   memory length: 201764   epsilon: 0.7985053000043743    steps: 198    lr: 4e-05     evaluation reward: 2.86\nepisode: 1049   score: 3.0   memory length: 201993   epsilon: 0.7980518800043841    steps: 229    lr: 4e-05     evaluation reward: 2.88\nepisode: 1050   score: 2.0   memory length: 202211   epsilon: 0.7976202400043935    steps: 218    lr: 4e-05     evaluation reward: 2.85\nepisode: 1051   score: 3.0   memory length: 202436   epsilon: 0.7971747400044031    steps: 225    lr: 4e-05     evaluation reward: 2.85\nepisode: 1052   score: 6.0   memory length: 202775   epsilon: 0.7965035200044177    steps: 339    lr: 4e-05     evaluation reward: 2.9\nepisode: 1053   score: 4.0   memory length: 203070   epsilon: 0.7959194200044304    steps: 295    lr: 4e-05     evaluation reward: 2.92\nepisode: 1054   score: 8.0   memory length: 203510   epsilon: 0.7950482200044493    steps: 440    lr: 4e-05     evaluation reward: 2.98\nepisode: 1055   score: 4.0   memory length: 203825   epsilon: 0.7944245200044628    steps: 315    lr: 4e-05     evaluation reward: 3.02\nepisode: 1056   score: 0.0   memory length: 203947   epsilon: 0.7941829600044681    steps: 122    lr: 4e-05     evaluation reward: 2.99\nepisode: 1057   score: 3.0   memory length: 204175   epsilon: 0.7937315200044779    steps: 228    lr: 4e-05     evaluation reward: 3.01\nepisode: 1058   score: 3.0   memory length: 204407   epsilon: 0.7932721600044879    steps: 232    lr: 4e-05     evaluation reward: 3.01\nepisode: 1059   score: 3.0   memory length: 204636   epsilon: 0.7928187400044977    steps: 229    lr: 4e-05     evaluation reward: 2.97\nepisode: 1060   score: 4.0   memory length: 204898   epsilon: 0.792299980004509    steps: 262    lr: 4e-05     evaluation reward: 2.98\nepisode: 1061   score: 3.0   memory length: 205129   epsilon: 0.7918426000045189    steps: 231    lr: 4e-05     evaluation reward: 3.0\nepisode: 1062   score: 3.0   memory length: 205361   epsilon: 0.7913832400045289    steps: 232    lr: 4e-05     evaluation reward: 3.0\nepisode: 1063   score: 4.0   memory length: 205605   epsilon: 0.7909001200045394    steps: 244    lr: 4e-05     evaluation reward: 3.01\nepisode: 1064   score: 2.0   memory length: 205808   epsilon: 0.7904981800045481    steps: 203    lr: 4e-05     evaluation reward: 3.0\nepisode: 1065   score: 3.0   memory length: 206034   epsilon: 0.7900507000045578    steps: 226    lr: 4e-05     evaluation reward: 3.01\nepisode: 1066   score: 4.0   memory length: 206323   epsilon: 0.7894784800045702    steps: 289    lr: 4e-05     evaluation reward: 3.02\nepisode: 1067   score: 4.0   memory length: 206600   epsilon: 0.7889300200045821    steps: 277    lr: 4e-05     evaluation reward: 3.04\nepisode: 1068   score: 5.0   memory length: 206929   epsilon: 0.7882786000045963    steps: 329    lr: 4e-05     evaluation reward: 3.07\nepisode: 1069   score: 3.0   memory length: 207160   epsilon: 0.7878212200046062    steps: 231    lr: 4e-05     evaluation reward: 3.03\nepisode: 1070   score: 1.0   memory length: 207312   epsilon: 0.7875202600046127    steps: 152    lr: 4e-05     evaluation reward: 3.03\nepisode: 1071   score: 4.0   memory length: 207607   epsilon: 0.7869361600046254    steps: 295    lr: 4e-05     evaluation reward: 3.04\nepisode: 1072   score: 4.0   memory length: 207904   epsilon: 0.7863481000046382    steps: 297    lr: 4e-05     evaluation reward: 3.06\nepisode: 1073   score: 4.0   memory length: 208202   epsilon: 0.785758060004651    steps: 298    lr: 4e-05     evaluation reward: 3.09\nepisode: 1074   score: 0.0   memory length: 208325   epsilon: 0.7855145200046563    steps: 123    lr: 4e-05     evaluation reward: 3.06\nepisode: 1075   score: 4.0   memory length: 208585   epsilon: 0.7849997200046674    steps: 260    lr: 4e-05     evaluation reward: 3.05\nepisode: 1076   score: 3.0   memory length: 208811   epsilon: 0.7845522400046772    steps: 226    lr: 4e-05     evaluation reward: 3.01\nepisode: 1077   score: 5.0   memory length: 209119   epsilon: 0.7839424000046904    steps: 308    lr: 4e-05     evaluation reward: 3.02\nepisode: 1078   score: 2.0   memory length: 209317   epsilon: 0.7835503600046989    steps: 198    lr: 4e-05     evaluation reward: 3.02\nepisode: 1079   score: 2.0   memory length: 209534   epsilon: 0.7831207000047082    steps: 217    lr: 4e-05     evaluation reward: 3.02\nepisode: 1080   score: 2.0   memory length: 209732   epsilon: 0.7827286600047167    steps: 198    lr: 4e-05     evaluation reward: 2.89\nepisode: 1081   score: 2.0   memory length: 209930   epsilon: 0.7823366200047253    steps: 198    lr: 4e-05     evaluation reward: 2.87\nepisode: 1082   score: 4.0   memory length: 210184   epsilon: 0.7818337000047362    steps: 254    lr: 4e-05     evaluation reward: 2.88\nepisode: 1083   score: 3.0   memory length: 210431   epsilon: 0.7813446400047468    steps: 247    lr: 4e-05     evaluation reward: 2.87\nepisode: 1084   score: 5.0   memory length: 210735   epsilon: 0.7807427200047599    steps: 304    lr: 4e-05     evaluation reward: 2.91\nepisode: 1085   score: 2.0   memory length: 210915   epsilon: 0.7803863200047676    steps: 180    lr: 4e-05     evaluation reward: 2.91\nepisode: 1086   score: 4.0   memory length: 211226   epsilon: 0.779770540004781    steps: 311    lr: 4e-05     evaluation reward: 2.93\nepisode: 1087   score: 0.0   memory length: 211349   epsilon: 0.7795270000047863    steps: 123    lr: 4e-05     evaluation reward: 2.92\nepisode: 1088   score: 7.0   memory length: 211746   epsilon: 0.7787409400048033    steps: 397    lr: 4e-05     evaluation reward: 2.96\nepisode: 1089   score: 5.0   memory length: 212054   epsilon: 0.7781311000048166    steps: 308    lr: 4e-05     evaluation reward: 2.99\nepisode: 1090   score: 2.0   memory length: 212234   epsilon: 0.7777747000048243    steps: 180    lr: 4e-05     evaluation reward: 2.99\nepisode: 1091   score: 4.0   memory length: 212509   epsilon: 0.7772302000048361    steps: 275    lr: 4e-05     evaluation reward: 3.01\nepisode: 1092   score: 3.0   memory length: 212774   epsilon: 0.7767055000048475    steps: 265    lr: 4e-05     evaluation reward: 3.03\nepisode: 1093   score: 4.0   memory length: 213064   epsilon: 0.77613130000486    steps: 290    lr: 4e-05     evaluation reward: 3.03\nepisode: 1094   score: 3.0   memory length: 213311   epsilon: 0.7756422400048706    steps: 247    lr: 4e-05     evaluation reward: 3.03\nepisode: 1095   score: 4.0   memory length: 213586   epsilon: 0.7750977400048824    steps: 275    lr: 4e-05     evaluation reward: 3.03\nepisode: 1096   score: 8.0   memory length: 214019   epsilon: 0.774240400004901    steps: 433    lr: 4e-05     evaluation reward: 3.09\nepisode: 1097   score: 4.0   memory length: 214294   epsilon: 0.7736959000049128    steps: 275    lr: 4e-05     evaluation reward: 3.09\nepisode: 1098   score: 5.0   memory length: 214639   epsilon: 0.7730128000049277    steps: 345    lr: 4e-05     evaluation reward: 3.07\nepisode: 1099   score: 1.0   memory length: 214790   epsilon: 0.7727138200049342    steps: 151    lr: 4e-05     evaluation reward: 3.04\nepisode: 1100   score: 2.0   memory length: 214988   epsilon: 0.7723217800049427    steps: 198    lr: 4e-05     evaluation reward: 3.03\nepisode: 1101   score: 2.0   memory length: 215205   epsilon: 0.771892120004952    steps: 217    lr: 4e-05     evaluation reward: 3.02\nepisode: 1102   score: 3.0   memory length: 215471   epsilon: 0.7713654400049634    steps: 266    lr: 4e-05     evaluation reward: 3.04\nepisode: 1103   score: 4.0   memory length: 215768   epsilon: 0.7707773800049762    steps: 297    lr: 4e-05     evaluation reward: 3.03\nepisode: 1104   score: 4.0   memory length: 216065   epsilon: 0.770189320004989    steps: 297    lr: 4e-05     evaluation reward: 3.04\nepisode: 1105   score: 4.0   memory length: 216346   epsilon: 0.769632940005001    steps: 281    lr: 4e-05     evaluation reward: 2.98\nepisode: 1106   score: 3.0   memory length: 216572   epsilon: 0.7691854600050108    steps: 226    lr: 4e-05     evaluation reward: 3.01\nepisode: 1107   score: 5.0   memory length: 216899   epsilon: 0.7685380000050248    steps: 327    lr: 4e-05     evaluation reward: 3.04\nepisode: 1108   score: 2.0   memory length: 217099   epsilon: 0.7681420000050334    steps: 200    lr: 4e-05     evaluation reward: 3.03\nepisode: 1109   score: 5.0   memory length: 217428   epsilon: 0.7674905800050476    steps: 329    lr: 4e-05     evaluation reward: 3.04\nepisode: 1110   score: 4.0   memory length: 217702   epsilon: 0.7669480600050593    steps: 274    lr: 4e-05     evaluation reward: 3.06\nepisode: 1111   score: 4.0   memory length: 217997   epsilon: 0.766363960005072    steps: 295    lr: 4e-05     evaluation reward: 3.09\nepisode: 1112   score: 4.0   memory length: 218257   epsilon: 0.7658491600050832    steps: 260    lr: 4e-05     evaluation reward: 3.12\nepisode: 1113   score: 1.0   memory length: 218425   epsilon: 0.7655165200050904    steps: 168    lr: 4e-05     evaluation reward: 3.09\nepisode: 1114   score: 5.0   memory length: 218771   epsilon: 0.7648314400051053    steps: 346    lr: 4e-05     evaluation reward: 3.13\nepisode: 1115   score: 5.0   memory length: 219115   epsilon: 0.7641503200051201    steps: 344    lr: 4e-05     evaluation reward: 3.14\nepisode: 1116   score: 1.0   memory length: 219284   epsilon: 0.7638157000051273    steps: 169    lr: 4e-05     evaluation reward: 3.13\nepisode: 1117   score: 8.0   memory length: 219700   epsilon: 0.7629920200051452    steps: 416    lr: 4e-05     evaluation reward: 3.17\nepisode: 1118   score: 2.0   memory length: 219918   epsilon: 0.7625603800051546    steps: 218    lr: 4e-05     evaluation reward: 3.16\nepisode: 1119   score: 5.0   memory length: 220222   epsilon: 0.7619584600051676    steps: 304    lr: 4e-05     evaluation reward: 3.17\nepisode: 1120   score: 6.0   memory length: 220598   epsilon: 0.7612139800051838    steps: 376    lr: 4e-05     evaluation reward: 3.18\nepisode: 1121   score: 3.0   memory length: 220865   epsilon: 0.7606853200051953    steps: 267    lr: 4e-05     evaluation reward: 3.21\nepisode: 1122   score: 2.0   memory length: 221045   epsilon: 0.760328920005203    steps: 180    lr: 4e-05     evaluation reward: 3.21\nepisode: 1123   score: 2.0   memory length: 221263   epsilon: 0.7598972800052124    steps: 218    lr: 4e-05     evaluation reward: 3.23\nepisode: 1124   score: 6.0   memory length: 221631   epsilon: 0.7591686400052282    steps: 368    lr: 4e-05     evaluation reward: 3.28\nepisode: 1125   score: 2.0   memory length: 221853   epsilon: 0.7587290800052378    steps: 222    lr: 4e-05     evaluation reward: 3.27\nepisode: 1126   score: 2.0   memory length: 222073   epsilon: 0.7582934800052472    steps: 220    lr: 4e-05     evaluation reward: 3.29\nepisode: 1127   score: 2.0   memory length: 222271   epsilon: 0.7579014400052557    steps: 198    lr: 4e-05     evaluation reward: 3.29\nepisode: 1128   score: 3.0   memory length: 222521   epsilon: 0.7574064400052665    steps: 250    lr: 4e-05     evaluation reward: 3.3\nepisode: 1129   score: 7.0   memory length: 222946   epsilon: 0.7565649400052847    steps: 425    lr: 4e-05     evaluation reward: 3.35\nepisode: 1130   score: 6.0   memory length: 223323   epsilon: 0.7558184800053009    steps: 377    lr: 4e-05     evaluation reward: 3.36\nepisode: 1131   score: 3.0   memory length: 223549   epsilon: 0.7553710000053107    steps: 226    lr: 4e-05     evaluation reward: 3.38\nepisode: 1132   score: 5.0   memory length: 223915   epsilon: 0.7546463200053264    steps: 366    lr: 4e-05     evaluation reward: 3.41\nepisode: 1133   score: 6.0   memory length: 224261   epsilon: 0.7539612400053413    steps: 346    lr: 4e-05     evaluation reward: 3.44\nepisode: 1134   score: 1.0   memory length: 224412   epsilon: 0.7536622600053478    steps: 151    lr: 4e-05     evaluation reward: 3.45\nepisode: 1135   score: 4.0   memory length: 224671   epsilon: 0.7531494400053589    steps: 259    lr: 4e-05     evaluation reward: 3.43\nepisode: 1136   score: 3.0   memory length: 224898   epsilon: 0.7526999800053686    steps: 227    lr: 4e-05     evaluation reward: 3.43\nepisode: 1137   score: 5.0   memory length: 225244   epsilon: 0.7520149000053835    steps: 346    lr: 4e-05     evaluation reward: 3.46\nepisode: 1138   score: 5.0   memory length: 225568   epsilon: 0.7513733800053974    steps: 324    lr: 4e-05     evaluation reward: 3.48\nepisode: 1139   score: 6.0   memory length: 225942   epsilon: 0.7506328600054135    steps: 374    lr: 4e-05     evaluation reward: 3.52\nepisode: 1140   score: 3.0   memory length: 226168   epsilon: 0.7501853800054232    steps: 226    lr: 4e-05     evaluation reward: 3.52\nepisode: 1141   score: 2.0   memory length: 226369   epsilon: 0.7497874000054319    steps: 201    lr: 4e-05     evaluation reward: 3.51\nepisode: 1142   score: 3.0   memory length: 226595   epsilon: 0.7493399200054416    steps: 226    lr: 4e-05     evaluation reward: 3.51\nepisode: 1143   score: 7.0   memory length: 226990   epsilon: 0.7485578200054586    steps: 395    lr: 4e-05     evaluation reward: 3.54\nepisode: 1144   score: 6.0   memory length: 227355   epsilon: 0.7478351200054743    steps: 365    lr: 4e-05     evaluation reward: 3.59\nepisode: 1145   score: 4.0   memory length: 227633   epsilon: 0.7472846800054862    steps: 278    lr: 4e-05     evaluation reward: 3.6\nepisode: 1146   score: 4.0   memory length: 227893   epsilon: 0.7467698800054974    steps: 260    lr: 4e-05     evaluation reward: 3.61\nepisode: 1147   score: 2.0   memory length: 228075   epsilon: 0.7464095200055052    steps: 182    lr: 4e-05     evaluation reward: 3.6\nepisode: 1148   score: 5.0   memory length: 228400   epsilon: 0.7457660200055192    steps: 325    lr: 4e-05     evaluation reward: 3.63\nepisode: 1149   score: 5.0   memory length: 228704   epsilon: 0.7451641000055322    steps: 304    lr: 4e-05     evaluation reward: 3.65\nepisode: 1150   score: 1.0   memory length: 228855   epsilon: 0.7448651200055387    steps: 151    lr: 4e-05     evaluation reward: 3.64\nepisode: 1151   score: 5.0   memory length: 229162   epsilon: 0.7442572600055519    steps: 307    lr: 4e-05     evaluation reward: 3.66\nepisode: 1152   score: 2.0   memory length: 229380   epsilon: 0.7438256200055613    steps: 218    lr: 4e-05     evaluation reward: 3.62\nepisode: 1153   score: 4.0   memory length: 229640   epsilon: 0.7433108200055725    steps: 260    lr: 4e-05     evaluation reward: 3.62\nepisode: 1154   score: 3.0   memory length: 229866   epsilon: 0.7428633400055822    steps: 226    lr: 4e-05     evaluation reward: 3.57\nepisode: 1155   score: 5.0   memory length: 230175   epsilon: 0.7422515200055955    steps: 309    lr: 4e-05     evaluation reward: 3.58\nepisode: 1156   score: 4.0   memory length: 230416   epsilon: 0.7417743400056058    steps: 241    lr: 4e-05     evaluation reward: 3.62\nepisode: 1157   score: 2.0   memory length: 230635   epsilon: 0.7413407200056152    steps: 219    lr: 4e-05     evaluation reward: 3.61\nepisode: 1158   score: 6.0   memory length: 231030   epsilon: 0.7405586200056322    steps: 395    lr: 4e-05     evaluation reward: 3.64\nepisode: 1159   score: 7.0   memory length: 231399   epsilon: 0.7398280000056481    steps: 369    lr: 4e-05     evaluation reward: 3.68\nepisode: 1160   score: 3.0   memory length: 231628   epsilon: 0.7393745800056579    steps: 229    lr: 4e-05     evaluation reward: 3.67\nepisode: 1161   score: 4.0   memory length: 231900   epsilon: 0.7388360200056696    steps: 272    lr: 4e-05     evaluation reward: 3.68\nepisode: 1162   score: 4.0   memory length: 232177   epsilon: 0.7382875600056815    steps: 277    lr: 4e-05     evaluation reward: 3.69\nepisode: 1163   score: 3.0   memory length: 232403   epsilon: 0.7378400800056912    steps: 226    lr: 4e-05     evaluation reward: 3.68\nepisode: 1164   score: 2.0   memory length: 232601   epsilon: 0.7374480400056997    steps: 198    lr: 4e-05     evaluation reward: 3.68\nepisode: 1165   score: 3.0   memory length: 232829   epsilon: 0.7369966000057095    steps: 228    lr: 4e-05     evaluation reward: 3.68\nepisode: 1166   score: 3.0   memory length: 233054   epsilon: 0.7365511000057192    steps: 225    lr: 4e-05     evaluation reward: 3.67\nepisode: 1167   score: 4.0   memory length: 233313   epsilon: 0.7360382800057303    steps: 259    lr: 4e-05     evaluation reward: 3.67\nepisode: 1168   score: 11.0   memory length: 233881   epsilon: 0.7349136400057548    steps: 568    lr: 4e-05     evaluation reward: 3.73\nepisode: 1169   score: 3.0   memory length: 234111   epsilon: 0.7344582400057647    steps: 230    lr: 4e-05     evaluation reward: 3.73\nepisode: 1170   score: 0.0   memory length: 234234   epsilon: 0.7342147000057699    steps: 123    lr: 4e-05     evaluation reward: 3.72\nepisode: 1171   score: 13.0   memory length: 234653   epsilon: 0.733385080005788    steps: 419    lr: 4e-05     evaluation reward: 3.81\nepisode: 1172   score: 7.0   memory length: 235025   epsilon: 0.7326485200058039    steps: 372    lr: 4e-05     evaluation reward: 3.84\nepisode: 1173   score: 6.0   memory length: 235417   epsilon: 0.7318723600058208    steps: 392    lr: 4e-05     evaluation reward: 3.86\nepisode: 1174   score: 7.0   memory length: 235771   epsilon: 0.731171440005836    steps: 354    lr: 4e-05     evaluation reward: 3.93\nepisode: 1175   score: 1.0   memory length: 235942   epsilon: 0.7308328600058434    steps: 171    lr: 4e-05     evaluation reward: 3.9\nepisode: 1176   score: 2.0   memory length: 236139   epsilon: 0.7304428000058518    steps: 197    lr: 4e-05     evaluation reward: 3.89\nepisode: 1177   score: 2.0   memory length: 236337   epsilon: 0.7300507600058603    steps: 198    lr: 4e-05     evaluation reward: 3.86\nepisode: 1178   score: 3.0   memory length: 236584   epsilon: 0.729561700005871    steps: 247    lr: 4e-05     evaluation reward: 3.87\nepisode: 1179   score: 6.0   memory length: 236931   epsilon: 0.7288746400058859    steps: 347    lr: 4e-05     evaluation reward: 3.91\nepisode: 1180   score: 3.0   memory length: 237160   epsilon: 0.7284212200058957    steps: 229    lr: 4e-05     evaluation reward: 3.92\nepisode: 1181   score: 5.0   memory length: 237484   epsilon: 0.7277797000059096    steps: 324    lr: 4e-05     evaluation reward: 3.95\nepisode: 1182   score: 3.0   memory length: 237717   epsilon: 0.7273183600059197    steps: 233    lr: 4e-05     evaluation reward: 3.94\nepisode: 1183   score: 3.0   memory length: 237928   epsilon: 0.7269005800059287    steps: 211    lr: 4e-05     evaluation reward: 3.94\nepisode: 1184   score: 2.0   memory length: 238126   epsilon: 0.7265085400059372    steps: 198    lr: 4e-05     evaluation reward: 3.91\nepisode: 1185   score: 10.0   memory length: 238670   epsilon: 0.7254314200059606    steps: 544    lr: 4e-05     evaluation reward: 3.99\nepisode: 1186   score: 6.0   memory length: 239009   epsilon: 0.7247602000059752    steps: 339    lr: 4e-05     evaluation reward: 4.01\nepisode: 1187   score: 9.0   memory length: 239506   epsilon: 0.7237761400059965    steps: 497    lr: 4e-05     evaluation reward: 4.1\nepisode: 1188   score: 2.0   memory length: 239703   epsilon: 0.723386080006005    steps: 197    lr: 4e-05     evaluation reward: 4.05\nepisode: 1189   score: 3.0   memory length: 239949   epsilon: 0.7228990000060156    steps: 246    lr: 4e-05     evaluation reward: 4.03\nepisode: 1190   score: 0.0   memory length: 240072   epsilon: 0.7226554600060209    steps: 123    lr: 4e-05     evaluation reward: 4.01\nepisode: 1191   score: 2.0   memory length: 240253   epsilon: 0.7222970800060287    steps: 181    lr: 4e-05     evaluation reward: 3.99\nepisode: 1192   score: 0.0   memory length: 240376   epsilon: 0.722053540006034    steps: 123    lr: 4e-05     evaluation reward: 3.96\nepisode: 1193   score: 6.0   memory length: 240736   epsilon: 0.7213407400060494    steps: 360    lr: 4e-05     evaluation reward: 3.98\nepisode: 1194   score: 7.0   memory length: 241057   epsilon: 0.7207051600060632    steps: 321    lr: 4e-05     evaluation reward: 4.02\nepisode: 1195   score: 7.0   memory length: 241441   epsilon: 0.7199448400060797    steps: 384    lr: 4e-05     evaluation reward: 4.05\nepisode: 1196   score: 7.0   memory length: 241850   epsilon: 0.7191350200060973    steps: 409    lr: 4e-05     evaluation reward: 4.04\nepisode: 1197   score: 2.0   memory length: 242052   epsilon: 0.718735060006106    steps: 202    lr: 4e-05     evaluation reward: 4.02\nepisode: 1198   score: 3.0   memory length: 242302   epsilon: 0.7182400600061167    steps: 250    lr: 4e-05     evaluation reward: 4.0\nepisode: 1199   score: 0.0   memory length: 242425   epsilon: 0.717996520006122    steps: 123    lr: 4e-05     evaluation reward: 3.99\nepisode: 1200   score: 0.0   memory length: 242548   epsilon: 0.7177529800061273    steps: 123    lr: 4e-05     evaluation reward: 3.97\nepisode: 1201   score: 1.0   memory length: 242699   epsilon: 0.7174540000061338    steps: 151    lr: 4e-05     evaluation reward: 3.96\nepisode: 1202   score: 4.0   memory length: 242959   epsilon: 0.716939200006145    steps: 260    lr: 4e-05     evaluation reward: 3.97\nepisode: 1203   score: 4.0   memory length: 243215   epsilon: 0.716432320006156    steps: 256    lr: 4e-05     evaluation reward: 3.97\nepisode: 1204   score: 5.0   memory length: 243540   epsilon: 0.71578882000617    steps: 325    lr: 4e-05     evaluation reward: 3.98\nepisode: 1205   score: 4.0   memory length: 243801   epsilon: 0.7152720400061812    steps: 261    lr: 4e-05     evaluation reward: 3.98\nepisode: 1206   score: 5.0   memory length: 244106   epsilon: 0.7146681400061943    steps: 305    lr: 4e-05     evaluation reward: 4.0\nepisode: 1207   score: 3.0   memory length: 244352   epsilon: 0.7141810600062048    steps: 246    lr: 4e-05     evaluation reward: 3.98\nepisode: 1208   score: 4.0   memory length: 244645   epsilon: 0.7136009200062174    steps: 293    lr: 4e-05     evaluation reward: 4.0\nepisode: 1209   score: 5.0   memory length: 244945   epsilon: 0.7130069200062303    steps: 300    lr: 4e-05     evaluation reward: 4.0\nepisode: 1210   score: 4.0   memory length: 245255   epsilon: 0.7123931200062437    steps: 310    lr: 4e-05     evaluation reward: 4.0\nepisode: 1211   score: 8.0   memory length: 245715   epsilon: 0.7114823200062634    steps: 460    lr: 4e-05     evaluation reward: 4.04\nepisode: 1212   score: 5.0   memory length: 246003   epsilon: 0.7109120800062758    steps: 288    lr: 4e-05     evaluation reward: 4.05\nepisode: 1213   score: 8.0   memory length: 246418   epsilon: 0.7100903800062937    steps: 415    lr: 4e-05     evaluation reward: 4.12\nepisode: 1214   score: 4.0   memory length: 246694   epsilon: 0.7095439000063055    steps: 276    lr: 4e-05     evaluation reward: 4.11\nepisode: 1215   score: 6.0   memory length: 247085   epsilon: 0.7087697200063223    steps: 391    lr: 4e-05     evaluation reward: 4.12\nepisode: 1216   score: 2.0   memory length: 247285   epsilon: 0.7083737200063309    steps: 200    lr: 4e-05     evaluation reward: 4.13\nepisode: 1217   score: 4.0   memory length: 247560   epsilon: 0.7078292200063427    steps: 275    lr: 4e-05     evaluation reward: 4.09\nepisode: 1218   score: 6.0   memory length: 247896   epsilon: 0.7071639400063572    steps: 336    lr: 4e-05     evaluation reward: 4.13\nepisode: 1219   score: 4.0   memory length: 248173   epsilon: 0.7066154800063691    steps: 277    lr: 4e-05     evaluation reward: 4.12\nepisode: 1220   score: 4.0   memory length: 248473   epsilon: 0.706021480006382    steps: 300    lr: 4e-05     evaluation reward: 4.1\nepisode: 1221   score: 4.0   memory length: 248769   epsilon: 0.7054354000063947    steps: 296    lr: 4e-05     evaluation reward: 4.11\nepisode: 1222   score: 5.0   memory length: 249073   epsilon: 0.7048334800064078    steps: 304    lr: 4e-05     evaluation reward: 4.14\nepisode: 1223   score: 6.0   memory length: 249428   epsilon: 0.704130580006423    steps: 355    lr: 4e-05     evaluation reward: 4.18\nepisode: 1224   score: 3.0   memory length: 249654   epsilon: 0.7036831000064327    steps: 226    lr: 4e-05     evaluation reward: 4.15\nepisode: 1225   score: 2.0   memory length: 249854   epsilon: 0.7032871000064413    steps: 200    lr: 4e-05     evaluation reward: 4.15\nepisode: 1226   score: 6.0   memory length: 250210   epsilon: 0.7025822200064566    steps: 356    lr: 4e-05     evaluation reward: 4.19\nepisode: 1227   score: 5.0   memory length: 250515   epsilon: 0.7019783200064698    steps: 305    lr: 4e-05     evaluation reward: 4.22\nepisode: 1228   score: 2.0   memory length: 250713   epsilon: 0.7015862800064783    steps: 198    lr: 4e-05     evaluation reward: 4.21\nepisode: 1229   score: 5.0   memory length: 251014   epsilon: 0.7009903000064912    steps: 301    lr: 4e-05     evaluation reward: 4.19\nepisode: 1230   score: 6.0   memory length: 251331   epsilon: 0.7003626400065048    steps: 317    lr: 4e-05     evaluation reward: 4.19\nepisode: 1231   score: 6.0   memory length: 251721   epsilon: 0.6995904400065216    steps: 390    lr: 4e-05     evaluation reward: 4.22\nepisode: 1232   score: 5.0   memory length: 252046   epsilon: 0.6989469400065356    steps: 325    lr: 4e-05     evaluation reward: 4.22\nepisode: 1233   score: 6.0   memory length: 252362   epsilon: 0.6983212600065491    steps: 316    lr: 4e-05     evaluation reward: 4.22\nepisode: 1234   score: 3.0   memory length: 252573   epsilon: 0.6979034800065582    steps: 211    lr: 4e-05     evaluation reward: 4.24\nepisode: 1235   score: 6.0   memory length: 252912   epsilon: 0.6972322600065728    steps: 339    lr: 4e-05     evaluation reward: 4.26\nepisode: 1236   score: 7.0   memory length: 253310   epsilon: 0.6964442200065899    steps: 398    lr: 4e-05     evaluation reward: 4.3\nepisode: 1237   score: 4.0   memory length: 253582   epsilon: 0.6959056600066016    steps: 272    lr: 4e-05     evaluation reward: 4.29\nepisode: 1238   score: 3.0   memory length: 253826   epsilon: 0.6954225400066121    steps: 244    lr: 4e-05     evaluation reward: 4.27\nepisode: 1239   score: 2.0   memory length: 254026   epsilon: 0.6950265400066207    steps: 200    lr: 4e-05     evaluation reward: 4.23\nepisode: 1240   score: 3.0   memory length: 254256   epsilon: 0.6945711400066306    steps: 230    lr: 4e-05     evaluation reward: 4.23\nepisode: 1241   score: 7.0   memory length: 254610   epsilon: 0.6938702200066458    steps: 354    lr: 4e-05     evaluation reward: 4.28\nepisode: 1242   score: 0.0   memory length: 254733   epsilon: 0.6936266800066511    steps: 123    lr: 4e-05     evaluation reward: 4.25\nepisode: 1243   score: 6.0   memory length: 255067   epsilon: 0.6929653600066654    steps: 334    lr: 4e-05     evaluation reward: 4.24\nepisode: 1244   score: 3.0   memory length: 255295   epsilon: 0.6925139200066752    steps: 228    lr: 4e-05     evaluation reward: 4.21\nepisode: 1245   score: 5.0   memory length: 255623   epsilon: 0.6918644800066893    steps: 328    lr: 4e-05     evaluation reward: 4.22\nepisode: 1246   score: 8.0   memory length: 256053   epsilon: 0.6910130800067078    steps: 430    lr: 4e-05     evaluation reward: 4.26\nepisode: 1247   score: 3.0   memory length: 256297   epsilon: 0.6905299600067183    steps: 244    lr: 4e-05     evaluation reward: 4.27\nepisode: 1248   score: 4.0   memory length: 256551   epsilon: 0.6900270400067292    steps: 254    lr: 4e-05     evaluation reward: 4.26\nepisode: 1249   score: 3.0   memory length: 256777   epsilon: 0.6895795600067389    steps: 226    lr: 4e-05     evaluation reward: 4.24\nepisode: 1250   score: 7.0   memory length: 257127   epsilon: 0.688886560006754    steps: 350    lr: 4e-05     evaluation reward: 4.3\nepisode: 1251   score: 4.0   memory length: 257403   epsilon: 0.6883400800067658    steps: 276    lr: 4e-05     evaluation reward: 4.29\nepisode: 1252   score: 11.0   memory length: 257938   epsilon: 0.6872807800067888    steps: 535    lr: 4e-05     evaluation reward: 4.38\nepisode: 1253   score: 7.0   memory length: 258307   epsilon: 0.6865501600068047    steps: 369    lr: 4e-05     evaluation reward: 4.41\nepisode: 1254   score: 4.0   memory length: 258624   epsilon: 0.6859225000068183    steps: 317    lr: 4e-05     evaluation reward: 4.42\nepisode: 1255   score: 5.0   memory length: 258934   epsilon: 0.6853087000068316    steps: 310    lr: 4e-05     evaluation reward: 4.42\nepisode: 1256   score: 5.0   memory length: 259255   epsilon: 0.6846731200068454    steps: 321    lr: 4e-05     evaluation reward: 4.43\nepisode: 1257   score: 5.0   memory length: 259566   epsilon: 0.6840573400068588    steps: 311    lr: 4e-05     evaluation reward: 4.46\nepisode: 1258   score: 8.0   memory length: 260006   epsilon: 0.6831861400068777    steps: 440    lr: 4e-05     evaluation reward: 4.48\nepisode: 1259   score: 7.0   memory length: 260401   epsilon: 0.6824040400068947    steps: 395    lr: 4e-05     evaluation reward: 4.48\nepisode: 1260   score: 6.0   memory length: 260775   epsilon: 0.6816635200069108    steps: 374    lr: 4e-05     evaluation reward: 4.51\nepisode: 1261   score: 4.0   memory length: 261050   epsilon: 0.6811190200069226    steps: 275    lr: 4e-05     evaluation reward: 4.51\nepisode: 1262   score: 3.0   memory length: 261281   epsilon: 0.6806616400069325    steps: 231    lr: 4e-05     evaluation reward: 4.5\nepisode: 1263   score: 3.0   memory length: 261549   epsilon: 0.680131000006944    steps: 268    lr: 4e-05     evaluation reward: 4.5\nepisode: 1264   score: 4.0   memory length: 261805   epsilon: 0.679624120006955    steps: 256    lr: 4e-05     evaluation reward: 4.52\nepisode: 1265   score: 2.0   memory length: 261985   epsilon: 0.6792677200069628    steps: 180    lr: 4e-05     evaluation reward: 4.51\nepisode: 1266   score: 4.0   memory length: 262261   epsilon: 0.6787212400069746    steps: 276    lr: 4e-05     evaluation reward: 4.52\nepisode: 1267   score: 5.0   memory length: 262608   epsilon: 0.6780341800069896    steps: 347    lr: 4e-05     evaluation reward: 4.53\nepisode: 1268   score: 4.0   memory length: 262924   epsilon: 0.6774085000070031    steps: 316    lr: 4e-05     evaluation reward: 4.46\nepisode: 1269   score: 4.0   memory length: 263185   epsilon: 0.6768917200070144    steps: 261    lr: 4e-05     evaluation reward: 4.47\nepisode: 1270   score: 7.0   memory length: 263590   epsilon: 0.6760898200070318    steps: 405    lr: 4e-05     evaluation reward: 4.54\nepisode: 1271   score: 4.0   memory length: 263866   epsilon: 0.6755433400070436    steps: 276    lr: 4e-05     evaluation reward: 4.45\nepisode: 1272   score: 4.0   memory length: 264161   epsilon: 0.6749592400070563    steps: 295    lr: 4e-05     evaluation reward: 4.42\nepisode: 1273   score: 1.0   memory length: 264312   epsilon: 0.6746602600070628    steps: 151    lr: 4e-05     evaluation reward: 4.37\nepisode: 1274   score: 4.0   memory length: 264586   epsilon: 0.6741177400070746    steps: 274    lr: 4e-05     evaluation reward: 4.34\nepisode: 1275   score: 4.0   memory length: 264861   epsilon: 0.6735732400070864    steps: 275    lr: 4e-05     evaluation reward: 4.37\nepisode: 1276   score: 4.0   memory length: 265183   epsilon: 0.6729356800071002    steps: 322    lr: 4e-05     evaluation reward: 4.39\nepisode: 1277   score: 4.0   memory length: 265457   epsilon: 0.672393160007112    steps: 274    lr: 4e-05     evaluation reward: 4.41\nepisode: 1278   score: 3.0   memory length: 265686   epsilon: 0.6719397400071219    steps: 229    lr: 4e-05     evaluation reward: 4.41\nepisode: 1279   score: 5.0   memory length: 266005   epsilon: 0.6713081200071356    steps: 319    lr: 4e-05     evaluation reward: 4.4\nepisode: 1280   score: 2.0   memory length: 266184   epsilon: 0.6709537000071433    steps: 179    lr: 4e-05     evaluation reward: 4.39\nepisode: 1281   score: 0.0   memory length: 266307   epsilon: 0.6707101600071486    steps: 123    lr: 4e-05     evaluation reward: 4.34\nepisode: 1282   score: 4.0   memory length: 266544   epsilon: 0.6702409000071587    steps: 237    lr: 4e-05     evaluation reward: 4.35\nepisode: 1283   score: 3.0   memory length: 266772   epsilon: 0.6697894600071685    steps: 228    lr: 4e-05     evaluation reward: 4.35\nepisode: 1284   score: 7.0   memory length: 267115   epsilon: 0.6691103200071833    steps: 343    lr: 4e-05     evaluation reward: 4.4\nepisode: 1285   score: 5.0   memory length: 267422   epsilon: 0.6685024600071965    steps: 307    lr: 4e-05     evaluation reward: 4.35\nepisode: 1286   score: 3.0   memory length: 267651   epsilon: 0.6680490400072063    steps: 229    lr: 4e-05     evaluation reward: 4.32\nepisode: 1287   score: 4.0   memory length: 267911   epsilon: 0.6675342400072175    steps: 260    lr: 4e-05     evaluation reward: 4.27\nepisode: 1288   score: 4.0   memory length: 268186   epsilon: 0.6669897400072293    steps: 275    lr: 4e-05     evaluation reward: 4.29\nepisode: 1289   score: 6.0   memory length: 268561   epsilon: 0.6662472400072454    steps: 375    lr: 4e-05     evaluation reward: 4.32\nepisode: 1290   score: 14.0   memory length: 269147   epsilon: 0.6650869600072706    steps: 586    lr: 4e-05     evaluation reward: 4.46\nepisode: 1291   score: 10.0   memory length: 269707   epsilon: 0.6639781600072947    steps: 560    lr: 4e-05     evaluation reward: 4.54\nepisode: 1292   score: 5.0   memory length: 270043   epsilon: 0.6633128800073091    steps: 336    lr: 4e-05     evaluation reward: 4.59\nepisode: 1293   score: 3.0   memory length: 270290   epsilon: 0.6628238200073198    steps: 247    lr: 4e-05     evaluation reward: 4.56\nepisode: 1294   score: 7.0   memory length: 270716   epsilon: 0.6619803400073381    steps: 426    lr: 4e-05     evaluation reward: 4.56\nepisode: 1295   score: 6.0   memory length: 271070   epsilon: 0.6612794200073533    steps: 354    lr: 4e-05     evaluation reward: 4.55\nepisode: 1296   score: 2.0   memory length: 271270   epsilon: 0.6608834200073619    steps: 200    lr: 4e-05     evaluation reward: 4.5\nepisode: 1297   score: 5.0   memory length: 271560   epsilon: 0.6603092200073744    steps: 290    lr: 4e-05     evaluation reward: 4.53\nepisode: 1298   score: 2.0   memory length: 271778   epsilon: 0.6598775800073837    steps: 218    lr: 4e-05     evaluation reward: 4.52\nepisode: 1299   score: 7.0   memory length: 272173   epsilon: 0.6590954800074007    steps: 395    lr: 4e-05     evaluation reward: 4.59\nepisode: 1300   score: 6.0   memory length: 272532   epsilon: 0.6583846600074161    steps: 359    lr: 4e-05     evaluation reward: 4.65\nepisode: 1301   score: 4.0   memory length: 272772   epsilon: 0.6579094600074264    steps: 240    lr: 4e-05     evaluation reward: 4.68\nepisode: 1302   score: 7.0   memory length: 273158   epsilon: 0.657145180007443    steps: 386    lr: 4e-05     evaluation reward: 4.71\nepisode: 1303   score: 2.0   memory length: 273358   epsilon: 0.6567491800074516    steps: 200    lr: 4e-05     evaluation reward: 4.69\nepisode: 1304   score: 5.0   memory length: 273664   epsilon: 0.6561433000074648    steps: 306    lr: 4e-05     evaluation reward: 4.69\nepisode: 1305   score: 5.0   memory length: 273970   epsilon: 0.655537420007478    steps: 306    lr: 4e-05     evaluation reward: 4.7\nepisode: 1306   score: 7.0   memory length: 274395   epsilon: 0.6546959200074962    steps: 425    lr: 4e-05     evaluation reward: 4.72\nepisode: 1307   score: 1.0   memory length: 274566   epsilon: 0.6543573400075036    steps: 171    lr: 4e-05     evaluation reward: 4.7\nepisode: 1308   score: 6.0   memory length: 274966   epsilon: 0.6535653400075208    steps: 400    lr: 4e-05     evaluation reward: 4.72\nepisode: 1309   score: 6.0   memory length: 275344   epsilon: 0.652816900007537    steps: 378    lr: 4e-05     evaluation reward: 4.73\nepisode: 1310   score: 2.0   memory length: 275563   epsilon: 0.6523832800075464    steps: 219    lr: 4e-05     evaluation reward: 4.71\nepisode: 1311   score: 9.0   memory length: 276059   epsilon: 0.6514012000075677    steps: 496    lr: 4e-05     evaluation reward: 4.72\nepisode: 1312   score: 3.0   memory length: 276309   epsilon: 0.6509062000075785    steps: 250    lr: 4e-05     evaluation reward: 4.7\nepisode: 1313   score: 8.0   memory length: 276688   epsilon: 0.6501557800075948    steps: 379    lr: 4e-05     evaluation reward: 4.7\nepisode: 1314   score: 6.0   memory length: 277063   epsilon: 0.6494132800076109    steps: 375    lr: 4e-05     evaluation reward: 4.72\nepisode: 1315   score: 2.0   memory length: 277245   epsilon: 0.6490529200076187    steps: 182    lr: 4e-05     evaluation reward: 4.68\nepisode: 1316   score: 6.0   memory length: 277617   epsilon: 0.6483163600076347    steps: 372    lr: 4e-05     evaluation reward: 4.72\nepisode: 1317   score: 8.0   memory length: 277984   epsilon: 0.6475897000076505    steps: 367    lr: 4e-05     evaluation reward: 4.76\nepisode: 1318   score: 8.0   memory length: 278416   epsilon: 0.646734340007669    steps: 432    lr: 4e-05     evaluation reward: 4.78\nepisode: 1319   score: 6.0   memory length: 278788   epsilon: 0.645997780007685    steps: 372    lr: 4e-05     evaluation reward: 4.8\nepisode: 1320   score: 4.0   memory length: 279082   epsilon: 0.6454156600076977    steps: 294    lr: 4e-05     evaluation reward: 4.8\nepisode: 1321   score: 4.0   memory length: 279359   epsilon: 0.6448672000077096    steps: 277    lr: 4e-05     evaluation reward: 4.8\nepisode: 1322   score: 7.0   memory length: 279756   epsilon: 0.6440811400077266    steps: 397    lr: 4e-05     evaluation reward: 4.82\nepisode: 1323   score: 5.0   memory length: 280082   epsilon: 0.6434356600077407    steps: 326    lr: 4e-05     evaluation reward: 4.81\nepisode: 1324   score: 8.0   memory length: 280539   epsilon: 0.6425308000077603    steps: 457    lr: 4e-05     evaluation reward: 4.86\nepisode: 1325   score: 2.0   memory length: 280737   epsilon: 0.6421387600077688    steps: 198    lr: 4e-05     evaluation reward: 4.86\nepisode: 1326   score: 2.0   memory length: 280919   epsilon: 0.6417784000077766    steps: 182    lr: 4e-05     evaluation reward: 4.82\nepisode: 1327   score: 5.0   memory length: 281246   epsilon: 0.6411309400077907    steps: 327    lr: 4e-05     evaluation reward: 4.82\nepisode: 1328   score: 5.0   memory length: 281550   epsilon: 0.6405290200078038    steps: 304    lr: 4e-05     evaluation reward: 4.85\nepisode: 1329   score: 6.0   memory length: 281887   epsilon: 0.6398617600078182    steps: 337    lr: 4e-05     evaluation reward: 4.86\nepisode: 1330   score: 2.0   memory length: 282085   epsilon: 0.6394697200078268    steps: 198    lr: 4e-05     evaluation reward: 4.82\nepisode: 1331   score: 7.0   memory length: 282506   epsilon: 0.6386361400078449    steps: 421    lr: 4e-05     evaluation reward: 4.83\nepisode: 1332   score: 5.0   memory length: 282868   epsilon: 0.6379193800078604    steps: 362    lr: 4e-05     evaluation reward: 4.83\nepisode: 1333   score: 4.0   memory length: 283125   epsilon: 0.6374105200078715    steps: 257    lr: 4e-05     evaluation reward: 4.81\nepisode: 1334   score: 6.0   memory length: 283497   epsilon: 0.6366739600078875    steps: 372    lr: 4e-05     evaluation reward: 4.84\nepisode: 1335   score: 6.0   memory length: 283873   epsilon: 0.6359294800079036    steps: 376    lr: 4e-05     evaluation reward: 4.84\nepisode: 1336   score: 7.0   memory length: 284239   epsilon: 0.6352048000079193    steps: 366    lr: 4e-05     evaluation reward: 4.84\nepisode: 1337   score: 5.0   memory length: 284567   epsilon: 0.6345553600079334    steps: 328    lr: 4e-05     evaluation reward: 4.85\nepisode: 1338   score: 5.0   memory length: 284860   epsilon: 0.633975220007946    steps: 293    lr: 4e-05     evaluation reward: 4.87\nepisode: 1339   score: 7.0   memory length: 285261   epsilon: 0.6331812400079633    steps: 401    lr: 4e-05     evaluation reward: 4.92\nepisode: 1340   score: 4.0   memory length: 285556   epsilon: 0.632597140007976    steps: 295    lr: 4e-05     evaluation reward: 4.93\nepisode: 1341   score: 6.0   memory length: 285894   epsilon: 0.6319279000079905    steps: 338    lr: 4e-05     evaluation reward: 4.92\nepisode: 1342   score: 5.0   memory length: 286198   epsilon: 0.6313259800080036    steps: 304    lr: 4e-05     evaluation reward: 4.97\nepisode: 1343   score: 6.0   memory length: 286576   epsilon: 0.6305775400080198    steps: 378    lr: 4e-05     evaluation reward: 4.97\nepisode: 1344   score: 9.0   memory length: 287031   epsilon: 0.6296766400080394    steps: 455    lr: 4e-05     evaluation reward: 5.03\nepisode: 1345   score: 5.0   memory length: 287394   epsilon: 0.628957900008055    steps: 363    lr: 4e-05     evaluation reward: 5.03\nepisode: 1346   score: 5.0   memory length: 287719   epsilon: 0.6283144000080689    steps: 325    lr: 4e-05     evaluation reward: 5.0\nepisode: 1347   score: 7.0   memory length: 288073   epsilon: 0.6276134800080841    steps: 354    lr: 4e-05     evaluation reward: 5.04\nepisode: 1348   score: 4.0   memory length: 288347   epsilon: 0.6270709600080959    steps: 274    lr: 4e-05     evaluation reward: 5.04\nepisode: 1349   score: 3.0   memory length: 288591   epsilon: 0.6265878400081064    steps: 244    lr: 4e-05     evaluation reward: 5.04\nepisode: 1350   score: 4.0   memory length: 288835   epsilon: 0.6261047200081169    steps: 244    lr: 4e-05     evaluation reward: 5.01\nepisode: 1351   score: 5.0   memory length: 289184   epsilon: 0.6254137000081319    steps: 349    lr: 4e-05     evaluation reward: 5.02\nepisode: 1352   score: 8.0   memory length: 289619   epsilon: 0.6245524000081506    steps: 435    lr: 4e-05     evaluation reward: 4.99\nepisode: 1353   score: 8.0   memory length: 290067   epsilon: 0.6236653600081699    steps: 448    lr: 4e-05     evaluation reward: 5.0\nepisode: 1354   score: 2.0   memory length: 290266   epsilon: 0.6232713400081784    steps: 199    lr: 4e-05     evaluation reward: 4.98\nepisode: 1355   score: 1.0   memory length: 290438   epsilon: 0.6229307800081858    steps: 172    lr: 4e-05     evaluation reward: 4.94\nepisode: 1356   score: 3.0   memory length: 290685   epsilon: 0.6224417200081964    steps: 247    lr: 4e-05     evaluation reward: 4.92\nepisode: 1357   score: 4.0   memory length: 290961   epsilon: 0.6218952400082083    steps: 276    lr: 4e-05     evaluation reward: 4.91\nepisode: 1358   score: 6.0   memory length: 291336   epsilon: 0.6211527400082244    steps: 375    lr: 4e-05     evaluation reward: 4.89\nepisode: 1359   score: 4.0   memory length: 291611   epsilon: 0.6206082400082362    steps: 275    lr: 4e-05     evaluation reward: 4.86\nepisode: 1360   score: 4.0   memory length: 291870   epsilon: 0.6200954200082474    steps: 259    lr: 4e-05     evaluation reward: 4.84\nepisode: 1361   score: 5.0   memory length: 292194   epsilon: 0.6194539000082613    steps: 324    lr: 4e-05     evaluation reward: 4.85\nepisode: 1362   score: 6.0   memory length: 292568   epsilon: 0.6187133800082774    steps: 374    lr: 4e-05     evaluation reward: 4.88\nepisode: 1363   score: 5.0   memory length: 292856   epsilon: 0.6181431400082897    steps: 288    lr: 4e-05     evaluation reward: 4.9\nepisode: 1364   score: 4.0   memory length: 293115   epsilon: 0.6176303200083009    steps: 259    lr: 4e-05     evaluation reward: 4.9\nepisode: 1365   score: 7.0   memory length: 293497   epsilon: 0.6168739600083173    steps: 382    lr: 4e-05     evaluation reward: 4.95\nepisode: 1366   score: 7.0   memory length: 293903   epsilon: 0.6160700800083347    steps: 406    lr: 4e-05     evaluation reward: 4.98\nepisode: 1367   score: 6.0   memory length: 294277   epsilon: 0.6153295600083508    steps: 374    lr: 4e-05     evaluation reward: 4.99\nepisode: 1368   score: 7.0   memory length: 294700   epsilon: 0.614492020008369    steps: 423    lr: 4e-05     evaluation reward: 5.02\nepisode: 1369   score: 5.0   memory length: 295024   epsilon: 0.6138505000083829    steps: 324    lr: 4e-05     evaluation reward: 5.03\nepisode: 1370   score: 3.0   memory length: 295249   epsilon: 0.6134050000083926    steps: 225    lr: 4e-05     evaluation reward: 4.99\nepisode: 1371   score: 7.0   memory length: 295623   epsilon: 0.6126644800084087    steps: 374    lr: 4e-05     evaluation reward: 5.02\nepisode: 1372   score: 5.0   memory length: 295919   epsilon: 0.6120784000084214    steps: 296    lr: 4e-05     evaluation reward: 5.03\nepisode: 1373   score: 8.0   memory length: 296375   epsilon: 0.611175520008441    steps: 456    lr: 4e-05     evaluation reward: 5.1\nepisode: 1374   score: 5.0   memory length: 296722   epsilon: 0.6104884600084559    steps: 347    lr: 4e-05     evaluation reward: 5.11\nepisode: 1375   score: 6.0   memory length: 297078   epsilon: 0.6097835800084712    steps: 356    lr: 4e-05     evaluation reward: 5.13\nepisode: 1376   score: 6.0   memory length: 297420   epsilon: 0.6091064200084859    steps: 342    lr: 4e-05     evaluation reward: 5.15\nepisode: 1377   score: 2.0   memory length: 297620   epsilon: 0.6087104200084945    steps: 200    lr: 4e-05     evaluation reward: 5.13\nepisode: 1378   score: 7.0   memory length: 298008   epsilon: 0.6079421800085112    steps: 388    lr: 4e-05     evaluation reward: 5.17\nepisode: 1379   score: 7.0   memory length: 298403   epsilon: 0.6071600800085282    steps: 395    lr: 4e-05     evaluation reward: 5.19\nepisode: 1380   score: 2.0   memory length: 298584   epsilon: 0.606801700008536    steps: 181    lr: 4e-05     evaluation reward: 5.19\nepisode: 1381   score: 6.0   memory length: 298950   epsilon: 0.6060770200085517    steps: 366    lr: 4e-05     evaluation reward: 5.25\nepisode: 1382   score: 9.0   memory length: 299401   epsilon: 0.6051840400085711    steps: 451    lr: 4e-05     evaluation reward: 5.3\nepisode: 1383   score: 5.0   memory length: 299703   epsilon: 0.604586080008584    steps: 302    lr: 4e-05     evaluation reward: 5.32\nepisode: 1384   score: 8.0   memory length: 299997   epsilon: 0.6040039600085967    steps: 294    lr: 4e-05     evaluation reward: 5.33\nepisode: 1385   score: 6.0   memory length: 300322   epsilon: 0.6033604600086107    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.34\nepisode: 1386   score: 5.0   memory length: 300616   epsilon: 0.6027783400086233    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 5.36\nepisode: 1387   score: 17.0   memory length: 301259   epsilon: 0.6015052000086509    steps: 643    lr: 1.6000000000000003e-05     evaluation reward: 5.49\nepisode: 1388   score: 5.0   memory length: 301585   epsilon: 0.6008597200086649    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 5.5\nepisode: 1389   score: 7.0   memory length: 302008   epsilon: 0.6000221800086831    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 5.51\nepisode: 1390   score: 5.0   memory length: 302301   epsilon: 0.5994420400086957    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 5.42\nepisode: 1391   score: 6.0   memory length: 302676   epsilon: 0.5986995400087118    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 5.38\nepisode: 1392   score: 7.0   memory length: 303026   epsilon: 0.5980065400087269    steps: 350    lr: 1.6000000000000003e-05     evaluation reward: 5.4\nepisode: 1393   score: 12.0   memory length: 303469   epsilon: 0.5971294000087459    steps: 443    lr: 1.6000000000000003e-05     evaluation reward: 5.49\nepisode: 1394   score: 8.0   memory length: 303898   epsilon: 0.5962799800087644    steps: 429    lr: 1.6000000000000003e-05     evaluation reward: 5.5\nepisode: 1395   score: 5.0   memory length: 304244   epsilon: 0.5955949000087792    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 5.49\nepisode: 1396   score: 5.0   memory length: 304592   epsilon: 0.5949058600087942    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 5.52\nepisode: 1397   score: 7.0   memory length: 304977   epsilon: 0.5941435600088107    steps: 385    lr: 1.6000000000000003e-05     evaluation reward: 5.54\nepisode: 1398   score: 7.0   memory length: 305405   epsilon: 0.5932961200088291    steps: 428    lr: 1.6000000000000003e-05     evaluation reward: 5.59\nepisode: 1399   score: 5.0   memory length: 305707   epsilon: 0.5926981600088421    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 5.57\nepisode: 1400   score: 8.0   memory length: 306130   epsilon: 0.5918606200088603    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 5.59\nepisode: 1401   score: 5.0   memory length: 306417   epsilon: 0.5912923600088726    steps: 287    lr: 1.6000000000000003e-05     evaluation reward: 5.6\nepisode: 1402   score: 8.0   memory length: 306858   epsilon: 0.5904191800088916    steps: 441    lr: 1.6000000000000003e-05     evaluation reward: 5.61\nepisode: 1403   score: 9.0   memory length: 307305   epsilon: 0.5895341200089108    steps: 447    lr: 1.6000000000000003e-05     evaluation reward: 5.68\nepisode: 1404   score: 5.0   memory length: 307649   epsilon: 0.5888530000089256    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 5.68\nepisode: 1405   score: 11.0   memory length: 308174   epsilon: 0.5878135000089482    steps: 525    lr: 1.6000000000000003e-05     evaluation reward: 5.74\nepisode: 1406   score: 11.0   memory length: 308700   epsilon: 0.5867720200089708    steps: 526    lr: 1.6000000000000003e-05     evaluation reward: 5.78\nepisode: 1407   score: 7.0   memory length: 309086   epsilon: 0.5860077400089874    steps: 386    lr: 1.6000000000000003e-05     evaluation reward: 5.84\nepisode: 1408   score: 8.0   memory length: 309538   epsilon: 0.5851127800090068    steps: 452    lr: 1.6000000000000003e-05     evaluation reward: 5.86\nepisode: 1409   score: 4.0   memory length: 309834   epsilon: 0.5845267000090195    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 5.84\nepisode: 1410   score: 4.0   memory length: 310111   epsilon: 0.5839782400090314    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 5.86\nepisode: 1411   score: 5.0   memory length: 310414   epsilon: 0.5833783000090444    steps: 303    lr: 1.6000000000000003e-05     evaluation reward: 5.82\nepisode: 1412   score: 6.0   memory length: 310771   epsilon: 0.5826714400090598    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 5.85\nepisode: 1413   score: 6.0   memory length: 311141   epsilon: 0.5819388400090757    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 5.83\nepisode: 1414   score: 7.0   memory length: 311516   epsilon: 0.5811963400090918    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 5.84\nepisode: 1415   score: 3.0   memory length: 311742   epsilon: 0.5807488600091015    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 5.85\nepisode: 1416   score: 4.0   memory length: 312035   epsilon: 0.5801687200091141    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 5.83\nepisode: 1417   score: 5.0   memory length: 312308   epsilon: 0.5796281800091259    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 5.8\nepisode: 1418   score: 3.0   memory length: 312554   epsilon: 0.5791411000091364    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 5.75\nepisode: 1419   score: 8.0   memory length: 312992   epsilon: 0.5782738600091553    steps: 438    lr: 1.6000000000000003e-05     evaluation reward: 5.77\nepisode: 1420   score: 6.0   memory length: 313345   epsilon: 0.5775749200091704    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 5.79\nepisode: 1421   score: 6.0   memory length: 313700   epsilon: 0.5768720200091857    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 5.81\nepisode: 1422   score: 6.0   memory length: 314055   epsilon: 0.576169120009201    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 5.8\nepisode: 1423   score: 6.0   memory length: 314408   epsilon: 0.5754701800092161    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 5.81\nepisode: 1424   score: 7.0   memory length: 314850   epsilon: 0.5745950200092351    steps: 442    lr: 1.6000000000000003e-05     evaluation reward: 5.8\nepisode: 1425   score: 5.0   memory length: 315157   epsilon: 0.5739871600092483    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 5.83\nepisode: 1426   score: 10.0   memory length: 315679   epsilon: 0.5729536000092708    steps: 522    lr: 1.6000000000000003e-05     evaluation reward: 5.91\nepisode: 1427   score: 3.0   memory length: 315925   epsilon: 0.5724665200092813    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 5.89\nepisode: 1428   score: 6.0   memory length: 316282   epsilon: 0.5717596600092967    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 5.9\nepisode: 1429   score: 8.0   memory length: 316711   epsilon: 0.5709102400093151    steps: 429    lr: 1.6000000000000003e-05     evaluation reward: 5.92\nepisode: 1430   score: 10.0   memory length: 317208   epsilon: 0.5699261800093365    steps: 497    lr: 1.6000000000000003e-05     evaluation reward: 6.0\nepisode: 1431   score: 6.0   memory length: 317542   epsilon: 0.5692648600093508    steps: 334    lr: 1.6000000000000003e-05     evaluation reward: 5.99\nepisode: 1432   score: 5.0   memory length: 317854   epsilon: 0.5686471000093642    steps: 312    lr: 1.6000000000000003e-05     evaluation reward: 5.99\nepisode: 1433   score: 7.0   memory length: 318221   epsilon: 0.56792044000938    steps: 367    lr: 1.6000000000000003e-05     evaluation reward: 6.02\nepisode: 1434   score: 2.0   memory length: 318419   epsilon: 0.5675284000093885    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 5.98\nepisode: 1435   score: 8.0   memory length: 318845   epsilon: 0.5666849200094068    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 6.0\nepisode: 1436   score: 7.0   memory length: 319262   epsilon: 0.5658592600094248    steps: 417    lr: 1.6000000000000003e-05     evaluation reward: 6.0\nepisode: 1437   score: 2.0   memory length: 319460   epsilon: 0.5654672200094333    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 5.97\nepisode: 1438   score: 3.0   memory length: 319688   epsilon: 0.5650157800094431    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 5.95\nepisode: 1439   score: 3.0   memory length: 319935   epsilon: 0.5645267200094537    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 5.91\nepisode: 1440   score: 8.0   memory length: 320330   epsilon: 0.5637446200094707    steps: 395    lr: 1.6000000000000003e-05     evaluation reward: 5.95\nepisode: 1441   score: 5.0   memory length: 320626   epsilon: 0.5631585400094834    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 5.94\nepisode: 1442   score: 4.0   memory length: 320910   epsilon: 0.5625962200094956    steps: 284    lr: 1.6000000000000003e-05     evaluation reward: 5.93\nepisode: 1443   score: 6.0   memory length: 321252   epsilon: 0.5619190600095103    steps: 342    lr: 1.6000000000000003e-05     evaluation reward: 5.93\nepisode: 1444   score: 4.0   memory length: 321569   epsilon: 0.5612914000095239    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 5.88\nepisode: 1445   score: 4.0   memory length: 321813   epsilon: 0.5608082800095344    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 5.87\nepisode: 1446   score: 10.0   memory length: 322331   epsilon: 0.5597826400095567    steps: 518    lr: 1.6000000000000003e-05     evaluation reward: 5.92\nepisode: 1447   score: 7.0   memory length: 322756   epsilon: 0.558941140009575    steps: 425    lr: 1.6000000000000003e-05     evaluation reward: 5.92\nepisode: 1448   score: 5.0   memory length: 323063   epsilon: 0.5583332800095882    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 5.93\nepisode: 1449   score: 3.0   memory length: 323273   epsilon: 0.5579174800095972    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 5.93\nepisode: 1450   score: 6.0   memory length: 323590   epsilon: 0.5572898200096108    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 5.95\nepisode: 1451   score: 4.0   memory length: 323858   epsilon: 0.5567591800096223    steps: 268    lr: 1.6000000000000003e-05     evaluation reward: 5.94\nepisode: 1452   score: 6.0   memory length: 324179   epsilon: 0.5561236000096361    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 5.92\nepisode: 1453   score: 8.0   memory length: 324595   epsilon: 0.555299920009654    steps: 416    lr: 1.6000000000000003e-05     evaluation reward: 5.92\nepisode: 1454   score: 9.0   memory length: 325063   epsilon: 0.5543732800096741    steps: 468    lr: 1.6000000000000003e-05     evaluation reward: 5.99\nepisode: 1455   score: 9.0   memory length: 325543   epsilon: 0.5534228800096948    steps: 480    lr: 1.6000000000000003e-05     evaluation reward: 6.07\nepisode: 1456   score: 13.0   memory length: 326084   epsilon: 0.552351700009718    steps: 541    lr: 1.6000000000000003e-05     evaluation reward: 6.17\nepisode: 1457   score: 2.0   memory length: 326282   epsilon: 0.5519596600097265    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 6.15\nepisode: 1458   score: 8.0   memory length: 326663   epsilon: 0.5512052800097429    steps: 381    lr: 1.6000000000000003e-05     evaluation reward: 6.17\nepisode: 1459   score: 7.0   memory length: 327068   epsilon: 0.5504033800097603    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 6.2\nepisode: 1460   score: 5.0   memory length: 327417   epsilon: 0.5497123600097753    steps: 349    lr: 1.6000000000000003e-05     evaluation reward: 6.21\nepisode: 1461   score: 3.0   memory length: 327663   epsilon: 0.5492252800097859    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 6.19\nepisode: 1462   score: 6.0   memory length: 327970   epsilon: 0.5486174200097991    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 6.19\nepisode: 1463   score: 7.0   memory length: 328330   epsilon: 0.5479046200098145    steps: 360    lr: 1.6000000000000003e-05     evaluation reward: 6.21\nepisode: 1464   score: 7.0   memory length: 328721   epsilon: 0.5471304400098314    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 6.24\nepisode: 1465   score: 5.0   memory length: 329045   epsilon: 0.5464889200098453    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 6.22\nepisode: 1466   score: 6.0   memory length: 329398   epsilon: 0.5457899800098605    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 6.21\nepisode: 1467   score: 5.0   memory length: 329763   epsilon: 0.5450672800098761    steps: 365    lr: 1.6000000000000003e-05     evaluation reward: 6.2\nepisode: 1468   score: 6.0   memory length: 330137   epsilon: 0.5443267600098922    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 6.19\nepisode: 1469   score: 6.0   memory length: 330458   epsilon: 0.543691180009906    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 6.2\nepisode: 1470   score: 10.0   memory length: 331029   epsilon: 0.5425606000099306    steps: 571    lr: 1.6000000000000003e-05     evaluation reward: 6.27\nepisode: 1471   score: 3.0   memory length: 331243   epsilon: 0.5421368800099398    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 6.23\nepisode: 1472   score: 4.0   memory length: 331501   epsilon: 0.5416260400099508    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 6.22\nepisode: 1473   score: 7.0   memory length: 331885   epsilon: 0.5408657200099674    steps: 384    lr: 1.6000000000000003e-05     evaluation reward: 6.21\nepisode: 1474   score: 11.0   memory length: 332308   epsilon: 0.5400281800099855    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 6.27\nepisode: 1475   score: 6.0   memory length: 332645   epsilon: 0.53936092001    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 6.27\nepisode: 1476   score: 11.0   memory length: 333176   epsilon: 0.5383095400100228    steps: 531    lr: 1.6000000000000003e-05     evaluation reward: 6.32\nepisode: 1477   score: 4.0   memory length: 333455   epsilon: 0.5377571200100348    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 6.34\nepisode: 1478   score: 8.0   memory length: 333896   epsilon: 0.5368839400100538    steps: 441    lr: 1.6000000000000003e-05     evaluation reward: 6.35\nepisode: 1479   score: 3.0   memory length: 334144   epsilon: 0.5363929000100645    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 6.31\nepisode: 1480   score: 7.0   memory length: 334509   epsilon: 0.5356702000100801    steps: 365    lr: 1.6000000000000003e-05     evaluation reward: 6.36\nepisode: 1481   score: 6.0   memory length: 334886   epsilon: 0.5349237400100963    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 6.36\nepisode: 1482   score: 9.0   memory length: 335359   epsilon: 0.5339872000101167    steps: 473    lr: 1.6000000000000003e-05     evaluation reward: 6.36\nepisode: 1483   score: 5.0   memory length: 335687   epsilon: 0.5333377600101308    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 6.36\nepisode: 1484   score: 4.0   memory length: 335985   epsilon: 0.5327477200101436    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 6.32\nepisode: 1485   score: 10.0   memory length: 336457   epsilon: 0.5318131600101639    steps: 472    lr: 1.6000000000000003e-05     evaluation reward: 6.36\nepisode: 1486   score: 7.0   memory length: 336811   epsilon: 0.5311122400101791    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 6.38\nepisode: 1487   score: 7.0   memory length: 337254   epsilon: 0.5302351000101981    steps: 443    lr: 1.6000000000000003e-05     evaluation reward: 6.28\nepisode: 1488   score: 6.0   memory length: 337624   epsilon: 0.529502500010214    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 6.29\nepisode: 1489   score: 9.0   memory length: 338094   epsilon: 0.5285719000102342    steps: 470    lr: 1.6000000000000003e-05     evaluation reward: 6.31\nepisode: 1490   score: 3.0   memory length: 338320   epsilon: 0.528124420010244    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 6.29\nepisode: 1491   score: 4.0   memory length: 338561   epsilon: 0.5276472400102543    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 6.27\nepisode: 1492   score: 8.0   memory length: 339012   epsilon: 0.5267542600102737    steps: 451    lr: 1.6000000000000003e-05     evaluation reward: 6.28\nepisode: 1493   score: 11.0   memory length: 339528   epsilon: 0.5257325800102959    steps: 516    lr: 1.6000000000000003e-05     evaluation reward: 6.27\nepisode: 1494   score: 11.0   memory length: 340078   epsilon: 0.5246435800103195    steps: 550    lr: 1.6000000000000003e-05     evaluation reward: 6.3\nepisode: 1495   score: 6.0   memory length: 340417   epsilon: 0.5239723600103341    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 6.31\nepisode: 1496   score: 7.0   memory length: 340780   epsilon: 0.5232536200103497    steps: 363    lr: 1.6000000000000003e-05     evaluation reward: 6.33\nepisode: 1497   score: 8.0   memory length: 341253   epsilon: 0.52231708001037    steps: 473    lr: 1.6000000000000003e-05     evaluation reward: 6.34\nepisode: 1498   score: 7.0   memory length: 341650   epsilon: 0.5215310200103871    steps: 397    lr: 1.6000000000000003e-05     evaluation reward: 6.34\nepisode: 1499   score: 5.0   memory length: 341971   epsilon: 0.5208954400104009    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 6.34\nepisode: 1500   score: 5.0   memory length: 342294   epsilon: 0.5202559000104148    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 6.31\nepisode: 1501   score: 7.0   memory length: 342688   epsilon: 0.5194757800104317    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 6.33\nepisode: 1502   score: 11.0   memory length: 343196   epsilon: 0.5184699400104535    steps: 508    lr: 1.6000000000000003e-05     evaluation reward: 6.36\nepisode: 1503   score: 5.0   memory length: 343506   epsilon: 0.5178561400104669    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 6.32\nepisode: 1504   score: 6.0   memory length: 343829   epsilon: 0.5172166000104808    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 6.33\nepisode: 1505   score: 4.0   memory length: 344074   epsilon: 0.5167315000104913    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 6.26\nepisode: 1506   score: 8.0   memory length: 344515   epsilon: 0.5158583200105102    steps: 441    lr: 1.6000000000000003e-05     evaluation reward: 6.23\nepisode: 1507   score: 3.0   memory length: 344742   epsilon: 0.51540886001052    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 6.19\nepisode: 1508   score: 4.0   memory length: 345001   epsilon: 0.5148960400105311    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 6.15\nepisode: 1509   score: 5.0   memory length: 345295   epsilon: 0.5143139200105438    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 6.16\nepisode: 1510   score: 7.0   memory length: 345699   epsilon: 0.5135140000105611    steps: 404    lr: 1.6000000000000003e-05     evaluation reward: 6.19\nepisode: 1511   score: 5.0   memory length: 346003   epsilon: 0.5129120800105742    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 6.19\nepisode: 1512   score: 10.0   memory length: 346558   epsilon: 0.5118131800105981    steps: 555    lr: 1.6000000000000003e-05     evaluation reward: 6.23\nepisode: 1513   score: 9.0   memory length: 347040   epsilon: 0.5108588200106188    steps: 482    lr: 1.6000000000000003e-05     evaluation reward: 6.26\nepisode: 1514   score: 5.0   memory length: 347364   epsilon: 0.5102173000106327    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 6.24\nepisode: 1515   score: 8.0   memory length: 347770   epsilon: 0.5094134200106502    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 6.29\nepisode: 1516   score: 4.0   memory length: 348047   epsilon: 0.5088649600106621    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 6.29\nepisode: 1517   score: 6.0   memory length: 348365   epsilon: 0.5082353200106757    steps: 318    lr: 1.6000000000000003e-05     evaluation reward: 6.3\nepisode: 1518   score: 12.0   memory length: 348985   epsilon: 0.5070077200107024    steps: 620    lr: 1.6000000000000003e-05     evaluation reward: 6.39\nepisode: 1519   score: 6.0   memory length: 349358   epsilon: 0.5062691800107184    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 6.37\nepisode: 1520   score: 9.0   memory length: 349851   epsilon: 0.5052930400107396    steps: 493    lr: 1.6000000000000003e-05     evaluation reward: 6.4\nepisode: 1521   score: 5.0   memory length: 350160   epsilon: 0.5046812200107529    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 6.39\nepisode: 1522   score: 5.0   memory length: 350488   epsilon: 0.504031780010767    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 6.38\nepisode: 1523   score: 5.0   memory length: 350837   epsilon: 0.503340760010782    steps: 349    lr: 1.6000000000000003e-05     evaluation reward: 6.37\nepisode: 1524   score: 5.0   memory length: 351142   epsilon: 0.5027368600107951    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 6.35\nepisode: 1525   score: 7.0   memory length: 351549   epsilon: 0.5019310000108126    steps: 407    lr: 1.6000000000000003e-05     evaluation reward: 6.37\nepisode: 1526   score: 8.0   memory length: 351983   epsilon: 0.5010716800108312    steps: 434    lr: 1.6000000000000003e-05     evaluation reward: 6.35\nepisode: 1527   score: 7.0   memory length: 352409   epsilon: 0.5002282000108496    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 6.39\nepisode: 1528   score: 11.0   memory length: 352903   epsilon: 0.49925008001084975    steps: 494    lr: 1.6000000000000003e-05     evaluation reward: 6.44\nepisode: 1529   score: 8.0   memory length: 353347   epsilon: 0.4983709600108442    steps: 444    lr: 1.6000000000000003e-05     evaluation reward: 6.44\nepisode: 1530   score: 2.0   memory length: 353528   epsilon: 0.4980125800108419    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 6.36\nepisode: 1531   score: 4.0   memory length: 353787   epsilon: 0.4974997600108387    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 6.34\nepisode: 1532   score: 7.0   memory length: 354209   epsilon: 0.4966642000108334    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 6.36\nepisode: 1533   score: 6.0   memory length: 354582   epsilon: 0.4959256600108287    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 6.35\nepisode: 1534   score: 9.0   memory length: 355075   epsilon: 0.49494952001082254    steps: 493    lr: 1.6000000000000003e-05     evaluation reward: 6.42\nepisode: 1535   score: 5.0   memory length: 355396   epsilon: 0.4943139400108185    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 6.39\nepisode: 1536   score: 7.0   memory length: 355804   epsilon: 0.4935061000108134    steps: 408    lr: 1.6000000000000003e-05     evaluation reward: 6.39\nepisode: 1537   score: 7.0   memory length: 356179   epsilon: 0.4927636000108087    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 6.44\nepisode: 1538   score: 4.0   memory length: 356455   epsilon: 0.49221712001080525    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 6.45\nepisode: 1539   score: 9.0   memory length: 356883   epsilon: 0.4913696800107999    steps: 428    lr: 1.6000000000000003e-05     evaluation reward: 6.51\nepisode: 1540   score: 6.0   memory length: 357204   epsilon: 0.49073410001079587    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 6.49\nepisode: 1541   score: 7.0   memory length: 357605   epsilon: 0.48994012001079085    steps: 401    lr: 1.6000000000000003e-05     evaluation reward: 6.51\nepisode: 1542   score: 7.0   memory length: 358015   epsilon: 0.4891283200107857    steps: 410    lr: 1.6000000000000003e-05     evaluation reward: 6.54\nepisode: 1543   score: 9.0   memory length: 358502   epsilon: 0.4881640600107796    steps: 487    lr: 1.6000000000000003e-05     evaluation reward: 6.57\nepisode: 1544   score: 10.0   memory length: 358982   epsilon: 0.4872136600107736    steps: 480    lr: 1.6000000000000003e-05     evaluation reward: 6.63\nepisode: 1545   score: 7.0   memory length: 359383   epsilon: 0.4864196800107686    steps: 401    lr: 1.6000000000000003e-05     evaluation reward: 6.66\nepisode: 1546   score: 6.0   memory length: 359758   epsilon: 0.4856771800107639    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 6.62\nepisode: 1547   score: 6.0   memory length: 360111   epsilon: 0.48497824001075945    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 6.61\nepisode: 1548   score: 5.0   memory length: 360459   epsilon: 0.4842892000107551    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 6.61\nepisode: 1549   score: 7.0   memory length: 360817   epsilon: 0.4835803600107506    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 6.65\nepisode: 1550   score: 8.0   memory length: 361249   epsilon: 0.4827250000107452    steps: 432    lr: 1.6000000000000003e-05     evaluation reward: 6.67\nepisode: 1551   score: 11.0   memory length: 361789   epsilon: 0.48165580001073843    steps: 540    lr: 1.6000000000000003e-05     evaluation reward: 6.74\nepisode: 1552   score: 7.0   memory length: 362171   epsilon: 0.48089944001073365    steps: 382    lr: 1.6000000000000003e-05     evaluation reward: 6.75\nepisode: 1553   score: 4.0   memory length: 362428   epsilon: 0.48039058001073043    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 6.71\nepisode: 1554   score: 3.0   memory length: 362654   epsilon: 0.4799431000107276    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 6.65\nepisode: 1555   score: 8.0   memory length: 363075   epsilon: 0.4791095200107223    steps: 421    lr: 1.6000000000000003e-05     evaluation reward: 6.64\nepisode: 1556   score: 8.0   memory length: 363464   epsilon: 0.47833930001071745    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 6.59\nepisode: 1557   score: 5.0   memory length: 363773   epsilon: 0.4777274800107136    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 6.62\nepisode: 1558   score: 8.0   memory length: 364183   epsilon: 0.47691568001070844    steps: 410    lr: 1.6000000000000003e-05     evaluation reward: 6.62\nepisode: 1559   score: 3.0   memory length: 364414   epsilon: 0.47645830001070555    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 6.58\nepisode: 1560   score: 6.0   memory length: 364786   epsilon: 0.4757217400107009    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 6.59\nepisode: 1561   score: 11.0   memory length: 365147   epsilon: 0.47500696001069637    steps: 361    lr: 1.6000000000000003e-05     evaluation reward: 6.67\nepisode: 1562   score: 8.0   memory length: 365553   epsilon: 0.4742030800106913    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 6.69\nepisode: 1563   score: 6.0   memory length: 365912   epsilon: 0.4734922600106868    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 6.68\nepisode: 1564   score: 10.0   memory length: 366462   epsilon: 0.4724032600106799    steps: 550    lr: 1.6000000000000003e-05     evaluation reward: 6.71\nepisode: 1565   score: 7.0   memory length: 366884   epsilon: 0.4715677000106746    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 6.73\nepisode: 1566   score: 5.0   memory length: 367191   epsilon: 0.47095984001067076    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 6.72\nepisode: 1567   score: 6.0   memory length: 367510   epsilon: 0.47032822001066676    steps: 319    lr: 1.6000000000000003e-05     evaluation reward: 6.73\nepisode: 1568   score: 7.0   memory length: 367903   epsilon: 0.46955008001066184    steps: 393    lr: 1.6000000000000003e-05     evaluation reward: 6.74\nepisode: 1569   score: 7.0   memory length: 368151   epsilon: 0.46905904001065873    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 6.75\nepisode: 1570   score: 5.0   memory length: 368494   epsilon: 0.46837990001065444    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 6.7\nepisode: 1571   score: 6.0   memory length: 368871   epsilon: 0.4676334400106497    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 6.73\nepisode: 1572   score: 7.0   memory length: 369275   epsilon: 0.46683352001064465    steps: 404    lr: 1.6000000000000003e-05     evaluation reward: 6.76\nepisode: 1573   score: 3.0   memory length: 369485   epsilon: 0.466417720010642    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 6.72\nepisode: 1574   score: 3.0   memory length: 369713   epsilon: 0.46596628001063917    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 6.64\nepisode: 1575   score: 22.0   memory length: 370299   epsilon: 0.4648060000106318    steps: 586    lr: 1.6000000000000003e-05     evaluation reward: 6.8\nepisode: 1576   score: 6.0   memory length: 370673   epsilon: 0.46406548001062714    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 6.75\nepisode: 1577   score: 10.0   memory length: 371199   epsilon: 0.46302400001062055    steps: 526    lr: 1.6000000000000003e-05     evaluation reward: 6.81\nepisode: 1578   score: 5.0   memory length: 371485   epsilon: 0.46245772001061697    steps: 286    lr: 1.6000000000000003e-05     evaluation reward: 6.78\nepisode: 1579   score: 9.0   memory length: 371960   epsilon: 0.461517220010611    steps: 475    lr: 1.6000000000000003e-05     evaluation reward: 6.84\nepisode: 1580   score: 6.0   memory length: 372352   epsilon: 0.4607410600106061    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 6.83\nepisode: 1581   score: 7.0   memory length: 372755   epsilon: 0.45994312001060106    steps: 403    lr: 1.6000000000000003e-05     evaluation reward: 6.84\nepisode: 1582   score: 8.0   memory length: 373169   epsilon: 0.4591234000105959    steps: 414    lr: 1.6000000000000003e-05     evaluation reward: 6.83\nepisode: 1583   score: 6.0   memory length: 373545   epsilon: 0.45837892001059116    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 6.84\nepisode: 1584   score: 4.0   memory length: 373807   epsilon: 0.4578601600105879    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 6.84\nepisode: 1585   score: 7.0   memory length: 374180   epsilon: 0.4571216200105832    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 6.81\nepisode: 1586   score: 8.0   memory length: 374611   epsilon: 0.4562682400105778    steps: 431    lr: 1.6000000000000003e-05     evaluation reward: 6.82\nepisode: 1587   score: 3.0   memory length: 374823   epsilon: 0.45584848001057515    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 6.78\nepisode: 1588   score: 4.0   memory length: 375083   epsilon: 0.4553336800105719    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 6.76\nepisode: 1589   score: 11.0   memory length: 375558   epsilon: 0.45439318001056594    steps: 475    lr: 1.6000000000000003e-05     evaluation reward: 6.78\nepisode: 1590   score: 11.0   memory length: 376022   epsilon: 0.45347446001056013    steps: 464    lr: 1.6000000000000003e-05     evaluation reward: 6.86\nepisode: 1591   score: 6.0   memory length: 376380   epsilon: 0.45276562001055565    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 6.88\nepisode: 1592   score: 8.0   memory length: 376855   epsilon: 0.4518251200105497    steps: 475    lr: 1.6000000000000003e-05     evaluation reward: 6.88\nepisode: 1593   score: 8.0   memory length: 377279   epsilon: 0.4509856000105444    steps: 424    lr: 1.6000000000000003e-05     evaluation reward: 6.85\nepisode: 1594   score: 3.0   memory length: 377510   epsilon: 0.4505282200105415    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 6.77\nepisode: 1595   score: 5.0   memory length: 377836   epsilon: 0.4498827400105374    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 6.76\nepisode: 1596   score: 8.0   memory length: 378273   epsilon: 0.44901748001053193    steps: 437    lr: 1.6000000000000003e-05     evaluation reward: 6.77\nepisode: 1597   score: 9.0   memory length: 378715   epsilon: 0.4481423200105264    steps: 442    lr: 1.6000000000000003e-05     evaluation reward: 6.78\nepisode: 1598   score: 3.0   memory length: 378926   epsilon: 0.44772454001052375    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 6.74\nepisode: 1599   score: 7.0   memory length: 379341   epsilon: 0.44690284001051855    steps: 415    lr: 1.6000000000000003e-05     evaluation reward: 6.76\nepisode: 1600   score: 9.0   memory length: 379842   epsilon: 0.4459108600105123    steps: 501    lr: 1.6000000000000003e-05     evaluation reward: 6.8\nepisode: 1601   score: 9.0   memory length: 380337   epsilon: 0.4449307600105061    steps: 495    lr: 1.6000000000000003e-05     evaluation reward: 6.82\nepisode: 1602   score: 10.0   memory length: 380856   epsilon: 0.4439031400104996    steps: 519    lr: 1.6000000000000003e-05     evaluation reward: 6.81\nepisode: 1603   score: 9.0   memory length: 381361   epsilon: 0.44290324001049325    steps: 505    lr: 1.6000000000000003e-05     evaluation reward: 6.85\nepisode: 1604   score: 5.0   memory length: 381651   epsilon: 0.4423290400104896    steps: 290    lr: 1.6000000000000003e-05     evaluation reward: 6.84\nepisode: 1605   score: 4.0   memory length: 381910   epsilon: 0.44181622001048637    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 6.84\nepisode: 1606   score: 6.0   memory length: 382238   epsilon: 0.44116678001048226    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 6.82\nepisode: 1607   score: 5.0   memory length: 382566   epsilon: 0.44051734001047815    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 6.84\nepisode: 1608   score: 12.0   memory length: 383150   epsilon: 0.43936102001047084    steps: 584    lr: 1.6000000000000003e-05     evaluation reward: 6.92\nepisode: 1609   score: 15.0   memory length: 383674   epsilon: 0.4383235000104643    steps: 524    lr: 1.6000000000000003e-05     evaluation reward: 7.02\nepisode: 1610   score: 10.0   memory length: 384178   epsilon: 0.43732558001045796    steps: 504    lr: 1.6000000000000003e-05     evaluation reward: 7.05\nepisode: 1611   score: 11.0   memory length: 384727   epsilon: 0.4362385600104511    steps: 549    lr: 1.6000000000000003e-05     evaluation reward: 7.11\nepisode: 1612   score: 8.0   memory length: 385163   epsilon: 0.4353752800104456    steps: 436    lr: 1.6000000000000003e-05     evaluation reward: 7.09\nepisode: 1613   score: 7.0   memory length: 385535   epsilon: 0.43463872001044096    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 7.07\nepisode: 1614   score: 7.0   memory length: 385947   epsilon: 0.4338229600104358    steps: 412    lr: 1.6000000000000003e-05     evaluation reward: 7.09\nepisode: 1615   score: 8.0   memory length: 386369   epsilon: 0.4329874000104305    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 7.09\nepisode: 1616   score: 8.0   memory length: 386786   epsilon: 0.4321617400104253    steps: 417    lr: 1.6000000000000003e-05     evaluation reward: 7.13\nepisode: 1617   score: 7.0   memory length: 387165   epsilon: 0.43141132001042054    steps: 379    lr: 1.6000000000000003e-05     evaluation reward: 7.14\nepisode: 1618   score: 6.0   memory length: 387496   epsilon: 0.4307559400104164    steps: 331    lr: 1.6000000000000003e-05     evaluation reward: 7.08\nepisode: 1619   score: 6.0   memory length: 387834   epsilon: 0.43008670001041216    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 7.08\nepisode: 1620   score: 6.0   memory length: 388190   epsilon: 0.4293818200104077    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 7.05\nepisode: 1621   score: 5.0   memory length: 388463   epsilon: 0.4288412800104043    steps: 273    lr: 1.6000000000000003e-05     evaluation reward: 7.05\nepisode: 1622   score: 8.0   memory length: 388919   epsilon: 0.42793840001039857    steps: 456    lr: 1.6000000000000003e-05     evaluation reward: 7.08\nepisode: 1623   score: 8.0   memory length: 389395   epsilon: 0.4269959200103926    steps: 476    lr: 1.6000000000000003e-05     evaluation reward: 7.11\nepisode: 1624   score: 6.0   memory length: 389753   epsilon: 0.4262870800103881    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 7.12\nepisode: 1625   score: 4.0   memory length: 390032   epsilon: 0.4257346600103846    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 7.09\nepisode: 1626   score: 4.0   memory length: 390294   epsilon: 0.42521590001038134    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 7.05\nepisode: 1627   score: 4.0   memory length: 390555   epsilon: 0.4246991200103781    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 7.02\nepisode: 1628   score: 6.0   memory length: 390897   epsilon: 0.4240219600103738    steps: 342    lr: 1.6000000000000003e-05     evaluation reward: 6.97\nepisode: 1629   score: 5.0   memory length: 391203   epsilon: 0.42341608001036996    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 6.94\nepisode: 1630   score: 7.0   memory length: 391595   epsilon: 0.42263992001036504    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 6.99\nepisode: 1631   score: 11.0   memory length: 392135   epsilon: 0.4215707200103583    steps: 540    lr: 1.6000000000000003e-05     evaluation reward: 7.06\nepisode: 1632   score: 5.0   memory length: 392442   epsilon: 0.42096286001035443    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 7.04\nepisode: 1633   score: 5.0   memory length: 392769   epsilon: 0.42031540001035034    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 7.03\nepisode: 1634   score: 5.0   memory length: 393093   epsilon: 0.4196738800103463    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 6.99\nepisode: 1635   score: 8.0   memory length: 393566   epsilon: 0.41873734001034035    steps: 473    lr: 1.6000000000000003e-05     evaluation reward: 7.02\nepisode: 1636   score: 11.0   memory length: 394118   epsilon: 0.41764438001033344    steps: 552    lr: 1.6000000000000003e-05     evaluation reward: 7.06\nepisode: 1637   score: 8.0   memory length: 394562   epsilon: 0.4167652600103279    steps: 444    lr: 1.6000000000000003e-05     evaluation reward: 7.07\nepisode: 1638   score: 4.0   memory length: 394822   epsilon: 0.4162504600103246    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 7.07\nepisode: 1639   score: 9.0   memory length: 395257   epsilon: 0.41538916001031917    steps: 435    lr: 1.6000000000000003e-05     evaluation reward: 7.07\nepisode: 1640   score: 9.0   memory length: 395696   epsilon: 0.41451994001031367    steps: 439    lr: 1.6000000000000003e-05     evaluation reward: 7.1\nepisode: 1641   score: 5.0   memory length: 396039   epsilon: 0.4138408000103094    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 7.08\nepisode: 1642   score: 6.0   memory length: 396361   epsilon: 0.41320324001030534    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 7.07\nepisode: 1643   score: 9.0   memory length: 396836   epsilon: 0.4122627400102994    steps: 475    lr: 1.6000000000000003e-05     evaluation reward: 7.07\nepisode: 1644   score: 6.0   memory length: 397175   epsilon: 0.41159152001029514    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 7.03\nepisode: 1645   score: 7.0   memory length: 397553   epsilon: 0.4108430800102904    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 7.03\nepisode: 1646   score: 10.0   memory length: 398049   epsilon: 0.4098610000102842    steps: 496    lr: 1.6000000000000003e-05     evaluation reward: 7.07\nepisode: 1647   score: 7.0   memory length: 398470   epsilon: 0.4090274200102789    steps: 421    lr: 1.6000000000000003e-05     evaluation reward: 7.08\nepisode: 1648   score: 8.0   memory length: 398880   epsilon: 0.4082156200102738    steps: 410    lr: 1.6000000000000003e-05     evaluation reward: 7.11\nepisode: 1649   score: 13.0   memory length: 399427   epsilon: 0.40713256001026693    steps: 547    lr: 1.6000000000000003e-05     evaluation reward: 7.17\nepisode: 1650   score: 7.0   memory length: 399793   epsilon: 0.40640788001026235    steps: 366    lr: 1.6000000000000003e-05     evaluation reward: 7.16\nepisode: 1651   score: 7.0   memory length: 400180   epsilon: 0.4056416200102575    steps: 387    lr: 6.400000000000001e-06     evaluation reward: 7.12\nepisode: 1652   score: 9.0   memory length: 400612   epsilon: 0.4047862600102521    steps: 432    lr: 6.400000000000001e-06     evaluation reward: 7.14\nepisode: 1653   score: 12.0   memory length: 401206   epsilon: 0.40361014001024464    steps: 594    lr: 6.400000000000001e-06     evaluation reward: 7.22\nepisode: 1654   score: 7.0   memory length: 401594   epsilon: 0.4028419000102398    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 7.26\nepisode: 1655   score: 3.0   memory length: 401820   epsilon: 0.40239442001023695    steps: 226    lr: 6.400000000000001e-06     evaluation reward: 7.21\nepisode: 1656   score: 8.0   memory length: 402257   epsilon: 0.4015291600102315    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 7.21\nepisode: 1657   score: 6.0   memory length: 402610   epsilon: 0.40083022001022706    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 7.22\nepisode: 1658   score: 8.0   memory length: 402890   epsilon: 0.40027582001022355    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 7.22\nepisode: 1659   score: 7.0   memory length: 403259   epsilon: 0.3995452000102189    steps: 369    lr: 6.400000000000001e-06     evaluation reward: 7.26\nepisode: 1660   score: 7.0   memory length: 403647   epsilon: 0.39877696001021407    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 7.27\nepisode: 1661   score: 9.0   memory length: 404112   epsilon: 0.39785626001020824    steps: 465    lr: 6.400000000000001e-06     evaluation reward: 7.25\nepisode: 1662   score: 6.0   memory length: 404454   epsilon: 0.39717910001020396    steps: 342    lr: 6.400000000000001e-06     evaluation reward: 7.23\nepisode: 1663   score: 5.0   memory length: 404747   epsilon: 0.3965989600102003    steps: 293    lr: 6.400000000000001e-06     evaluation reward: 7.22\nepisode: 1664   score: 3.0   memory length: 404975   epsilon: 0.39614752001019743    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 7.15\nepisode: 1665   score: 7.0   memory length: 405333   epsilon: 0.39543868001019294    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 7.15\nepisode: 1666   score: 7.0   memory length: 405719   epsilon: 0.3946744000101881    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 7.17\nepisode: 1667   score: 6.0   memory length: 406041   epsilon: 0.3940368400101841    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 7.17\nepisode: 1668   score: 6.0   memory length: 406405   epsilon: 0.3933161200101795    steps: 364    lr: 6.400000000000001e-06     evaluation reward: 7.16\nepisode: 1669   score: 12.0   memory length: 406930   epsilon: 0.39227662001017294    steps: 525    lr: 6.400000000000001e-06     evaluation reward: 7.21\nepisode: 1670   score: 7.0   memory length: 407321   epsilon: 0.39150244001016804    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 7.23\nepisode: 1671   score: 5.0   memory length: 407610   epsilon: 0.3909302200101644    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 7.22\nepisode: 1672   score: 8.0   memory length: 408021   epsilon: 0.39011644001015927    steps: 411    lr: 6.400000000000001e-06     evaluation reward: 7.23\nepisode: 1673   score: 5.0   memory length: 408324   epsilon: 0.3895165000101555    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 7.25\nepisode: 1674   score: 7.0   memory length: 408727   epsilon: 0.3887185600101504    steps: 403    lr: 6.400000000000001e-06     evaluation reward: 7.29\nepisode: 1675   score: 9.0   memory length: 409205   epsilon: 0.38777212001014444    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 7.16\nepisode: 1676   score: 6.0   memory length: 409578   epsilon: 0.38703358001013977    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 7.16\nepisode: 1677   score: 11.0   memory length: 410141   epsilon: 0.3859188400101327    steps: 563    lr: 6.400000000000001e-06     evaluation reward: 7.17\nepisode: 1678   score: 6.0   memory length: 410512   epsilon: 0.38518426001012807    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 7.18\nepisode: 1679   score: 8.0   memory length: 410918   epsilon: 0.384380380010123    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 7.17\nepisode: 1680   score: 12.0   memory length: 411509   epsilon: 0.3832102000101156    steps: 591    lr: 6.400000000000001e-06     evaluation reward: 7.23\nepisode: 1681   score: 9.0   memory length: 412015   epsilon: 0.38220832001010924    steps: 506    lr: 6.400000000000001e-06     evaluation reward: 7.25\nepisode: 1682   score: 8.0   memory length: 412452   epsilon: 0.38134306001010376    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 7.25\nepisode: 1683   score: 14.0   memory length: 413071   epsilon: 0.380117440010096    steps: 619    lr: 6.400000000000001e-06     evaluation reward: 7.33\nepisode: 1684   score: 9.0   memory length: 413390   epsilon: 0.379485820010092    steps: 319    lr: 6.400000000000001e-06     evaluation reward: 7.38\nepisode: 1685   score: 4.0   memory length: 413648   epsilon: 0.3789749800100888    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 7.35\nepisode: 1686   score: 17.0   memory length: 414358   epsilon: 0.3775691800100799    steps: 710    lr: 6.400000000000001e-06     evaluation reward: 7.44\nepisode: 1687   score: 7.0   memory length: 414757   epsilon: 0.3767791600100749    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 7.48\nepisode: 1688   score: 4.0   memory length: 415001   epsilon: 0.37629604001007183    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 7.48\nepisode: 1689   score: 9.0   memory length: 415450   epsilon: 0.3754070200100662    steps: 449    lr: 6.400000000000001e-06     evaluation reward: 7.46\nepisode: 1690   score: 4.0   memory length: 415693   epsilon: 0.37492588001006316    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 7.39\nepisode: 1691   score: 9.0   memory length: 416148   epsilon: 0.37402498001005746    steps: 455    lr: 6.400000000000001e-06     evaluation reward: 7.42\nepisode: 1692   score: 11.0   memory length: 416686   epsilon: 0.3729597400100507    steps: 538    lr: 6.400000000000001e-06     evaluation reward: 7.45\nepisode: 1693   score: 11.0   memory length: 417239   epsilon: 0.3718648000100438    steps: 553    lr: 6.400000000000001e-06     evaluation reward: 7.48\nepisode: 1694   score: 12.0   memory length: 417831   epsilon: 0.3706926400100364    steps: 592    lr: 6.400000000000001e-06     evaluation reward: 7.57\nepisode: 1695   score: 10.0   memory length: 418364   epsilon: 0.3696373000100297    steps: 533    lr: 6.400000000000001e-06     evaluation reward: 7.62\nepisode: 1696   score: 8.0   memory length: 418749   epsilon: 0.3688750000100249    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 7.62\nepisode: 1697   score: 9.0   memory length: 419268   epsilon: 0.3678473800100184    steps: 519    lr: 6.400000000000001e-06     evaluation reward: 7.62\nepisode: 1698   score: 6.0   memory length: 419613   epsilon: 0.36716428001001405    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 7.65\nepisode: 1699   score: 4.0   memory length: 419892   epsilon: 0.36661186001001056    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 7.62\nepisode: 1700   score: 11.0   memory length: 420421   epsilon: 0.36556444001000393    steps: 529    lr: 6.400000000000001e-06     evaluation reward: 7.64\nepisode: 1701   score: 8.0   memory length: 420842   epsilon: 0.36473086000999866    steps: 421    lr: 6.400000000000001e-06     evaluation reward: 7.63\nepisode: 1702   score: 12.0   memory length: 421461   epsilon: 0.3635052400099909    steps: 619    lr: 6.400000000000001e-06     evaluation reward: 7.65\nepisode: 1703   score: 14.0   memory length: 422015   epsilon: 0.36240832000998396    steps: 554    lr: 6.400000000000001e-06     evaluation reward: 7.7\nepisode: 1704   score: 8.0   memory length: 422462   epsilon: 0.36152326000997836    steps: 447    lr: 6.400000000000001e-06     evaluation reward: 7.73\nepisode: 1705   score: 11.0   memory length: 423020   epsilon: 0.3604184200099714    steps: 558    lr: 6.400000000000001e-06     evaluation reward: 7.8\nepisode: 1706   score: 6.0   memory length: 423322   epsilon: 0.3598204600099676    steps: 302    lr: 6.400000000000001e-06     evaluation reward: 7.8\nepisode: 1707   score: 7.0   memory length: 423695   epsilon: 0.3590819200099629    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 7.82\nepisode: 1708   score: 6.0   memory length: 424017   epsilon: 0.3584443600099589    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 7.76\nepisode: 1709   score: 7.0   memory length: 424393   epsilon: 0.3576998800099542    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 7.68\nepisode: 1710   score: 5.0   memory length: 424727   epsilon: 0.35703856000995    steps: 334    lr: 6.400000000000001e-06     evaluation reward: 7.63\nepisode: 1711   score: 4.0   memory length: 424969   epsilon: 0.35655940000994696    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 7.56\nepisode: 1712   score: 6.0   memory length: 425304   epsilon: 0.35589610000994276    steps: 335    lr: 6.400000000000001e-06     evaluation reward: 7.54\nepisode: 1713   score: 10.0   memory length: 425877   epsilon: 0.3547615600099356    steps: 573    lr: 6.400000000000001e-06     evaluation reward: 7.57\nepisode: 1714   score: 10.0   memory length: 426413   epsilon: 0.35370028000992887    steps: 536    lr: 6.400000000000001e-06     evaluation reward: 7.6\nepisode: 1715   score: 5.0   memory length: 426700   epsilon: 0.3531320200099253    steps: 287    lr: 6.400000000000001e-06     evaluation reward: 7.57\nepisode: 1716   score: 9.0   memory length: 427171   epsilon: 0.3521994400099194    steps: 471    lr: 6.400000000000001e-06     evaluation reward: 7.58\nepisode: 1717   score: 9.0   memory length: 427612   epsilon: 0.35132626000991385    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 7.6\nepisode: 1718   score: 8.0   memory length: 428046   epsilon: 0.3504669400099084    steps: 434    lr: 6.400000000000001e-06     evaluation reward: 7.62\nepisode: 1719   score: 11.0   memory length: 428485   epsilon: 0.3495977200099029    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 7.67\nepisode: 1720   score: 10.0   memory length: 428953   epsilon: 0.34867108000989705    steps: 468    lr: 6.400000000000001e-06     evaluation reward: 7.71\nepisode: 1721   score: 9.0   memory length: 429314   epsilon: 0.3479563000098925    steps: 361    lr: 6.400000000000001e-06     evaluation reward: 7.75\nepisode: 1722   score: 10.0   memory length: 429853   epsilon: 0.3468890800098858    steps: 539    lr: 6.400000000000001e-06     evaluation reward: 7.77\nepisode: 1723   score: 5.0   memory length: 430168   epsilon: 0.34626538000988183    steps: 315    lr: 6.400000000000001e-06     evaluation reward: 7.74\nepisode: 1724   score: 7.0   memory length: 430572   epsilon: 0.34546546000987677    steps: 404    lr: 6.400000000000001e-06     evaluation reward: 7.75\nepisode: 1725   score: 10.0   memory length: 431117   epsilon: 0.34438636000986994    steps: 545    lr: 6.400000000000001e-06     evaluation reward: 7.81\nepisode: 1726   score: 16.0   memory length: 431733   epsilon: 0.3431666800098622    steps: 616    lr: 6.400000000000001e-06     evaluation reward: 7.93\nepisode: 1727   score: 13.0   memory length: 432235   epsilon: 0.34217272000985594    steps: 502    lr: 6.400000000000001e-06     evaluation reward: 8.02\nepisode: 1728   score: 8.0   memory length: 432634   epsilon: 0.34138270000985094    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 8.04\nepisode: 1729   score: 7.0   memory length: 433004   epsilon: 0.3406501000098463    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 8.06\nepisode: 1730   score: 11.0   memory length: 433556   epsilon: 0.3395571400098394    steps: 552    lr: 6.400000000000001e-06     evaluation reward: 8.1\nepisode: 1731   score: 9.0   memory length: 434026   epsilon: 0.3386265400098335    steps: 470    lr: 6.400000000000001e-06     evaluation reward: 8.08\nepisode: 1732   score: 16.0   memory length: 434628   epsilon: 0.33743458000982596    steps: 602    lr: 6.400000000000001e-06     evaluation reward: 8.19\nepisode: 1733   score: 14.0   memory length: 435331   epsilon: 0.33604264000981715    steps: 703    lr: 6.400000000000001e-06     evaluation reward: 8.28\nepisode: 1734   score: 11.0   memory length: 435919   epsilon: 0.3348784000098098    steps: 588    lr: 6.400000000000001e-06     evaluation reward: 8.34\nepisode: 1735   score: 11.0   memory length: 436503   epsilon: 0.33372208000980247    steps: 584    lr: 6.400000000000001e-06     evaluation reward: 8.37\nepisode: 1736   score: 5.0   memory length: 436827   epsilon: 0.3330805600097984    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 8.31\nepisode: 1737   score: 9.0   memory length: 437307   epsilon: 0.3321301600097924    steps: 480    lr: 6.400000000000001e-06     evaluation reward: 8.32\nepisode: 1738   score: 4.0   memory length: 437582   epsilon: 0.33158566000978895    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 8.32\nepisode: 1739   score: 8.0   memory length: 438004   epsilon: 0.33075010000978367    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 8.31\nepisode: 1740   score: 13.0   memory length: 438624   epsilon: 0.3295225000097759    steps: 620    lr: 6.400000000000001e-06     evaluation reward: 8.35\nepisode: 1741   score: 8.0   memory length: 439008   epsilon: 0.3287621800097711    steps: 384    lr: 6.400000000000001e-06     evaluation reward: 8.38\nepisode: 1742   score: 12.0   memory length: 439567   epsilon: 0.3276553600097641    steps: 559    lr: 6.400000000000001e-06     evaluation reward: 8.44\nepisode: 1743   score: 11.0   memory length: 440074   epsilon: 0.32665150000975773    steps: 507    lr: 6.400000000000001e-06     evaluation reward: 8.46\nepisode: 1744   score: 11.0   memory length: 440607   epsilon: 0.32559616000975106    steps: 533    lr: 6.400000000000001e-06     evaluation reward: 8.51\nepisode: 1745   score: 7.0   memory length: 440976   epsilon: 0.32486554000974643    steps: 369    lr: 6.400000000000001e-06     evaluation reward: 8.51\nepisode: 1746   score: 6.0   memory length: 441351   epsilon: 0.32412304000974174    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 8.47\nepisode: 1747   score: 19.0   memory length: 442046   epsilon: 0.32274694000973303    steps: 695    lr: 6.400000000000001e-06     evaluation reward: 8.59\nepisode: 1748   score: 10.0   memory length: 442537   epsilon: 0.3217747600097269    steps: 491    lr: 6.400000000000001e-06     evaluation reward: 8.61\nepisode: 1749   score: 8.0   memory length: 442955   epsilon: 0.32094712000972164    steps: 418    lr: 6.400000000000001e-06     evaluation reward: 8.56\nepisode: 1750   score: 10.0   memory length: 443400   epsilon: 0.32006602000971607    steps: 445    lr: 6.400000000000001e-06     evaluation reward: 8.59\nepisode: 1751   score: 19.0   memory length: 444073   epsilon: 0.31873348000970764    steps: 673    lr: 6.400000000000001e-06     evaluation reward: 8.71\nepisode: 1752   score: 8.0   memory length: 444513   epsilon: 0.3178622800097021    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 8.7\nepisode: 1753   score: 13.0   memory length: 445002   epsilon: 0.316894060009696    steps: 489    lr: 6.400000000000001e-06     evaluation reward: 8.71\nepisode: 1754   score: 6.0   memory length: 445362   epsilon: 0.3161812600096915    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 8.7\nepisode: 1755   score: 7.0   memory length: 445714   epsilon: 0.3154843000096871    steps: 352    lr: 6.400000000000001e-06     evaluation reward: 8.74\nepisode: 1756   score: 10.0   memory length: 446216   epsilon: 0.3144903400096808    steps: 502    lr: 6.400000000000001e-06     evaluation reward: 8.76\nepisode: 1757   score: 14.0   memory length: 446804   epsilon: 0.3133261000096734    steps: 588    lr: 6.400000000000001e-06     evaluation reward: 8.84\nepisode: 1758   score: 9.0   memory length: 447308   epsilon: 0.3123281800096671    steps: 504    lr: 6.400000000000001e-06     evaluation reward: 8.85\nepisode: 1759   score: 10.0   memory length: 447748   epsilon: 0.3114569800096616    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 8.88\nepisode: 1760   score: 7.0   memory length: 448136   epsilon: 0.31068874000965674    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 8.88\nepisode: 1761   score: 15.0   memory length: 448740   epsilon: 0.30949282000964917    steps: 604    lr: 6.400000000000001e-06     evaluation reward: 8.94\nepisode: 1762   score: 10.0   memory length: 449177   epsilon: 0.3086275600096437    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 8.98\nepisode: 1763   score: 9.0   memory length: 449648   epsilon: 0.3076949800096378    steps: 471    lr: 6.400000000000001e-06     evaluation reward: 9.02\nepisode: 1764   score: 17.0   memory length: 450301   epsilon: 0.3064020400096296    steps: 653    lr: 6.400000000000001e-06     evaluation reward: 9.16\nepisode: 1765   score: 10.0   memory length: 450812   epsilon: 0.3053902600096232    steps: 511    lr: 6.400000000000001e-06     evaluation reward: 9.19\nepisode: 1766   score: 7.0   memory length: 451203   epsilon: 0.3046160800096183    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 9.19\nepisode: 1767   score: 8.0   memory length: 451658   epsilon: 0.3037151800096126    steps: 455    lr: 6.400000000000001e-06     evaluation reward: 9.21\nepisode: 1768   score: 8.0   memory length: 452112   epsilon: 0.30281626000960693    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 9.23\nepisode: 1769   score: 8.0   memory length: 452518   epsilon: 0.30201238000960184    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 9.19\nepisode: 1770   score: 9.0   memory length: 452955   epsilon: 0.30114712000959637    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 9.21\nepisode: 1771   score: 9.0   memory length: 453466   epsilon: 0.30013534000958997    steps: 511    lr: 6.400000000000001e-06     evaluation reward: 9.25\nepisode: 1772   score: 3.0   memory length: 453695   epsilon: 0.2996819200095871    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 9.2\nepisode: 1773   score: 7.0   memory length: 454083   epsilon: 0.29891368000958224    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 9.22\nepisode: 1774   score: 10.0   memory length: 454660   epsilon: 0.297771220009575    steps: 577    lr: 6.400000000000001e-06     evaluation reward: 9.25\nepisode: 1775   score: 9.0   memory length: 455099   epsilon: 0.2969020000095695    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 9.25\nepisode: 1776   score: 9.0   memory length: 455566   epsilon: 0.29597734000956366    steps: 467    lr: 6.400000000000001e-06     evaluation reward: 9.28\nepisode: 1777   score: 5.0   memory length: 455876   epsilon: 0.2953635400095598    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 9.22\nepisode: 1778   score: 9.0   memory length: 456349   epsilon: 0.29442700000955385    steps: 473    lr: 6.400000000000001e-06     evaluation reward: 9.25\nepisode: 1779   score: 8.0   memory length: 456793   epsilon: 0.2935478800095483    steps: 444    lr: 6.400000000000001e-06     evaluation reward: 9.25\nepisode: 1780   score: 13.0   memory length: 457367   epsilon: 0.2924113600095411    steps: 574    lr: 6.400000000000001e-06     evaluation reward: 9.26\nepisode: 1781   score: 8.0   memory length: 457789   epsilon: 0.2915758000095358    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 9.25\nepisode: 1782   score: 9.0   memory length: 458242   epsilon: 0.29067886000953014    steps: 453    lr: 6.400000000000001e-06     evaluation reward: 9.26\nepisode: 1783   score: 10.0   memory length: 458710   epsilon: 0.2897522200095243    steps: 468    lr: 6.400000000000001e-06     evaluation reward: 9.22\nepisode: 1784   score: 13.0   memory length: 459350   epsilon: 0.28848502000951626    steps: 640    lr: 6.400000000000001e-06     evaluation reward: 9.26\nepisode: 1785   score: 7.0   memory length: 459758   epsilon: 0.28767718000951115    steps: 408    lr: 6.400000000000001e-06     evaluation reward: 9.29\nepisode: 1786   score: 12.0   memory length: 460318   epsilon: 0.28656838000950413    steps: 560    lr: 6.400000000000001e-06     evaluation reward: 9.24\nepisode: 1787   score: 14.0   memory length: 460918   epsilon: 0.2853803800094966    steps: 600    lr: 6.400000000000001e-06     evaluation reward: 9.31\nepisode: 1788   score: 9.0   memory length: 461411   epsilon: 0.28440424000949044    steps: 493    lr: 6.400000000000001e-06     evaluation reward: 9.36\nepisode: 1789   score: 9.0   memory length: 461871   epsilon: 0.2834934400094847    steps: 460    lr: 6.400000000000001e-06     evaluation reward: 9.36\nepisode: 1790   score: 9.0   memory length: 462189   epsilon: 0.2828638000094807    steps: 318    lr: 6.400000000000001e-06     evaluation reward: 9.41\nepisode: 1791   score: 11.0   memory length: 462710   epsilon: 0.28183222000947417    steps: 521    lr: 6.400000000000001e-06     evaluation reward: 9.43\nepisode: 1792   score: 13.0   memory length: 463177   epsilon: 0.2809075600094683    steps: 467    lr: 6.400000000000001e-06     evaluation reward: 9.45\nepisode: 1793   score: 12.0   memory length: 463761   epsilon: 0.279751240009461    steps: 584    lr: 6.400000000000001e-06     evaluation reward: 9.46\nepisode: 1794   score: 11.0   memory length: 464298   epsilon: 0.2786879800094543    steps: 537    lr: 6.400000000000001e-06     evaluation reward: 9.45\nepisode: 1795   score: 17.0   memory length: 464905   epsilon: 0.27748612000944667    steps: 607    lr: 6.400000000000001e-06     evaluation reward: 9.52\nepisode: 1796   score: 8.0   memory length: 465361   epsilon: 0.27658324000944096    steps: 456    lr: 6.400000000000001e-06     evaluation reward: 9.52\nepisode: 1797   score: 10.0   memory length: 465839   epsilon: 0.27563680000943497    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 9.53\nepisode: 1798   score: 8.0   memory length: 466259   epsilon: 0.2748052000094297    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 9.55\nepisode: 1799   score: 13.0   memory length: 466728   epsilon: 0.27387658000942383    steps: 469    lr: 6.400000000000001e-06     evaluation reward: 9.64\nepisode: 1800   score: 15.0   memory length: 467320   epsilon: 0.2727044200094164    steps: 592    lr: 6.400000000000001e-06     evaluation reward: 9.68\nepisode: 1801   score: 7.0   memory length: 467712   epsilon: 0.2719282600094115    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 9.67\nepisode: 1802   score: 10.0   memory length: 468234   epsilon: 0.27089470000940497    steps: 522    lr: 6.400000000000001e-06     evaluation reward: 9.65\nepisode: 1803   score: 16.0   memory length: 468854   epsilon: 0.2696671000093972    steps: 620    lr: 6.400000000000001e-06     evaluation reward: 9.67\nepisode: 1804   score: 16.0   memory length: 469464   epsilon: 0.26845930000938956    steps: 610    lr: 6.400000000000001e-06     evaluation reward: 9.75\nepisode: 1805   score: 13.0   memory length: 470110   epsilon: 0.26718022000938146    steps: 646    lr: 6.400000000000001e-06     evaluation reward: 9.77\nepisode: 1806   score: 7.0   memory length: 470497   epsilon: 0.2664139600093766    steps: 387    lr: 6.400000000000001e-06     evaluation reward: 9.78\nepisode: 1807   score: 10.0   memory length: 470989   epsilon: 0.26543980000937045    steps: 492    lr: 6.400000000000001e-06     evaluation reward: 9.81\nepisode: 1808   score: 8.0   memory length: 471414   epsilon: 0.26459830000936513    steps: 425    lr: 6.400000000000001e-06     evaluation reward: 9.83\nepisode: 1809   score: 15.0   memory length: 472015   epsilon: 0.2634083200093576    steps: 601    lr: 6.400000000000001e-06     evaluation reward: 9.91\nepisode: 1810   score: 18.0   memory length: 472658   epsilon: 0.26213518000934954    steps: 643    lr: 6.400000000000001e-06     evaluation reward: 10.04\nepisode: 1811   score: 14.0   memory length: 473227   epsilon: 0.2610085600093424    steps: 569    lr: 6.400000000000001e-06     evaluation reward: 10.14\nepisode: 1812   score: 12.0   memory length: 473816   epsilon: 0.25984234000933504    steps: 589    lr: 6.400000000000001e-06     evaluation reward: 10.2\nepisode: 1813   score: 17.0   memory length: 474465   epsilon: 0.2585573200093269    steps: 649    lr: 6.400000000000001e-06     evaluation reward: 10.27\nepisode: 1814   score: 14.0   memory length: 475076   epsilon: 0.25734754000931925    steps: 611    lr: 6.400000000000001e-06     evaluation reward: 10.31\nepisode: 1815   score: 16.0   memory length: 475604   epsilon: 0.25630210000931264    steps: 528    lr: 6.400000000000001e-06     evaluation reward: 10.42\nepisode: 1816   score: 7.0   memory length: 476006   epsilon: 0.2555061400093076    steps: 402    lr: 6.400000000000001e-06     evaluation reward: 10.4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Visualize Agent Performance","metadata":{}},{"cell_type":"markdown","source":"BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n\nPlease save your model before running this portion of the code.","metadata":{}},{"cell_type":"code","source":"torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gym.wrappers import Monitor # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\nimport glob\nimport io\nimport base64\n\nfrom IPython.display import HTML\nfrom IPython import display as ipythondisplay\n\nfrom pyvirtualdisplay import Display\n\n# Displaying the game live\ndef show_state(env, step=0, info=\"\"):\n    plt.figure(3)\n    plt.clf()\n    plt.imshow(env.render(mode='rgb_array'))\n    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n    plt.axis('off')\n\n    ipythondisplay.clear_output(wait=True)\n    ipythondisplay.display(plt.gcf())\n    \n# Recording the game and replaying the game afterwards\ndef show_video():\n    mp4list = glob.glob('video/*.mp4')\n    if len(mp4list) > 0:\n        mp4 = mp4list[0]\n        video = io.open(mp4, 'r+b').read()\n        encoded = base64.b64encode(video)\n        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n                loop controls style=\"height: 400px;\">\n                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n             </video>'''.format(encoded.decode('ascii'))))\n    else: \n        print(\"Could not find video\")\n    \n\ndef wrap_env(env):\n    env = Monitor(env, './video', force=True)\n    return env","metadata":{},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"display = Display(visible=0, size=(300, 200))\ndisplay.start()\n\n# Load agent\n# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\nagent.epsilon = 0.0 # Set agent to only exploit the best action\n\nenv = gym.make('BreakoutDeterministic-v4')\nenv = wrap_env(env)\n\ndone = False\nscore = 0\nstep = 0\nstate = env.reset()\nnext_state = state\nlife = number_lives\nhistory = np.zeros([5, 84, 84], dtype=np.uint8)\nget_init_state(history, state)\n\nwhile not done:\n    \n    # Render breakout\n    env.render()\n#     show_state(env,step) # uncommenting this provides another way to visualize the game\n\n    step += 1\n    frame += 1\n\n    # Perform a fire action if ball is no longer on screen\n    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n        action = 0\n    else:\n        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n    state = next_state\n    \n    next_state, reward, done, info = env.step(action + 1)\n        \n    frame_next_state = get_frame(next_state)\n    history[4, :, :] = frame_next_state\n    terminal_state = check_live(life, info['ale.lives'])\n        \n    life = info['ale.lives']\n    r = np.clip(reward, -1, 1) \n    r = reward\n\n    # Store the transition in memory \n    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n    # Start training after random sample generation\n    score += reward\n    \n    history[:4, :, :] = history[1:, :, :]\nenv.close()\nshow_video()\ndisplay.stop()","metadata":{},"execution_count":null,"outputs":[]}]}